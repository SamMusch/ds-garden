---
title: 3Blue1Brown - GPT
---

```ad-sam
GPT = Generative Pre-trained Transformer
- **Generative**: Create new text
- **Pre-trained**: How the model learned
- **Transformer**: Specific kind of NN, core invention underlying current boom in AI
```


"Attention is all you need" came from Google in 2017. 
- Specific use-case was to translate text.
- Our use-case is to predict the next word.


```ad-sam
How data flows through a transformer
1. **Embedding**
2. **Attention**
3. **MLPs**
4. **Un-embedding**
```



Deep Learning describes a *class* of models that scale very well. (Includes **Transformers**, MLPs, CNNs, and more.)
- The *training* algorithm is called backpropagation.















