---
title: 2.6 3Blue1Brown Explainer
created: '2025-07-18'
modified: '2025-04-20'
source_file: 2.6 3Blue1Brown Explainer.md
word_count: 95
reading_time: 0.5
children: 0
grandchildren: 0
ai_abstract: null
ai_key_terms: []
_kMDItemDisplayNameWithExtensions: 2.6 3Blue1Brown Explainer.md
kMDItemContentCreationDate: 2025-04-20 14:21:50 +0000
kMDItemContentCreationDate_Ranking: 2025-05-20 00:00:00 +0000
kMDItemContentModificationDate: 2025-04-20 15:33:14 +0000
kMDItemContentType: net.daringfireball.markdown
kMDItemContentTypeTree: (
kMDItemDateAdded: 2025-05-20 16:34:46 +0000
kMDItemDocumentIdentifier: '100722'
kMDItemFSCreatorCode: ''
kMDItemFSFinderFlags: '0'
kMDItemFSHasCustomIcon: (null)
kMDItemFSInvisible: '0'
kMDItemFSIsExtensionHidden: '0'
kMDItemFSIsStationery: (null)
kMDItemFSLabel: '0'
kMDItemFSNodeCount: (null)
kMDItemFSOwnerGroupID: '20'
kMDItemFSOwnerUserID: '502'
kMDItemFSTypeCode: ''
kMDItemInterestingDate_Ranking: 2025-04-20 00:00:00 +0000
Due: null
Function: null
Objective: null
Quality: null
QualityComment: null
ReviewFreq: null
CoverImage: null
HoursDone: null
HoursRemain: null
tags: null
TimeSpent: null
TimeSpent2: null
Covers: null
cssclasses: null
aliases: null
---


```ad-sam
GPT = Generative Pre-trained Transformer
- **Generative**: Create new text
- **Pre-trained**: How the model learned
- **Transformer**: Specific kind of NN, core invention underlying current boom in AI
```


"Attention is all you need" came from Google in 2017. 
- Specific use-case was to translate text.
- Our use-case is to predict the next word.


```ad-sam
How data flows through a transformer
1. **Embedding**
2. **Attention**
3. **MLPs**
4. **Un-embedding**
```



Deep Learning describes a *class* of models that scale very well. (Includes **Transformers**, MLPs, CNNs, and more.)
- The *training* algorithm is called backpropagation.















