
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://sammusch.github.io/ds-garden/_assets/AI-Book-open-from-MOC/2-5-Autoencoders-GANs-DiffusionModels/">
      
      
        <link rel="prev" href="../2-4-Gen-Models-Overview/">
      
      
        <link rel="next" href="../2-6-3Blue1Brown-Explainer/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>2.5 Autoencoders, GANs & Diffusion Models (Hands‑On) - ds-garden</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.e53b48f4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#autoencoders" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="ds-garden" class="md-header__button md-logo" aria-label="ds-garden" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ds-garden
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2.5 Autoencoders, GANs & Diffusion Models (Hands‑On)
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/SamMusch/ds-garden" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="ds-garden" class="md-nav__button md-logo" aria-label="ds-garden" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    ds-garden
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/SamMusch/ds-garden" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DataScience HOME
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AB-Testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AB Testing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../AI-MOC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
     AI MOC
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../ML-MOC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
     ML MOC
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../TS-MOC/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
     TS MOC
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
     assets
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
             assets
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Deep-Learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Deep Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ML/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ML
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" checked>
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    AI Book open from MOC
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            AI Book open from MOC
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../0-0-Neural-Network-Taxonomy/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.0 Neural Network Taxonomy
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-1-Why-NNs-Work/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.1 Why NNs Work (Intuition)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-2-Transformers-Simple/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.2 Transformers in Plain English
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-3-Self%E2%80%91Supervision-%E2%80%9CLearning-Without-Labels%E2%80%9D/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.3 Self‑Supervision   “Learning Without Labels”
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-4-Frameworks-PyTorch-JAX/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.4 Modern Frameworks (PyTorch, JAX)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-5-NLP-Fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.5 NLP Fundamentals
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-6-Hugging-Face-Workflows/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1.6 Hugging Face Workflows
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-1-GPT%E2%80%914o-Llama-3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2.1 What Makes GPT‑4o & Llama 3 Tick (High Level)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-4-Gen-Models-Overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2.4 Generative Models Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    2.5 Autoencoders, GANs & Diffusion Models (Hands‑On)
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    2.5 Autoencoders, GANs & Diffusion Models (Hands‑On)
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#autoencoders" class="md-nav__link">
    <span class="md-ellipsis">
      Autoencoders
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ch-17" class="md-nav__link">
    <span class="md-ellipsis">
      Ch 17
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ch 17">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gans" class="md-nav__link">
    <span class="md-ellipsis">
      GANs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#autoencoders-vs-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Autoencoders vs GANs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-autoencoders" class="md-nav__link">
    <span class="md-ellipsis">
      Variational Autoencoders
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-to-ai-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      Getting to AI - generative models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Getting to AI - generative models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#autoencoders-for-inspiration" class="md-nav__link">
    <span class="md-ellipsis">
      Autoencoders (For Inspiration)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#building-an-autoencoder" class="md-nav__link">
    <span class="md-ellipsis">
      Building an Autoencoder
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#variational-autoencoders-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Variational autoencoders (VAE)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Variational autoencoders (VAE)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#structure" class="md-nav__link">
    <span class="md-ellipsis">
      Structure
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Structure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#encoder" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoder" class="md-nav__link">
    <span class="md-ellipsis">
      Decoder
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-and-optimizing-vaes" class="md-nav__link">
    <span class="md-ellipsis">
      Training and optimizing VAEs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#utilizing-a-vae" class="md-nav__link">
    <span class="md-ellipsis">
      Utilizing a VAE
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generative-adversarial-networks-gan" class="md-nav__link">
    <span class="md-ellipsis">
      Generative adversarial networks (GAN)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Generative adversarial networks (GAN)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_1" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#discriminator-network" class="md-nav__link">
    <span class="md-ellipsis">
      Discriminator network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generator-network" class="md-nav__link">
    <span class="md-ellipsis">
      Generator network
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-gans" class="md-nav__link">
    <span class="md-ellipsis">
      Training GANs
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-forms-of-generative-models" class="md-nav__link">
    <span class="md-ellipsis">
      Other forms of generative models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Other forms of generative models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#overview_2" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fully-visible-belief-nets" class="md-nav__link">
    <span class="md-ellipsis">
      Fully visible belief nets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hidden-markov-models" class="md-nav__link">
    <span class="md-ellipsis">
      Hidden Markov models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#boltzmann-machines" class="md-nav__link">
    <span class="md-ellipsis">
      Boltzmann machines
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-6-3Blue1Brown-Explainer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2.6 3Blue1Brown Explainer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5-1-Local-vs-Cloud-Inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5.1 Local vs Cloud Inference (Pros & Cons)
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5-2-Quick-Quantization-Laptop-GPU/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5.2 Quick Quantization to Fit on a Laptop GPU
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6-1-Collect-Clean-Text-Data/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6.1 Collect and Clean Text Data
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6-2-CI-CD-for-Models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6.2 CI CD for Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_4" >
        
          
          <label class="md-nav__link" for="__nav_6_4" id="__nav_6_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    ML Deeper open from MOC
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_4">
            <span class="md-nav__icon md-icon"></span>
            ML Deeper open from MOC
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ML-Deeper-open-from-MOC/Supervised-2-Classification/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised 2 Classification
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ML-Deeper-open-from-MOC/Supervised-4-Regression-Eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised 4 Regression Eval
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ML-Deeper-open-from-MOC/Supervised-6-Ensemble/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised 6 Ensemble
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_5" >
        
          
          <label class="md-nav__link" for="__nav_6_5" id="__nav_6_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Templates
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_5">
            <span class="md-nav__icon md-icon"></span>
            Templates
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../Templates/Template/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Template
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_6" >
        
          
          <label class="md-nav__link" for="__nav_6_6" id="__nav_6_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    TimeSeries
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_6">
            <span class="md-nav__icon md-icon"></span>
            TimeSeries
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../TimeSeries/Theory-Univariate/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Theory   Univariate
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../TimeSeries/Video-Series/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Video Series
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>2.5 Autoencoders, GANs & Diffusion Models (Hands‑On)</h1>

<div class="highlight"><pre><span></span><code>May20: Renamed from &quot;Ch 17 Autoencoders, GANs, and Diffusion Models&quot;

Note to self - created March 22, 2025. 
</code></pre></div>
<h2 id="autoencoders">Autoencoders</h2>
<p>Also see 2-4-gen-models-overview.md - different textbook
Moved to 2-4-gen-models-overview#overview---separate-resource.md</p>
<hr />
<h2 id="ch-17">Ch 17</h2>
<p><strong>Autoencoders</strong> are ANNs capable of learning latent representations without supervision.
- <strong>Latent representations</strong> (aka <strong>codings</strong>): dense representations of the input data.</p>
<p><strong>Autoencoders</strong> uses
- <strong>Dimensionality reduction</strong>: Since codings typically have a lower dimensionality than the input data
- <strong>Feature detectors</strong>: Can be used for unsupervised pretraining of DNNs
- <strong>Generation</strong>: Some are <em>generative models</em>: they are capable of randomly generating new data that looks very similar to the training data</p>
<h3 id="gans">GANs</h3>
<p><strong>GANs</strong> (Generative Adversarial Networks) are composed of 2 NNs that compete
1. <em>generator</em> to generate data similar to training data
2. <em>discriminator</em> that tries to tell real data from fake data
<strong>Intuition</strong>: criminal generates fake money, cop tries to id fake money
<strong>Adversarial training</strong>: training <em>competing</em> NNs</p>
<h3 id="autoencoders-vs-gans">Autoencoders vs GANs</h3>
<p>Both
- Unsupervised
- Learn dense representations
- Can be used for generation
- Similar applications</p>
<p>Work differently:
- <strong>Autoencoders</strong>: simply learn to copy their inputs --&gt; outputs (non-trivial)
- <strong>GANs</strong>: create 2 NNs that compete with each other</p>
<h3 id="variational-autoencoders">Variational Autoencoders</h3>
<p>These are different than the other autoencoders in the chapter:
- They are <strong>probabilistic</strong> - ie, their outputs are partly determined by chance.
- They are <strong>generative</strong> - ie, they can produce new data</p>
<h2 id="getting-to-ai-generative-models">Getting to AI - generative models</h2>
<p>Classes of neural networks (goals):
- <strong>Discriminative models</strong>: focus on learning boundaries or correlations between <em>inputs</em> &amp; <em>labels</em>.
    - (e.g., typical feedforward nets, CNNs for classification, RNNs for sequence labeling)
- <strong>Generative models</strong>: focus on modeling the underlying data <em>distribution</em>, allowing them to produce new (synthetic) data or fill in missing features given partial information.
    - (e.g., <strong>autoencoders</strong>, <strong>VAEs</strong>, <strong>GANs</strong>)</p>
<h3 id="autoencoders-for-inspiration">Autoencoders (For Inspiration)</h3>
<p>Summarized in 2-5-autoencoders-gans-diffusionmodels#autoencoders.md</p>
<h3 id="building-an-autoencoder">Building an Autoencoder</h3>
<p>If you're thinking that the task of reconstructing an output doesn't appear that useful, you're not alone. </p>
<p>What exactly do we use these networks for? Autoencoders help to extract features when there are no known labeled features at hand.</p>
<p>To illustrate how this works, let's walk through an example using TensorFlow. We're going to reconstruct the MNIST dataset here, and, later on, we will compare the performance of the standard autoencoder against the variational autoencoder in relation to the same task.</p>
<p>Let's get started with our imports and data. MNIST is contained natively within TensorFlow, so we can easily import it:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>  
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>  

<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.examples.tutorials.mnist</span><span class="w"> </span><span class="kn">import</span> <span class="n">input_data</span>  
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;/tmp/data/&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></p>
<p>For ease, we can build the auto-encoder with the <code>tf.layers</code> library. We'll want our Autoencoder architecture to follow the convolutional/de-convolutional pattern, where the input layer of the decoder matches the size of the input and the subsequent layer squash the data into a smaller and smaller representation. The decoder will be the same architecture reversed, starting with the small representation and working larger.</p>
<p>All together, we want it to look something like the following:
!pasted-image-20241231144552.png.md</p>
<p>Let's start with the encoder; we'll define an initializer for the the weight and bias factors first, and then define the encoder as a function that takes and input, x. we'll then use the <code>tf.layers.dense</code> function to create standard, fully connected neural network layers. The encoder will have three layers, with the first layer size matching the input dimensions of the input data (<code>784</code>), with the subsequent layers getting continually smaller:
<div class="highlight"><pre><span></span><code><span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()</span>  
<span class="k">def</span><span class="w"> </span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> 
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="n">z_prime</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">z_prime</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="k">return</span> <span class="n">z</span>
</code></pre></div></p>
<p>Next, let's let's build our decoder; it will be using the same layer type and initializer as the encoder, only now we invert the layers, so that the first layer of the decoder is the smallest and the last is the largest.
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>  
    <span class="n">x_prime_one</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="n">x_prime_two</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">x_prime_one</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">x_prime_two</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>  
    <span class="k">return</span> <span class="n">output_layer</span>
</code></pre></div></p>
<p>Before we get to training, let's define some hyper-parameters that will be needed during the training cycle. We'll define the size of our input, the learning rate, number of training steps, the batch size for the training cycle, as well as how often we want to display information about our training progress.
<div class="highlight"><pre><span></span><code><span class="n">input_dim</span> <span class="o">=</span> <span class="mi">784</span>   
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>  
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">1000</span>  
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>  
<span class="n">display</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div></p>
<p>We'll then define the placeholder for our input data so that we can compile the model:
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">])</span>
</code></pre></div></p>
<p>And subsequently, we compile the model and the optimizer as you've seen before in previous chapter:
<div class="highlight"><pre><span></span><code><span class="c1"># Construct the full autoencoder  </span>
<span class="n">z</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  

<span class="c1">## x_prime represents our predicted distribution  </span>
<span class="n">x_prime</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>   

<span class="c1"># Define the loss function and the optimizer  </span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_prime</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>  
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
</code></pre></div></p>
<p>Lastly, we'll code up the training cycle. By this point, most of this should be fairly familiar to you; start a TensorFlow session, and iterate over the epochs/batches, computing the loss and accuracy at each point:
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>  
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>  

    <span class="c1">## Training Loop  </span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>  

        <span class="c1">## Feed Batches of MNIST Data  </span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>  

        <span class="c1">## Run the Optimization Process  </span>
        <span class="n">_</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">})</span>  

        <span class="c1">## Display the loss at every 1000 out of 30,000 steps  </span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">display</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Step </span><span class="si">%i</span><span class="s1">: Loss: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">l</span><span class="p">))</span>
</code></pre></div></p>
<p>For this particular example, we'll add in a little something more to this process; a way to plot the reconstructed images alongside their original versions. Keep in mind that this code is still contained within the training session, just outside of the training loop:
<div class="highlight"><pre><span></span><code><span class="n">n</span> <span class="o">=</span> <span class="mi">4</span>  
<span class="n">canvas_orig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">28</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="n">n</span><span class="p">))</span>  
<span class="n">canvas_recon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">28</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="n">n</span><span class="p">))</span>  

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  

    <span class="n">batch_x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  

    <span class="c1"># Encode and decode each individual written digit  </span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">})</span>  

    <span class="c1"># Display original images  </span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  

        <span class="c1"># Draw the original digits  </span>
        <span class="n">canvas_orig</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">28</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">28</span><span class="p">:(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_x</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>  

    <span class="c1"># Display reconstructed images  </span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  

        <span class="c1"># Draw the reconstructed digits  </span>
        <span class="n">canvas_recon</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">28</span><span class="p">:(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="mi">28</span><span class="p">:(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span>  

<span class="c1"># Plot the original image vs the reconstructed images.   </span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original Images&quot;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">canvas_orig</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reconstructed Images&quot;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">canvas_recon</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s2">&quot;upper&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></p>
<p>After training, you should end up with a result along the lines of the following, with the actual digits on the left, and the reconstructed digits on the right:
!pasted-image-20241231145350.png.md</p>
<p>So what have we done here? By training the autoencoder on unlabeled digits, we've done the following: 
- Learned the latent features of the dataset without having explicit labels
- Successfully learned the distribution of the data and reconstructed the image from scratch, from that distribution</p>
<p>Now, let's say that we wanted to take this further and generate or classify new digits that we haven't seen yet. To do this, we could remove the decoder and attach a classifier or generator network:
!pasted-image-20241231145424.png.md</p>
<p>The encoder therefore becomes a means of initializing a supervised training model. Standard autoencoders have been used in a variety of tasks. In the supplementary code for this chapter, we'll walk through an example where we utilize autoencoders for visual anomaly detection.</p>
<h2 id="variational-autoencoders-vae">Variational autoencoders (VAE)</h2>
<h3 id="overview">Overview</h3>
<p><strong>Variational autoencoders</strong> (<strong>VAEs</strong>) are built on the idea of the standard autoencoder, and are powerful generative models and one of the most popular means of learning a complicated distribution in an unsupervised fashion. VAEs are <strong>probabilistic models</strong> rooted in Bayesian inference. A probabilistic model is exactly as it sounds:</p>
<p><em>Probabilistic models incorporate random variables and probability distributions into the model of an event or phenomenon.</em></p>
<p>VAEs, and other generative models, are probabilistic in that they seek to learn a distribution that they utilize for subsequent sampling. While all generative models are probabilistic models, not all probabilistic models are generative models.</p>
<p>The probabilistic structure of VAEs comes into play with their encoders. Instead of building an encoder that outputs a single value to describe the input data, we want to learn the latent variables by generating a probability distribution for each of those variables. VAEs have a constraint on the encoding network that forces it to generate vectors that roughly follow a standard normal distribution. This is what makes VAEs unique: they generate from continuous space, which means that we can easily sample and interpret from that space. We'll see how this unique probabilistic structure helps us to overcome the limitations of standard autoencoders.</p>
<h3 id="structure">Structure</h3>
<p>Like standard autoencoders, VAEs utilize the same encoder/decoder framework, but, that aside, they are mathematically different from their namesake. VAEs take a probabilistic perspective in terms of guiding the network:
!pasted-image-20241231145555.png.md</p>
<p>Both our <strong>encoder</strong> and <strong>decoder</strong> networks are generating distributions from their input data. The encoder generates a distribution from its training data, <strong>Z</strong>, which then becomes the input distribution for the decoder. The decoder takes this distribution, <strong>Z</strong>, and tries to replicate the original distribution, <strong>X</strong>, from it.</p>
<h4 id="encoder">Encoder</h4>
<p>The encoder generates its distribution by first defining its prior as a standard normal distribution. Then, during training, this distribution becomes updated, and the decoder can easily sample from this distribution later on. Both the encoder and the decoder are unique in terms of VAEs in that they output two vectors instead of one: a vector of means, <em>μ</em>, and another vector of standard deviation, <em>σ</em>. These help to define the limits for our generated distributions. Intuitively, the mean vector controls where the encoding of an input should be centered, while the standard deviation controls the extent to which the encoding may vary from the mean. This constraint on the encoder forces the network to learn a distribution, thereby taking it beyond the vanilla autoencoder that simply reconstructs its output.</p>
<h4 id="decoder">Decoder</h4>
<p>Like the standard autoencoder, the decoder in the VAE is a backward convolutional network, or a deconvolutional network. In processing the decoding, data is sampled from the generation stochastically (randomly), making the VAE one of the few models that can directly sample a probability distribution without a Markov chain Monte Carlo method. As a result of the stochastic generation process, the encoding that we generate from each pass will be a different representation of the data, all while maintaining the same mean and standard deviation. This helps with the decoder's sampling technique; because all encodings are generated from the same distribution, the decoder learns that a latent data point and its surrounding points are all members of the same class. This allows the decoder to learn how to generate from similar, but slightly varying, encodings.</p>
<h4 id="training-and-optimizing-vaes">Training and optimizing VAEs</h4>
<p>VAEs utilize a negative log-likelihood loss as their reconstruction loss to measure how much information is lost during the reconstruction phase of the decoder. If the decoder does not reconstruct the input satisfactorily, it will incur a large reconstruction loss. VAEs also introduce something called <strong>Kullback</strong>–<strong>Leibler</strong> (<strong>KL</strong>) divergence into their loss functions. KL divergence simply measures how much two probability distributions diverge; in other words, how different they are from one another. We want to minimize the KL distance between the mean and standard deviation of the target distribution and that of a standard normal. It is properly minimized when the mean is zero and the standard deviation is one. The log-likelihood loss with KL divergence forms the complete loss function for VAEs.</p>
<p>When training VAEs, there is an implicit trade-off between the accuracy of the model and how close it can model the normal distribution. On its own, KL loss results in encoded data that is densely clustered near the center of the distribution, with little iteration with other potentially similar encoded data. A decoder wouldn't be able to decode anything from the space, because it wouldn't be particularly continuous! By combining the losses and optimizing them, we are able to preserve the dense nature of encoded data created by the KL loss function, as well as the clustered data produced by the reconstruction loss. What we then end up with are tight clusters that are easy for the decoder to work with. We wanted our generated distribution Z to resemble a standard normal distribution as closely as possible, and the more efficiently we can encode the original image, the closer we can push the standard deviation of the generated distribution toward one, the standard deviation of the targeted normal distribution.</p>
<h4 id="utilizing-a-vae">Utilizing a VAE</h4>
<p>We can construct a variational autoencoder in TensorFlow to see how it compares to it's simpler, standard autoencoder cousin. In this section, we'll be using the same MNIST dataset so that we can standardize our comparison across methods. Let's walk through how to construct a VAE by utilizing it to generate handwriting based on the MNIST dataset. Think of <em>x</em> as being the individual written characters and <em>z</em> as the latent features in each of the individual characters that we are trying to learn.</p>
<p>First, let's start with our imports:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>  
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>  
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.examples.tutorials.mnist</span><span class="w"> </span><span class="kn">import</span> <span class="n">input_data</span>
</code></pre></div></p>
<p>As before, we can import the data directly from the TensorFlow library:
<div class="highlight"><pre><span></span><code><span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s1">&#39;MNIST_data&#39;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></p>
<p>Next, we can start to build the encoder. We're going to be utilizing the same <code>tf.layers</code> package as we did before. Here, our encoder will look fairly similar to how it did in the previous example, our layers will take in an input and gradually compress that input until we generate a latent distribution, <em>z</em>:
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>

    <span class="n">hidden_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>

    <span class="n">hidden_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">hidden_1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
</code></pre></div></p>
<p>Here's where we start to diverge from the standard autoencoder, however. While the last layer in the encoder will give us the potential z-distribution that represents our data, we'll need to calculate the values of $\mu$ and $\sigma$ that will help define that distribution. We can do that by creating two new layers that take in the potential distribution z, and output out values of <code>mu</code> and <code>sigma</code>:
<div class="highlight"><pre><span></span><code><span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  
<span class="n">sigma</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</code></pre></div></p>
<p>Next, we'll use these values to go ahead and calculate the KL divergence for the encoder, which will eventually go into constructing our final loss function:
<div class="highlight"><pre><span></span><code><span class="n">kl_div</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">sigma</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  

<span class="n">kl_div</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">latent_loss</span><span class="p">)</span>
</code></pre></div></p>
<p>Let's go ahead and create the decoder portion of the variational autoencoder now; we'll create a deconvolutional pattern that reverses the dimensions of the encoder. All of this will be contained under the function below:
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">initializer</span><span class="p">):</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">z</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;dec_l1&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span> 
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">layer_1</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;dec_l2&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
    <span class="n">layer_3</span> <span class="o">=</span> <span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">layer_2</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;dec_l3&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
    <span class="n">dec_out</span> <span class="o">=</span> <span class="n">fully_connected</span><span class="p">(</span>
        <span class="n">layer_3</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;dec_l4&#39;</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">)</span>
</code></pre></div></p>
<p>Also under the decoder function, we'll use the decoder output to calculate the reconstruction loss:
<div class="highlight"><pre><span></span><code><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-10</span>  

<span class="n">rec_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">epsilon</span> <span class="o">+</span> <span class="n">dec_out</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">epsilon</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dec_out</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  

<span class="n">rec_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">rec_loss</span><span class="p">)</span>
</code></pre></div></p>
<p>As usual, we'll prepare our training parameters before we start initializing the model. We'll define a learning rate, batch size for our training, the number of training epochs, dimension of the input, and the size of our total training sample:
<div class="highlight"><pre><span></span><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-4</span>  
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>  
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>  
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">784</span>   
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">55000</span>  
<span class="n">n_z</span> <span class="o">=</span> <span class="mi">10</span>
</code></pre></div></p>
<p>We'll also define the placeholder for our input data, x:
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">])</span>
</code></pre></div></p>
<p>Before we start training, we'll initialize the model, loss, and optimizer:
<div class="highlight"><pre><span></span><code><span class="c1">## initialize the models  </span>
<span class="n">z</span><span class="p">,</span> <span class="n">kl_div</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  
<span class="n">dec_out</span><span class="p">,</span> <span class="n">rec_loss</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  

<span class="c1">## Calculate the overall model loss term  </span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">rec_loss</span> <span class="o">+</span> <span class="n">kl_div</span><span class="p">)</span>  

<span class="c1">## Create the optimizer  </span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>  

<span class="c1">## Create the weight initializer  </span>
<span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()</span>
</code></pre></div></p>
<p>Finally, we can run the actual training process. This we be similar to the training processes that we've already built and experienced:
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">rl</span><span class="p">,</span> <span class="n">ll</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">rec_loss</span><span class="p">,</span> <span class="n">kl_div</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">batch_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]})</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[Epoch </span><span class="si">{}</span><span class="s1">] Total Loss: </span><span class="si">{}</span><span class="s1">, Reconstruction Loss: </span><span class="si">{}</span><span class="s1">, Latent Loss: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">rl</span><span class="p">,</span> <span class="n">ll</span><span class="p">))</span>
</code></pre></div></p>
<p>Lastly, we can use the bit of code following code to generate new samples from our newly trained model:
<div class="highlight"><pre><span></span><code><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_z</span><span class="p">])</span>  
<span class="n">x_generated</span> <span class="o">=</span> <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">dec_out</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">z</span><span class="p">:</span> <span class="n">z</span><span class="p">})</span>  

<span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>  
<span class="n">I_generated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">h</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="n">n</span><span class="p">))</span>  
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>  
        <span class="n">I_generated</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">h</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">h</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="n">w</span><span class="p">:(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">x_generated</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="n">n</span><span class="o">+</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>  

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>  
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_generated</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</code></pre></div></p>
<p>Ultimately, you should end up with an image such as the following, with the original digits on the left and the generated digits on the right. Observe how much clearer the digits are compared to the original autoencoder. Now, let's see how we can take this further with GANs. </p>
<h2 id="generative-adversarial-networks-gan">Generative adversarial networks (GAN)</h2>
<h3 id="overview_1">Overview</h3>
<p>Generative adversarial networks (<strong>GANs</strong>) are a class of networks that were introduced by Ian Goodfellow in 2014. In GANs, two neural networks play off against one another as adversaries in an <strong>actor</strong>-<strong>critic model</strong>, where one is the creator and the other is the scrutinizer. The creator, referred to as the <strong>generator network</strong>, tries to create samples that will fool the scrutinizer, the discriminator network. These two increasingly play off against one another, with the generator network creating increasingly believable samples and the discriminator network getting increasingly good at spotting the samples. In summary:</p>
<ul>
<li>The generator tries to maximize the probability of the discriminator passing its outputs as real, not generated</li>
<li>The discriminator guides the generator to create ever more realistic samples</li>
</ul>
<p>All in all, this process is represented as follows:
!pasted-image-20241231150923.png.md</p>
<p>GANs can be used for a variety of tasks, and, in recent years, many GAN varieties have been created. As they were originally built for image-related tasks, we will focus our architecture discussions on image-based GANs. A larger list of GANs is available at the end of the section. Throughout, we'll follow along in TensorFlow to illuminate the topics. As before, we'll be utilizing the same MNIST data in order to compare the frameworks with our previous ones:
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>  
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.examples.tutorials.mnist</span><span class="w"> </span><span class="kn">import</span> <span class="n">input_data</span>  
<span class="n">mnist</span> <span class="o">=</span> <span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span><span class="s2">&quot;MNIST_data/&quot;</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  
<span class="n">training_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="mf">0.5</span>
</code></pre></div></p>
<p>With that, let's walk through the pieces of the network one at a time. By this point, you should be pretty familiar with this process in TensorFlow.</p>
<h3 id="discriminator-network">Discriminator network</h3>
<p>The discriminator network in image-related GANs is a standard convolutional neural network. It takes in an image and outputs a single number that tells us whether the image is <em>real</em> or <em>fake</em>. The discriminator takes in an image, and learns the attributes of that image so that it may be a good <em>judge</em> vis-à-vis the outputs of the generator. In TensorFlow, we can create the <code>discriminator</code> as a function that we will then run in a TensorFlow session later on. This framework is more or less the same as you've seen in the previous sections with autoencoder and variational autoencoders; we'll use the higher level <code>tf.layers</code> api to create three main network layers and an output layer. After each of the main network layers, we'll add a dropout layer for regularization. The last layer will be slightly different, as we'll want to squash the output. For this, we'll use a sigmoid activation function that will give us a final output saying if an image is believed to be fake or not:
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">discriminator</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">):</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>
    <span class="n">dropout_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">dropout_1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;disc_layer_1&#39;</span><span class="p">)</span>
    <span class="n">dropout_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">layer_2</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">layer_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">dropout_2</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;disc_layer_2&#39;</span><span class="p">)</span>
    <span class="n">dropout_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">layer_3</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">dropout_3</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;disc_output&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_layer</span>
</code></pre></div></p>
<p>Now that we have this discriminator defined, let's go ahead and move on to the generator.</p>
<h3 id="generator-network">Generator network</h3>
<p>You can think of the <code>generator</code> portion of the GAN as a reverse convolutional neural network. Like a VAE, it uses generic normal distribution, the only difference being that it up samples the distribution to form an image. This distribution represents our prior, and is updated during training as the GAN improves at producing images that the discriminator is unable to determine whether they are fake.</p>
<p>In between each layer, we utilize a <code>ReLu</code> activation function and <code>batch_normalization</code> to stabilize each layer's outputs. As the discriminator starts inspecting the outputs of <code>generator</code>, <code>generator</code> will continually adjust the distribution from which it's drawing to closely match the target distribution. The code will look fairly familiar to what you've seen in previous sections:
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generator</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initializer</span><span class="p">):</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input_layer&#39;</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">layer_1</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden_layer_1&#39;</span><span class="p">)</span>
    <span class="n">layer_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">layer_2</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hidden_layer_2&#39;</span><span class="p">)</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span>
        <span class="n">layer_3</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">bias_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;generator_output&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_layer</span>
</code></pre></div></p>
<p>Now that we have our model set up, let's get into the training process!</p>
<h3 id="training-gans">Training GANs</h3>
<p>GANs are easy to train, but difficult to optimize due to a number of unstable dynamics in their training processes. To train a GAN, we train the generator on sub samples of a high-dimensional training distribution; since this does not innately exist, we initially sample from a standard normal (Gaussian) distribution.</p>
<p>!pasted-image-20241231152334.png.md</p>
<p>When training GANs, we train to minimize the objective function so that the generator can win. We want the generator to be able to create examples that are realistic enough to fool the discriminator. To do this, we train and optimize the discriminator and the generator in parallel using gradient ascent. For each iteration of training, we are going to train the discriminator network in small batches, and then train the generator network in small batches, alternating between the two paradigms. Gradient ascent for the discriminator computes the following:
!pasted-image-20241231152415.png.md</p>
<p>By taking the maximum of the generator's objective, we're maximizing the likelihood of being wrong. This parallelized training process can still be unstable, however, and stabilizing GANs is a very active area of research at the moment.</p>
<p>Let's get back to the TensorFlow process. We'll start by defining our network's training parameters:
<div class="highlight"><pre><span></span><code><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0002</span>  
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>  
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>  
<span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span>
</code></pre></div></p>
<p>We then need to define our placeholders, both for the input <code>x</code>, as well as the <code>z</code> distribution which the generator will generate from:
<div class="highlight"><pre><span></span><code><span class="n">z</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>  
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
</code></pre></div></p>
<p>Like before, we'll create a Glorot <code>Initializer</code> that will initialize our weight and bias values for us:
<div class="highlight"><pre><span></span><code><span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">()</span>
</code></pre></div></p>
<p>Once we have all of this, we can go ahead and actually define our network pieces. You'll notice that for the discriminator, we're using something called a scope. Scopes allow us to reuse items from the TensorFlow graph without generating an error - in this case, we want to use the variables from the discriminator function twice in a row, so we use the <code>tf.variable_scope</code> function that TensorFlow provides us. Between the two, we simply use the <code>scope.reuse_variables()</code> function to tell TensorFlow what we're doing:
<div class="highlight"><pre><span></span><code><span class="n">G</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">initializer</span><span class="p">)</span>  

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;discriminator_scope&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>  
    <span class="n">disc_real</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>  
    <span class="n">scope</span><span class="o">.</span><span class="n">reuse_variables</span><span class="p">()</span>  
    <span class="n">disc_fake</span> <span class="o">=</span> <span class="n">discriminator</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">initializer</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></p>
<p>Lastly, we'll define the loss functions for both the generator and discriminator, and set the optimizer:
<div class="highlight"><pre><span></span><code><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-2</span>  
<span class="n">disc_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">disc_real</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">disc_fake</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>  
<span class="n">gen_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">disc_fake</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">))</span>  

<span class="n">disc_optim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">disc_loss</span><span class="p">)</span>  
<span class="n">gen_optim</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">gen_loss</span><span class="p">)</span>
</code></pre></div></p>
<p>We can the run the training cycle just as we have in the previous two examples. The only two differences you'll see here is that we run two optimization processes, one for the generator and one for the discriminator:
<div class="highlight"><pre><span></span><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>  
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>   
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>  

        <span class="c1">## Define the loss to update as a list  </span>
        <span class="n">gen_loss</span> <span class="o">=</span> <span class="p">[]</span>  
        <span class="n">disc_loss</span> <span class="o">=</span> <span class="p">[]</span>  

        <span class="c1">## Run the training iteration  </span>
        <span class="k">for</span> <span class="nb">iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">):</span>  

            <span class="c1">## Batch the input for the discriminator  </span>
            <span class="n">x_prime</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="nb">iter</span><span class="o">*</span><span class="n">batch_size</span><span class="p">:(</span><span class="nb">iter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span><span class="p">]</span>  
            <span class="n">z_prime</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>  

            <span class="c1">## Run the discriminator session  </span>
            <span class="n">_</span><span class="p">,</span> <span class="n">DLoss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">disc_optim</span><span class="p">,</span> <span class="n">disc_loss</span><span class="p">],</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">x_prime</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">z_prime</span><span class="p">,</span> <span class="n">drop_out</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>  
            <span class="n">disc_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DLoss</span><span class="p">)</span>  

            <span class="c1">## Run the generator session   </span>
            <span class="n">z_prime</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>  
            <span class="n">_</span><span class="p">,</span> <span class="n">GLoss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">gen_optim</span><span class="p">,</span> <span class="n">gen_loss</span><span class="p">],</span> <span class="p">{</span><span class="n">z</span><span class="p">:</span> <span class="n">z_prime</span><span class="p">,</span> <span class="n">drop_out</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>  
            <span class="n">gen_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GLoss</span><span class="p">)</span>  

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">] - loss_d: </span><span class="si">%.3f</span><span class="s1">, loss_g: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">D_losses</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">G_losses</span><span class="p">)))</span>
</code></pre></div></p>
<p>GANs are fairly computational expensive, so training this network may take a while unless you scale with a web services platform. </p>
<p>As you can see, all of the models that we've run thus far have built upon each other. Even with advanced generative models like GANs, we can use certain recipes to create powerful neural networks, and larger AI applications, quickly and efficiently.</p>
<h2 id="other-forms-of-generative-models">Other forms of generative models</h2>
<h3 id="overview_2">Overview</h3>
<p>While we've only covered two types of generative model, there are many different types that you may encounter in the literature. The following chart is not exhaustive, but does provide a general overview of the types of generative models out there:
!pasted-image-20241231152903.png.md</p>
<p>Let's break this down: 
- <strong>Explicit density models</strong>: Model our data directly from a probability distribution. We explicitly define the probability and solve for it
- <strong>Implicit density models</strong>: Learn to sample from a probability distribution without defining what that distribution is</p>
<p>Within explicit density models, we have <strong>tractable density</strong> models and <strong>approximate density</strong> models. Here, tractable is related to defined computational time; we can calculate the computational complexity of a tractable problem. Approximate density relates to <strong>intractability</strong>—a computer science term that means that there is no defined computational time or algorithm. In practice, an intractable problem utilizes too many computational resources in order to be useful. Therefore, approximate density models use probabilistic approximation techniques to estimate the solution.</p>
<p>We'll briefly touch upon three notable classes: fully visible belief nets, Hidden Markov models, and Boltzmann machines. While each of these could be a chapter on its own, we'll touch on them briefly. Examples of each of these networks in Python are available in the code accompanying this chapter.</p>
<h3 id="fully-visible-belief-nets">Fully visible belief nets</h3>
<p>Fully visible belief networks are a class of explicit density models and a form of deep belief network. They use the chain rule to decompose a probability distribution $p(x)$ over a vector, into a product over each of the members of the vector, represented between by $p(x_i | x_1, \dots)$. All together, it's formula is:
!pasted-image-20241231153111.png.md</p>
<p>The most popular model in this family is PixelCNN, an <strong>autoregressive</strong> generative model. Pixels approach image generation problems by turning them into a sequence modeling problem, where the next pixel value is determined by all the previously generated pixel values. The network scans an image one pixel at a time, and predicts conditional distributions over the possible pixel values. We want to assign a probability to every pixel image based on the last pixels that the network saw. For instance, if we're looking at the same horse images as in the previous example, we would be consistently predicting what the next anticipated pixel looks such as follows:
!pasted-image-20241231153143.png.md</p>
<p>Based on the features that we've seen, will the next pixel still contain the horse's ear, or will it be background? While their training cycles are more stable than GANs, the biggest issue with the networks is that they generate new samples extremely slowly; the model must be run again fully in order to generate a new sample. They also block the execution, meaning that their processes cannot be run in parallel.</p>
<h3 id="hidden-markov-models">Hidden Markov models</h3>
<p>A hidden Markov model is a type of <strong>Markov model</strong>, which is itself a subclass of <strong>Dynamic Bayesian Networks</strong>. Markov models are used to model randomly changing systems called <strong>Markov processes</strong> also called <strong>Markov chains</strong>. Simply put, a Markov process is a sequence of events where the probability of an event happening solely depends on the previous event.</p>
<p>Markov chains appear as follows:
!pasted-image-20241231153404.png.md</p>
<p>In this simple chain, there are three states, represented by the circles. We then have probabilities for transitioning to another state, as well as probabilities of staying in a current state. The classic example of a Markov chain is that of the taxi driver, where the driver finds himself currently solely depends on where he was last, in other words, his most recent fare. If we were to apply this example to the preceding Markov chain, the driver would have three possible locations to pick up or drop off customers; the associated probabilities between locations would represent the chance of him going to the other location or staying put.</p>
<p>Hidden Markov models are used to model Markov processes that we can't observe; what if the driver's route structure of where he would like to pick up customers is secret? There is likely some logic to the scenario, and we can try and model that process with a Hidden Markov model.</p>
<h3 id="boltzmann-machines">Boltzmann machines</h3>
<p>Boltzmann machines are a general class of models that contain take binary vectors as input and units that assign a probability distribution to each of those binary vectors. As you can see in the following diagram, each unit is dependent on every other unit:
!pasted-image-20241231153508.png.md</p>
<p>A Boltzmann machine uses something called an <strong>energy function</strong>, which is similar to a loss function. For any given vector, the probability of a particular state is proportional to each of the energy function values. To convert this to an actual probability distribution, it's necessary to renormalize the distribution, but this problem becomes another intractable problem. Monte Carlo methods are again used here for sampling as a workaround, hence making Boltzmann machines a Monte Carlo-based method.</p>
<p>Let's say we have documents that are represented by binary features. A Boltzmann machine can help us determine whether a particular word or phrase came from a particular document. We can also use Boltzmann machines for anomaly detection in large, complex systems. They work well up to a point, although this method does not work well in high dimensional spaces.</p>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.sections", "navigation.top", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>