---
published: true
---

- **Definition**: Evaluate R & G outputs.

- **Subclasses**:

  - **Context Relevance**

    - *Definition*: Degree of alignment between Q & retrieved context.

    - *Metrics*: Precision, Recall.

    - *Evaluated By*: Human annotation, semantic similarity, frameworks.

  - **Answer Faithfulness** (Groundedness)

    - *Definition*: Degree to which generated answer is factually supported by retrieved context.

    - *Inverse Metric*: Hallucination Rate.

    - *Related Metric*: Coverage (how much retrieved info appears in the answer).

  - **Answer Relevance**

    - *Definition*: How well the answer addresses the query semantically.

    - *Metric Type*: Similarity-based (e.g., cosine similarity of synthetic vs. original questions).

- **Relations**:

  - `influences` → Frameworks

  - `depends_on` → R & G Components