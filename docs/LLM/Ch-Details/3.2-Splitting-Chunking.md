---
published: true
---

## 3.2 Data splitting (chunking)
load --> *split* --> embed --> store

Tokens

- **are**: the fundamental semantic units used in NLP

- OpenAI suggests one token to be made of four characters or 0.75 words

 **chunking advantages**:

- *Context window of LLMs*

- *Lost-in-the-middle problem*

- *Ease of search*

**chunking process**: “small to big”:

1. **Divide**: Long text --> compact units (eg sentences)

2. **Merge**: Units --> larger chunks

3. **Overlap**: Maintain overlap for context continuity

**chunking methods**

1. **Fixed-size**: use a special character or list of characters

2. **Specialized**: use h tags, key-value pairs, etc

3. **Semantic**: group sentences together based on semantic similarity

| Method      | how it works                      | use when             | weakness          |
| ----------- | --------------------------------- | -------------------- | ----------------- |
| Fixed-size  | predetermined (uniform + overlap) | uniform data         | ignores semantics |
| Specialized | based on source structure         | html, md, json, code | ignores semantics |
| Semantic    | based on semantic similarity      | need semantics       | experimental      |

**chunking methods** | considerations:

1. **Nature of the content** (use different method per sources if need)

2. **Expected length & complexity of queries**

3. **Use case reqs** (short chunks for Q&A, long chunks for summarization)

4. **Embeddings model**