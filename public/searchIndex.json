[{"title":"2.1 What Makes GPT‑4o & Llama 3 Tick (High Level)","tags":[],"path":"/2.1 What Makes GPT‑4o & Llama 3 Tick (High Level)","body":"\nResources\n- [ChatGPT](https://chatgpt.com/share/68179857-6608-8000-b571-8416b4c244a4): For this document.\n\n### Overview\n\n```ad-sam\nGPT‑4o (OpenAI) and LLaMA 3 (Meta) represent two of the most advanced LLMs currently available. \nBoth models follow the **transformer** architecture but differ in design philosophy, training data, and usage priorities.\n\n- **GPT‑4o** is optimized for commercial-scale AI applications with cutting-edge multimodal reasoning\n- **LLaMA 3** is designed for flexible research & local deployment. \n\n```\n\n\n```ad-sam\nDistinct approaches in openness, specialization, and end-use design.\n\n| FEATURE | Developer | Multimodal | Open Source          | Max Model Size | Inference           | Fine-tuning         | Use Cases                |\n| ------- | --------- | ---------- | -------------------- | -------------- | ------------------- | ------------------- | ------------------------ |\n| GPT‑4o  | OpenAI    | Yes        | No                   | Not disclosed  | Cloud-first         | Proprietary methods | ChatGPT, Copilot         |\n| LLAMA 3 | Meta      | No         | Yes (non-commercial) | 70B            | Local & Cloud-ready | LoRA / QLoRA (open) | Research, OSS assistants |\n\n\n- **Multimodal** means the model can understand and generate _multiple types of input and output_, such as **text/image/audio**\n\n\n```\n\n---\n### Same\n```ad-sam\n- **Transformer**: Both use the transformer decoder stack with self-attention and feedforward layers.\n- **Pretraining Objective**: Trained using next-token prediction on massive datasets.\n- **Tokenization**: Use byte pair encoding (BPE) or variants.\n- **Inference Mode**: Both support autoregressive text generation, often used in chat-based applications.\n```\n\n### Differences\n#### GPT‑4o\n```ad-sam\n- **Multimodal**: GPT‑4o is natively multimodal—trained to process text, audio, image, and video in a unified model.\n- **Training Emphasis**: Heavy focus on aligning model outputs with human preferences via reinforcement learning from human feedback (RLHF).\n- **Usage Context**: Best in class for general-purpose, multilingual, and reasoning-heavy tasks.\n- **Deployment**: Used in OpenAI’s commercial products (ChatGPT, Copilot).\n```\n\n#### LLaMA 3\n```ad-sam\n- **Open-Weight**: LLaMA 3 is released under a non-commercial license, enabling researchers to experiment and deploy with fewer constraints.\n- **Variants**: Released in sizes like 8B and 70B, with a focus on efficiency and open availability.\n- **Training Data**: Trained on 15T+ tokens, including public web data (filtered), books, code, and academic sources.\n- **Specialization**: Emphasizes interpretability and community fine-tuning via LoRA and QLoRA.\n```\n"},{"title":"3Blue1Brown - GPT","tags":[],"path":"/AI/3Blue1Brown - GPT","body":"\n```ad-sam\nGPT = Generative Pre-trained Transformer\n- **Generative**: Create new text\n- **Pre-trained**: How the model learned\n- **Transformer**: Specific kind of NN, core invention underlying current boom in AI\n```\n\n\n\"Attention is all you need\" came from Google in 2017. \n- Specific use-case was to translate text.\n- Our use-case is to predict the next word.\n\n\n```ad-sam\nHow data flows through a transformer\n1. **Embedding**\n2. **Attention**\n3. **MLPs**\n4. **Un-embedding**\n```\n\n\n\nDeep Learning describes a *class* of models that scale very well. (Includes **Transformers**, MLPs, CNNs, and more.)\n- The *training* algorithm is called backpropagation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"ChatGPT Need to know guide","tags":[],"path":"/AI/ChatGPT Need to know guide","body":"\n[ChatGPT](https://chatgpt.com/share/66e5b5a3-57e8-8000-9151-5a656753b002)  --> [ChatGPT resources](https://chatgpt.com/share/66e5b780-a5f4-8000-91dc-6488ed81f01d)\n\nHere's a guide to the key linear algebra concepts you’ll need for machine learning. This will give you a refresher with an emphasis on practical use cases relevant to data science.\n\n### Linear Algebra Concepts for Machine Learning\n\n#### 1. **Vectors and Vector Operations**\n\n- **Definition of a Vector**: Data as vectors, representing points in multi-dimensional space.\n- **Vector Addition and Scalar Multiplication**: Basics of manipulating vectors.\n- **Norms**: Magnitude of vectors, including the L1 and L2 norms (used in regularization).\n- **Dot Product**: Essential for projections and angle measurements between vectors.\n- **Cross Product**: Relevant in 3D spaces but less common in typical machine learning tasks.\n\n\n#### 2. **Matrices and Matrix Operations**\n\n- **Matrix Definition and Notation**: Understanding rows, columns, and types of matrices (square, rectangular, etc.).\n- **Matrix Addition and Scalar Multiplication**: Extending vector operations to matrices.\n- **Matrix Multiplication**: How to combine data transformations or operations.\n- **Transpose of a Matrix**: Used in various algorithms like PCA and least-squares regression.\n\n#### 3. **Matrix Inverses and Determinants**\n\n- **Matrix Inversion**: How to solve linear systems (e.g., linear regression) and understanding singular matrices.\n- **Determinant**: Its significance in matrix invertibility and the geometry of transformations.\n- **Pseudo-Inverse**: Important for handling non-invertible matrices, especially in least-squares solutions.\n\n#### 4. **Eigenvalues and Eigenvectors**\n\n- **Definition**: Key to understanding dimensionality reduction and covariance matrices.\n- **Principal Component Analysis (PCA)**: How eigenvectors and eigenvalues are used in reducing dimensions and extracting features.\n\n#### 5. **Singular Value Decomposition (SVD)**\n\n- **Definition**: Factorization of a matrix, which is used in tasks like dimensionality reduction, noise reduction, and matrix approximation.\n- **Connection to PCA**: SVD can be used to compute the principal components.\n\n#### 6. **Orthogonality and Orthonormality**\n\n- **Orthogonal Vectors and Matrices**: Importance in machine learning algorithms for ensuring no overlap between components (e.g., in PCA).\n- **Gram-Schmidt Process**: Method for orthonormalizing a set of vectors, used in various algorithms.\n\n#### 7. **Projections**\n\n- **Projection onto Subspaces**: Key for least-squares regression and understanding hyperplanes in higher-dimensional spaces.\n- **Orthogonal Projections**: Used in regression, PCA, and more.\n\n#### 8. **Linear Transformations**\n\n- **Definition**: How matrices can be seen as linear transformations applied to data vectors.\n- **Interpretation of Matrix Multiplication as a Transformation**: E.g., rotation, scaling, and shearing.\n- **Rank**: The rank of a matrix helps you understand the dimensionality of the data after a transformation.\n\n#### 9. **Vector Spaces**\n\n- **Basis and Span**: Understanding the dimension of data space and how to work with reduced dimensions.\n- **Linear Independence**: Why it's crucial to avoid redundant features or transformations.\n\n#### 10. **Systems of Linear Equations**\n\n- **Solving Linear Systems**: Essential in optimization tasks and linear models.\n- **Row Reduction and Gaussian Elimination**: Helps in solving systems and finding matrix inverses.\n\n#### 11. **Positive Definite Matrices**\n\n- **Definition**: Important in optimization, especially for convex functions and ensuring minimums in certain algorithms like gradient descent.\n\n#### 12. **Norms and Condition Numbers**\n\n- **Matrix Norms**: Important in measuring the size of a matrix (or its effect on vectors).\n- **Condition Number**: Helps in understanding the sensitivity of a system to changes in input.\n\n#### 13. **Tensor Operations**\n\n- **Tensors and Tensor Algebra**: Useful for deep learning when handling multi-dimensional data.\n- **Tensor Decomposition**: Analogous to SVD for higher-order matrices.\n\n---\n\nThis guide should help you revisit key linear algebra concepts and how they are applied in machine learning, from basic matrix operations to more advanced topics like SVD and eigenvectors. Would you like more detailed resources or examples on any of these topics?\n"},{"title":"Generative Models","tags":["ai_"],"path":"/AI/Generative Models","body":"\n```ad-sam\nNote to self (2024-12-31): With the exception of the first few paragraphs, the rest of this is just copied & pasted from the textbook.\n```\n\n[Textbook | Oreilly](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/719394b6-6058-4ac6-89f3-c2ec26563e7a.xhtml)\n\n## Overview\n**Generative models** are enabling computers to have an understanding of the world. They are:\n- Unsupervised\n- Data generators\n\nWe'll focus on the two most popular types of models:\n- The **variational autoencoder** (**VAE**)\n- The **generative adversarial network** (**GAN**)\n- (Also touch upon other common generative models)\n\n## Summary (end of chapter)\nWe learned about **variational autoencoders** & **GANs**. \n- Each relies on condensing data --> generating from this condensed data.\n- Both are probabilistic models, meaning that they rely on inference from probability distributions in order to generate data\n\nWhen writing advanced models in TensorFlow, remember:\n- **Layers**: what kind you need\n- **Activation function**: what type you need\n- **Shape**: shape your data through the network\n- **Procedures**: for example, think choosing loss functions & optimizers\n\n\n## Getting to AI - generative models\nClasses of neural networks (goals):\n- **Discriminative models**: focus on learning boundaries or correlations between _inputs_ & _labels_. \n    - (e.g., typical feedforward nets, CNNs for classification, RNNs for sequence labeling)\n- **Generative models**: focus on modeling the underlying data _distribution_, allowing them to produce new (synthetic) data or fill in missing features given partial information. \n    - (e.g., **autoencoders**, **VAEs**, **GANs**)\n\n### Autoencoders (For Inspiration)\n\nSummarized in [[Ch 17 Autoencoders, GANs, and Diffusion Models#Autoencoders]]\n\n\n### Building an Autoencoder\n\nIf you're thinking that the task of reconstructing an output doesn't appear that useful, you're not alone. \n\nWhat exactly do we use these networks for? Autoencoders help to extract features when there are no known labeled features at hand. \n\nTo illustrate how this works, let's walk through an example using TensorFlow. We're going to reconstruct the MNIST dataset here, and, later on, we will compare the performance of the standard autoencoder against the variational autoencoder in relation to the same task.\n\nLet's get started with our imports and data. MNIST is contained natively within TensorFlow, so we can easily import it:\n```python\nimport tensorflow as tf  \nimport numpy as np  \n  \nfrom tensorflow.examples.tutorials.mnist import input_data  \nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n```\n\nFor ease, we can build the auto-encoder with the `tf.layers` library. We'll want our Autoencoder architecture to follow the convolutional/de-convolutional pattern, where the input layer of the decoder matches the size of the input and the subsequent layer squash the data into a smaller and smaller representation. The decoder will be the same architecture reversed, starting with the small representation and working larger.\n\nAll together, we want it to look something like the following:\n![[Pasted image 20241231144552.png]]\n\nLet's start with the encoder; we'll define an initializer for the the weight and bias factors first, and then define the encoder as a function that takes and input, x. we'll then use the `tf.layers.dense` function to create standard, fully connected neural network layers. The encoder will have three layers, with the first layer size matching the input dimensions of the input data (`784`), with the subsequent layers getting continually smaller:\n```python\ninitializer = tf.contrib.layers.xavier_initializer()  \ndef encoder(x): \n    input_layer = tf.layers.dense(\n        inputs=x, units=784, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    z_prime = tf.layers.dense(\n        inputs=input_layer, units=256, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    z = tf.layers.dense(\n        inputs=z_prime, units=128, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    return z\n```\n\nNext, let's let's build our decoder; it will be using the same layer type and initializer as the encoder, only now we invert the layers, so that the first layer of the decoder is the smallest and the last is the largest.\n```python\ndef decoder(x):  \n    x_prime_one = tf.layers.dense(\n        inputs=x, units=128, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    x_prime_two = tf.layers.dense(\n        inputs=x_prime_one, units=256, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    output_layer = tf.layers.dense(\n        inputs=x_prime_two, units=784, activation=tf.nn.relu,\n        kernel_initializer=initializer, bias_initializer=initializer)  \n    return output_layer\n```\n\nBefore we get to training, let's define some hyper-parameters that will be needed during the training cycle. We'll define the size of our input, the learning rate, number of training steps, the batch size for the training cycle, as well as how often we want to display information about our training progress.\n```python\ninput_dim = 784   \nlearning_rate = 0.001  \nnum_steps = 1000  \nbatch_size = 256  \ndisplay = 1\n```\n\nWe'll then define the placeholder for our input data so that we can compile the model:\n```python\nx = tf.placeholder(\"float\", [None, input_dim])\n```\n\nAnd subsequently, we compile the model and the optimizer as you've seen before in previous chapter:\n```python\n# Construct the full autoencoder  \nz = encoder(x)  \n  \n## x_prime represents our predicted distribution  \nx_prime = decoder(z)   \n  \n# Define the loss function and the optimizer  \nloss = tf.reduce_mean(tf.pow(x - x_prime, 2))  \noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n```\n\nLastly, we'll code up the training cycle. By this point, most of this should be fairly familiar to you; start a TensorFlow session, and iterate over the epochs/batches, computing the loss and accuracy at each point:\n```python\nwith tf.Session() as sess:  \n    sess.run(tf.global_variables_initializer())  \n  \n    ## Training Loop  \n    for i in range(1, num_steps+1):  \n      \n        ## Feed Batches of MNIST Data  \n        batch_x, _ = mnist.train.next_batch(batch_size)  \n  \n        ## Run the Optimization Process  \n        _, l = sess.run([optimizer, loss], feed_dict={x: batch_x})  \n  \n        ## Display the loss at every 1000 out of 30,000 steps  \n        if i % display == 0 or i == 1:  \n            print('Step %i: Loss: %f' % (i, l))\n```\n\nFor this particular example, we'll add in a little something more to this process; a way to plot the reconstructed images alongside their original versions. Keep in mind that this code is still contained within the training session, just outside of the training loop:\n```python\nn = 4  \ncanvas_orig = np.empty((28 * n, 28 * n))  \ncanvas_recon = np.empty((28 * n, 28 * n))  \n\nfor i in range(n):  \n\n    batch_x, _ = mnist.test.next_batch(n)  \n\n    # Encode and decode each individual written digit  \n    g = sess.run(decoder, feed_dict={x: batch_x})  \n\n    # Display original images  \n    for j in range(n):  \n\n        # Draw the original digits  \n        canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch_x[j].reshape([28, 28])  \n\n    # Display reconstructed images  \n    for j in range(n):  \n\n        # Draw the reconstructed digits  \n        canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])  \n\n# Plot the original image vs the reconstructed images.   \nprint(\"Original Images\")  \nplt.figure(figsize=(n, n))  \nplt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")  \nplt.show()  \n\nprint(\"Reconstructed Images\")  \nplt.figure(figsize=(n, n))  \nplt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")  \nplt.show()\n```\n\nAfter training, you should end up with a result along the lines of the following, with the actual digits on the left, and the reconstructed digits on the right:\n![[Pasted image 20241231145350.png]]\n\nSo what have we done here? By training the autoencoder on unlabeled digits, we've done the following: \n- Learned the latent features of the dataset without having explicit labels\n- Successfully learned the distribution of the data and reconstructed the image from scratch, from that distribution\n\nNow, let's say that we wanted to take this further and generate or classify new digits that we haven't seen yet. To do this, we could remove the decoder and attach a classifier or generator network:\n![[Pasted image 20241231145424.png]]\n\nThe encoder therefore becomes a means of initializing a supervised training model. Standard autoencoders have been used in a variety of tasks. In the supplementary code for this chapter, we'll walk through an example where we utilize autoencoders for visual anomaly detection.\n\n\n## Variational autoencoders (VAE)\n\n### Overview\n**Variational autoencoders** (**VAEs**) are built on the idea of the standard autoencoder, and are powerful generative models and one of the most popular means of learning a complicated distribution in an unsupervised fashion. VAEs are **probabilistic models** rooted in Bayesian inference. A probabilistic model is exactly as it sounds:\n\n_Probabilistic models incorporate random variables and probability distributions into the model of an event or phenomenon._\n\nVAEs, and other generative models, are probabilistic in that they seek to learn a distribution that they utilize for subsequent sampling. While all generative models are probabilistic models, not all probabilistic models are generative models.\n\nThe probabilistic structure of VAEs comes into play with their encoders. Instead of building an encoder that outputs a single value to describe the input data, we want to learn the latent variables by generating a probability distribution for each of those variables. VAEs have a constraint on the encoding network that forces it to generate vectors that roughly follow a standard normal distribution. This is what makes VAEs unique: they generate from continuous space, which means that we can easily sample and interpret from that space. We'll see how this unique probabilistic structure helps us to overcome the limitations of standard autoencoders.\n\n### Structure\nLike standard autoencoders, VAEs utilize the same encoder/decoder framework, but, that aside, they are mathematically different from their namesake. VAEs take a probabilistic perspective in terms of guiding the network:\n![[Pasted image 20241231145555.png]]\n\nBoth our **encoder** and **decoder** networks are generating distributions from their input data. The encoder generates a distribution from its training data, **Z**, which then becomes the input distribution for the decoder. The decoder takes this distribution, **Z**, and tries to replicate the original distribution, **X**, from it.\n\n#### Encoder\nThe encoder generates its distribution by first defining its prior as a standard normal distribution. Then, during training, this distribution becomes updated, and the decoder can easily sample from this distribution later on. Both the encoder and the decoder are unique in terms of VAEs in that they output two vectors instead of one: a vector of means, _μ_, and another vector of standard deviation, _σ_. These help to define the limits for our generated distributions. Intuitively, the mean vector controls where the encoding of an input should be centered, while the standard deviation controls the extent to which the encoding may vary from the mean. This constraint on the encoder forces the network to learn a distribution, thereby taking it beyond the vanilla autoencoder that simply reconstructs its output.\n\n#### Decoder\nLike the standard autoencoder, the decoder in the VAE is a backward convolutional network, or a deconvolutional network. In processing the decoding, data is sampled from the generation stochastically (randomly), making the VAE one of the few models that can directly sample a probability distribution without a Markov chain Monte Carlo method. As a result of the stochastic generation process, the encoding that we generate from each pass will be a different representation of the data, all while maintaining the same mean and standard deviation. This helps with the decoder's sampling technique; because all encodings are generated from the same distribution, the decoder learns that a latent data point and its surrounding points are all members of the same class. This allows the decoder to learn how to generate from similar, but slightly varying, encodings.\n\n#### Training and optimizing VAEs\nVAEs utilize a negative log-likelihood loss as their reconstruction loss to measure how much information is lost during the reconstruction phase of the decoder. If the decoder does not reconstruct the input satisfactorily, it will incur a large reconstruction loss. VAEs also introduce something called **Kullback**–**Leibler** (**KL**) divergence into their loss functions. KL divergence simply measures how much two probability distributions diverge; in other words, how different they are from one another. We want to minimize the KL distance between the mean and standard deviation of the target distribution and that of a standard normal. It is properly minimized when the mean is zero and the standard deviation is one. The log-likelihood loss with KL divergence forms the complete loss function for VAEs.\n\nWhen training VAEs, there is an implicit trade-off between the accuracy of the model and how close it can model the normal distribution. On its own, KL loss results in encoded data that is densely clustered near the center of the distribution, with little iteration with other potentially similar encoded data. A decoder wouldn't be able to decode anything from the space, because it wouldn't be particularly continuous! By combining the losses and optimizing them, we are able to preserve the dense nature of encoded data created by the KL loss function, as well as the clustered data produced by the reconstruction loss. What we then end up with are tight clusters that are easy for the decoder to work with. We wanted our generated distribution Z to resemble a standard normal distribution as closely as possible, and the more efficiently we can encode the original image, the closer we can push the standard deviation of the generated distribution toward one, the standard deviation of the targeted normal distribution.\n\n#### Utilizing a VAE\nWe can construct a variational autoencoder in TensorFlow to see how it compares to it's simpler, standard autoencoder cousin. In this section, we'll be using the same MNIST dataset so that we can standardize our comparison across methods. Let's walk through how to construct a VAE by utilizing it to generate handwriting based on the MNIST dataset. Think of _x_ as being the individual written characters and _z_ as the latent features in each of the individual characters that we are trying to learn.\n\nFirst, let's start with our imports:\n```python\nimport numpy as np  \nimport tensorflow as tf  \nfrom tensorflow.examples.tutorials.mnist import input_data\n```\n\nAs before, we can import the data directly from the TensorFlow library:\n```python\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n```\n\nNext, we can start to build the encoder. We're going to be utilizing the same `tf.layers` package as we did before. Here, our encoder will look fairly similar to how it did in the previous example, our layers will take in an input and gradually compress that input until we generate a latent distribution, _z_:\n```python\ndef encoder(x):\n    input_layer = tf.layers.dense(\n        inputs=x, units=784, activation=tf.nn.elu,\n        kernel_initializer=initializer, bias_initializer=initializer,name='input_layer')\n        \n    hidden_1 = tf.layers.dense(\n        inputs=input_layer, units=256, activation=tf.nn.elu,\n        kernel_initializer=initializer, bias_initializer=initializer)\n    \n    hidden_2 = tf.layers.dense(\n        inputs=hidden_1, units=128, activation=tf.nn.elu,\n        kernel_initializer=initializer, bias_initializer=initializer)\n```\n\nHere's where we start to diverge from the standard autoencoder, however. While the last layer in the encoder will give us the potential z-distribution that represents our data, we'll need to calculate the values of $\\mu$ and $\\sigma$ that will help define that distribution. We can do that by creating two new layers that take in the potential distribution z, and output out values of `mu` and `sigma`:\n```python\nmu = tf.layers.dense(inputs=z, units=10, activation=None)  \nsigma = tf.layers.dense(inputs=z, units=10, activation=None)\n```\n\nNext, we'll use these values to go ahead and calculate the KL divergence for the encoder, which will eventually go into constructing our final loss function:\n```python\nkl_div = -0.5 * tf.reduce_sum( 1 + sigma - tf.square(mu) - tf.exp(sigma), axis=1)  \n  \nkl_div = tf.reduce_mean(latent_loss)\n```\n\nLet's go ahead and create the decoder portion of the variational autoencoder now; we'll create a deconvolutional pattern that reverses the dimensions of the encoder. All of this will be contained under the function below:\n```python\ndef decoder(z, initializer):\n    layer_1 = fully_connected(\n        z, 256, scope='dec_l1', activation_fn=tf.nn.elu, \n        kernel_initializer=initializer, bias_initializer=initializer)\n    layer_2 = fully_connected(\n        layer_1, 384, scope='dec_l2', activation_fn=tf.nn.elu,\n        kernel_initializer=initializer, bias_initializer=initializer)\n    layer_3 = fully_connected(\n        layer_2, 512, scope='dec_l3', activation_fn=tf.nn.elu,\n        kernel_initializer=initializer, bias_initializer=initializer)\n    dec_out = fully_connected(\n        layer_3, input_dim, scope='dec_l4', activation_fn=tf.sigmoid,\n        kernel_initializer=initializer, bias_initializer=initializer)\n```\n\nAlso under the decoder function, we'll use the decoder output to calculate the reconstruction loss:\n```python\nepsilon = 1e-10  \n  \nrec_loss = -tf.reduce_sum(x * tf.log(epsilon + dec_out) + (1 - x) * tf.log(epsilon + 1 - dec_out), axis=1)  \n  \nrec_loss = tf.reduce_mean(rec_loss)\n```\n\nAs usual, we'll prepare our training parameters before we start initializing the model. We'll define a learning rate, batch size for our training, the number of training epochs, dimension of the input, and the size of our total training sample:\n```python\nlearning_rate = 1e-4  \nbatch_size = 100  \nepochs = 100  \ninput_dim = 784   \nnum_sample = 55000  \nn_z = 10\n```\n\nWe'll also define the placeholder for our input data, x:\n```python\nx = tf.placeholder(name='x', dtype='float', shape=[None, input_dim])\n```\n\nBefore we start training, we'll initialize the model, loss, and optimizer:\n```python\n## initialize the models  \nz, kl_div = encoder(x)  \ndec_out, rec_loss = decoder(x)  \n  \n## Calculate the overall model loss term  \nloss = tf.reduce_mean(rec_loss + kl_div)  \n  \n## Create the optimizer  \noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)  \n  \n## Create the weight initializer  \ninitializer = tf.contrib.layers.xavier_initializer()\n```\n\nFinally, we can run the actual training process. This we be similar to the training processes that we've already built and experienced:\n```python\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(epochs):\n        for iter in range(num_sample // batch_size):\n            batch_x = mnist.train.next_batch(batch_size)\n            _, l, rl, ll = sess.run([optimizer, loss, rec_loss, kl_div], feed_dict={x: batch_x[0]})\n\n        if epoch % 5 == 0:\n            print('[Epoch {}] Total Loss: {}, Reconstruction Loss: {}, Latent Loss: {}'.format(epoch, l, rl, ll))\n```\n\nLastly, we can use the bit of code following code to generate new samples from our newly trained model:\n```python\nz = np.random.normal(size=[batch_size, n_z])  \nx_generated = x_hat = self.sess.run(dec_out, feed_dict={z: z})  \n  \nn = np.sqrt(batch_size).astype(np.int32)  \nI_generated = np.empty((h*n, w*n))  \nfor i in range(n):  \n    for j in range(n):  \n        I_generated[i*h:(i+1)*h, j*w:(j+1)*w] = x_generated[i*n+j, :].reshape(28, 28)  \n  \nplt.figure(figsize=(8, 8))  \nplt.imshow(I_generated, cmap='gray')\n```\n\nUltimately, you should end up with an image such as the following, with the original digits on the left and the generated digits on the right. Observe how much clearer the digits are compared to the original autoencoder. Now, let's see how we can take this further with GANs. \n\n\n\n\n## Generative adversarial networks (GAN)\n\n### Overview\nGenerative adversarial networks (**GANs**) are a class of networks that were introduced by Ian Goodfellow in 2014. In GANs, two neural networks play off against one another as adversaries in an **actor**-**critic model**, where one is the creator and the other is the scrutinizer. The creator, referred to as the **generator network**, tries to create samples that will fool the scrutinizer, the discriminator network. These two increasingly play off against one another, with the generator network creating increasingly believable samples and the discriminator network getting increasingly good at spotting the samples. In summary:\n\n- The generator tries to maximize the probability of the discriminator passing its outputs as real, not generated\n- The discriminator guides the generator to create ever more realistic samples\n\nAll in all, this process is represented as follows:\n![[Pasted image 20241231150923.png]]\n\nGANs can be used for a variety of tasks, and, in recent years, many GAN varieties have been created. As they were originally built for image-related tasks, we will focus our architecture discussions on image-based GANs. A larger list of GANs is available at the end of the section. Throughout, we'll follow along in TensorFlow to illuminate the topics. As before, we'll be utilizing the same MNIST data in order to compare the frameworks with our previous ones:\n```python\nimport tensorflow as tf  \nimport numpy as np\n\nfrom tensorflow.examples.tutorials.mnist import input_data  \nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)  \ntraining_data = (mnist.train.images - 0.5) / 0.5\n```\n\nWith that, let's walk through the pieces of the network one at a time. By this point, you should be pretty familiar with this process in TensorFlow.\n\n### Discriminator network\nThe discriminator network in image-related GANs is a standard convolutional neural network. It takes in an image and outputs a single number that tells us whether the image is _real_ or _fake_. The discriminator takes in an image, and learns the attributes of that image so that it may be a good _judge_ vis-à-vis the outputs of the generator. In TensorFlow, we can create the `discriminator` as a function that we will then run in a TensorFlow session later on. This framework is more or less the same as you've seen in the previous sections with autoencoder and variational autoencoders; we'll use the higher level `tf.layers` api to create three main network layers and an output layer. After each of the main network layers, we'll add a dropout layer for regularization. The last layer will be slightly different, as we'll want to squash the output. For this, we'll use a sigmoid activation function that will give us a final output saying if an image is believed to be fake or not:\n```python\ndef discriminator(x, initializer, dropout_rate):\n    layer_1 = tf.layers.dense(\n        x, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='input_layer')\n    dropout_1 = tf.layers.dropout(inputs=layer_1, rate=dropout_rate, training=True)\n    layer_2 = tf.layers.dense(\n        dropout_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='disc_layer_1')\n    dropout_2 = tf.layers.dropout(inputs=layer_2, rate=dropout_rate, training=True)\n    layer_3 = tf.layers.dense(\n        dropout_2, units=256, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='disc_layer_2')\n    dropout_3 = tf.layers.dropout(inputs=layer_3, rate=dropout_rate, training=True)\n    output_layer = tf.layers.dense(\n        dropout_3, units=1, activation=tf.sigmoid, kernel_initializer=initializer,\n        bias_initializer=initializer, name='disc_output')\n    return output_layer\n```\n\nNow that we have this discriminator defined, let's go ahead and move on to the generator.\n\n\n### Generator network\n\nYou can think of the `generator` portion of the GAN as a reverse convolutional neural network. Like a VAE, it uses generic normal distribution, the only difference being that it up samples the distribution to form an image. This distribution represents our prior, and is updated during training as the GAN improves at producing images that the discriminator is unable to determine whether they are fake.\n\nIn between each layer, we utilize a `ReLu` activation function and `batch_normalization` to stabilize each layer's outputs. As the discriminator starts inspecting the outputs of `generator`, `generator` will continually adjust the distribution from which it's drawing to closely match the target distribution. The code will look fairly familiar to what you've seen in previous sections:\n```python\ndef generator(x, initializer):\n    layer_1 = tf.layers.dense(\n        x, units=256, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='input_layer')\n    layer_2 = tf.layers.dense(\n        layer_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='hidden_layer_1')\n    layer_3 = tf.layers.dense(\n        layer_2, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,\n        bias_initializer=initializer, name='hidden_layer_2')\n    output_layer = tf.layers.dense(\n        layer_3, units=784, activation=tf.nn.tanh, kernel_initializer=initializer,\n        bias_initializer=initializer, name='generator_output')\n    return output_layer\n```\n\nNow that we have our model set up, let's get into the training process!\n\n### Training GANs\nGANs are easy to train, but difficult to optimize due to a number of unstable dynamics in their training processes. To train a GAN, we train the generator on sub samples of a high-dimensional training distribution; since this does not innately exist, we initially sample from a standard normal (Gaussian) distribution.\n\n![[Pasted image 20241231152334.png]]\n\nWhen training GANs, we train to minimize the objective function so that the generator can win. We want the generator to be able to create examples that are realistic enough to fool the discriminator. To do this, we train and optimize the discriminator and the generator in parallel using gradient ascent. For each iteration of training, we are going to train the discriminator network in small batches, and then train the generator network in small batches, alternating between the two paradigms. Gradient ascent for the discriminator computes the following:\n![[Pasted image 20241231152415.png]]\n\nBy taking the maximum of the generator's objective, we're maximizing the likelihood of being wrong. This parallelized training process can still be unstable, however, and stabilizing GANs is a very active area of research at the moment.\n\nLet's get back to the TensorFlow process. We'll start by defining our network's training parameters:\n```python\nlearning_rate = 0.0002  \nbatch_size = 100  \nepochs = 100  \ndropout_rate=0.5\n```\n\nWe then need to define our placeholders, both for the input `x`, as well as the `z` distribution which the generator will generate from:\n```python\nz = tf.placeholder(tf.float32, shape=(None, 100))  \nx = tf.placeholder(tf.float32, shape=(None, 784))\n```\n\nLike before, we'll create a Glorot `Initializer` that will initialize our weight and bias values for us:\n```python\ninitializer = tf.contrib.layers.xavier_initializer()\n```\n\nOnce we have all of this, we can go ahead and actually define our network pieces. You'll notice that for the discriminator, we're using something called a scope. Scopes allow us to reuse items from the TensorFlow graph without generating an error - in this case, we want to use the variables from the discriminator function twice in a row, so we use the `tf.variable_scope` function that TensorFlow provides us. Between the two, we simply use the `scope.reuse_variables()` function to tell TensorFlow what we're doing:\n```python\nG = generator(z, initializer)  \n  \nwith tf.variable_scope('discriminator_scope') as scope:  \n    disc_real = discriminator(x, initializer, 0.5)  \n    scope.reuse_variables()  \n    disc_fake = discriminator(G, initializer, 0.5)\n```\n\nLastly, we'll define the loss functions for both the generator and discriminator, and set the optimizer:\n```python\nepsilon = 1e-2  \ndisc_loss = tf.reduce_mean(-tf.log(disc_real + epsilon) - tf.log(1 - disc_fake + epsilon))  \ngen_loss = tf.reduce_mean(-tf.log(disc_fake + epsilon))  \n  \ndisc_optim = tf.train.AdamOptimizer(lr).minimize(disc_loss)  \ngen_optim = tf.train.AdamOptimizer(lr).minimize(gen_loss)\n```\n\nWe can the run the training cycle just as we have in the previous two examples. The only two differences you'll see here is that we run two optimization processes, one for the generator and one for the discriminator:\n```python\nwith tf.Session() as sess:  \n    sess.run(tf.global_variables_initializer())   \n    for epoch in range(epochs):  \n          \n        ## Define the loss to update as a list  \n        gen_loss = []  \n        disc_loss = []  \n          \n        ## Run the training iteration  \n        for iter in range(training_data.shape[0] // batch_size):  \n              \n            ## Batch the input for the discriminator  \n            x_prime = training_data[iter*batch_size:(iter+1)*batch_size]  \n            z_prime = np.random.normal(0, 1, (batch_size, 100))  \n  \n            ## Run the discriminator session  \n            _, DLoss = sess.run([disc_optim, disc_loss], {x: x_prime, z: z_prime, drop_out: 0.3})  \n            disc_loss.append(DLoss)  \n  \n            ## Run the generator session   \n            z_prime = np.random.normal(0, 1, (batch_size, 100))  \n            _, GLoss = sess.run([gen_optim, gen_loss], {z: z_prime, drop_out: 0.3})  \n            gen_loss.append(GLoss)  \n              \n        if epoch % 5 == 0:  \n            print('[%d/%d] - loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), epochs, np.mean(D_losses), np.mean(G_losses)))\n```\n\nGANs are fairly computational expensive, so training this network may take a while unless you scale with a web services platform. \n\nAs you can see, all of the models that we've run thus far have built upon each other. Even with advanced generative models like GANs, we can use certain recipes to create powerful neural networks, and larger AI applications, quickly and efficiently.\n\n\n\n\n## Other forms of generative models\n\n### Overview\nWhile we've only covered two types of generative model, there are many different types that you may encounter in the literature. The following chart is not exhaustive, but does provide a general overview of the types of generative models out there:\n![[Pasted image 20241231152903.png]]\n\nLet's break this down: \n- **Explicit density models**: Model our data directly from a probability distribution. We explicitly define the probability and solve for it\n- **Implicit density models**: Learn to sample from a probability distribution without defining what that distribution is\n\nWithin explicit density models, we have **tractable density** models and **approximate density** models. Here, tractable is related to defined computational time; we can calculate the computational complexity of a tractable problem. Approximate density relates to **intractability**—a computer science term that means that there is no defined computational time or algorithm. In practice, an intractable problem utilizes too many computational resources in order to be useful. Therefore, approximate density models use probabilistic approximation techniques to estimate the solution.\n\nWe'll briefly touch upon three notable classes: fully visible belief nets, Hidden Markov models, and Boltzmann machines. While each of these could be a chapter on its own, we'll touch on them briefly. Examples of each of these networks in Python are available in the code accompanying this chapter.\n\n### Fully visible belief nets\n\nFully visible belief networks are a class of explicit density models and a form of deep belief network. They use the chain rule to decompose a probability distribution $p(x)$ over a vector, into a product over each of the members of the vector, represented between by $p(x_i | x_1, \\dots)$. All together, it's formula is:\n![[Pasted image 20241231153111.png]]\n\nThe most popular model in this family is PixelCNN, an **autoregressive** generative model. Pixels approach image generation problems by turning them into a sequence modeling problem, where the next pixel value is determined by all the previously generated pixel values. The network scans an image one pixel at a time, and predicts conditional distributions over the possible pixel values. We want to assign a probability to every pixel image based on the last pixels that the network saw. For instance, if we're looking at the same horse images as in the previous example, we would be consistently predicting what the next anticipated pixel looks such as follows:\n![[Pasted image 20241231153143.png]]\n\nBased on the features that we've seen, will the next pixel still contain the horse's ear, or will it be background? While their training cycles are more stable than GANs, the biggest issue with the networks is that they generate new samples extremely slowly; the model must be run again fully in order to generate a new sample. They also block the execution, meaning that their processes cannot be run in parallel.\n\n\n\n\n\n### Hidden Markov models\nA hidden Markov model is a type of **Markov model**, which is itself a subclass of **Dynamic Bayesian Networks**. Markov models are used to model randomly changing systems called **Markov processes** also called **Markov chains**. Simply put, a Markov process is a sequence of events where the probability of an event happening solely depends on the previous event.\n\nMarkov chains appear as follows:\n![[Pasted image 20241231153404.png]]\n\nIn this simple chain, there are three states, represented by the circles. We then have probabilities for transitioning to another state, as well as probabilities of staying in a current state. The classic example of a Markov chain is that of the taxi driver, where the driver finds himself currently solely depends on where he was last, in other words, his most recent fare. If we were to apply this example to the preceding Markov chain, the driver would have three possible locations to pick up or drop off customers; the associated probabilities between locations would represent the chance of him going to the other location or staying put.\n\nHidden Markov models are used to model Markov processes that we can't observe; what if the driver's route structure of where he would like to pick up customers is secret? There is likely some logic to the scenario, and we can try and model that process with a Hidden Markov model.\n\n### Boltzmann machines\nBoltzmann machines are a general class of models that contain take binary vectors as input and units that assign a probability distribution to each of those binary vectors. As you can see in the following diagram, each unit is dependent on every other unit:\n![[Pasted image 20241231153508.png]]\n\nA Boltzmann machine uses something called an **energy function**, which is similar to a loss function. For any given vector, the probability of a particular state is proportional to each of the energy function values. To convert this to an actual probability distribution, it's necessary to renormalize the distribution, but this problem becomes another intractable problem. Monte Carlo methods are again used here for sampling as a workaround, hence making Boltzmann machines a Monte Carlo-based method.\n\nLet's say we have documents that are represented by binary features. A Boltzmann machine can help us determine whether a particular word or phrase came from a particular document. We can also use Boltzmann machines for anomaly detection in large, complex systems. They work well up to a point, although this method does not work well in high dimensional spaces.\n"},{"title":"HuggingFace NLP","tags":[],"path":"/AI/HuggingFace NLP","body":"\n[HuggingFace](https://huggingface.co/learn/nlp-course/chapter1/1)  |  [Wikipedia](https://www.wikiwand.com/en/Transformer_(deep_learning_architecture))\n- **NLP** | field of linguistics & ML related to language. The aim is to understand single words & the context of those words together.\n- **LLMs** are DL algorithms that use **transformer models** to perform **NLP** tasks.\n\n> Intro to [Attention is all you Need](https://arxiv.org/abs/1706.03762)\n> \n> The dominant sequence transduction models are based on complex RNNs or CNNs that include an encoder & a decoder. The best performing models also connect the encoder & decoder through an attention mechanism. \n>\n> We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. \n\n### 1. Transformer Models\n3 major groups of transformer models: [History, 2018-2021](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg)\n\n| Model                                                        |      |                      |                                                            | Examples                                   | Tasks                                                        |\n| ------------------------------------------------------------ | ---- | -------------------- | ---------------------------------------------------------- | ------------------------------------------ | ------------------------------------------------------------ |\n| [Encoder](https://huggingface.co/learn/nlp-course/chapter1/5?fw=pt) | BERT | Auto-Encoding        | Receives input, builds features.                           | ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa | Sentence classification, named entity recognition, extractive question answering |\n| [Decoder](https://huggingface.co/learn/nlp-course/chapter1/6?fw=pt) | GPT  | Auto-Regressive      | Uses encoder's features + other inputs to generate target. | CTRL, GPT, GPT-2, Transformer XL, LLaMA    | Text generation                                              |\n| [Encoder-decoder](https://huggingface.co/learn/nlp-course/chapter1/7?fw=pt) | BART | Sequence-to-sequence |                                                            | BART, T5, Marian, mBART                    | Summarization, translation, generative question answering    |\n> All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as ***language models***. This means they have been trained on large amounts of raw text in a **self-supervised** fashion. Self-supervised learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!\n>\n> The general pretrained model then goes through ***transfer learning*** where the model is fine-tuned in a supervised way — that is, using human-annotated labels — on a given task.\n\n#### Transfer Learning\n- *Pretraining* is the act of training a model from scratch.\n- *Fine-tuning* is done **after** a model has been pretrained, using a new specific dataset.\n\nTransformer models are built with *attention layers*, which tell the model to pay specific attention to certain words in the sentence. ([Paper](https://arxiv.org/abs/1706.03762))\n\n**Transformer Model** Terms:\n- **Architecture**: Skeleton of the model — the definition of each layer & operation within the model. (eg `BERT`)\n- **Checkpoints**: The weights that will be loaded in the architecture. (eg `bert-lower-cased`)\n- **Model**: Umbrella term that could mean “architecture” or “checkpoint”. This course will specify *architecture* or *checkpoint* when it matters.\n\n### 2. Using Transformers\n[Behind the pipeline](https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt) - steps - [YouTube](https://www.youtube.com/watch?v=1pedAIvTWXk&t=52s)\n\n1. **Preprocessing with a tokenizer**:\n   1. Load the tokenizer.\n   2. Tokenize input text into tokens and convert to tensors.\n2. **Model**:\n   1. Load the pretrained model.\n   2. Pass the tokenized inputs through the model to get output logits.\n3. **Postprocessing the output**:\n   1. Convert logits to probabilities using softmax.\n   2. Map the probabilities to labels.\n\nBreaking out steps in detail: **Tokenizer**\n1. **Tokens** | Split the input into *tokens* (ie words, subwords, punctuation)\n2. **Special tokens** | Add special tokens such as \"sentence begin\".\n3. **Input IDs** | Map each token to it's unique ID from that specific pre-trained model. (This is the *checkpoint* which comes out as a *dictionary*.)\n\nBreaking out steps in detail: **Model** ([Image](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg))\n1. Input from Tokenizer\n2. Transformer network\n   1. **Embeddings** | convert each unique ID into vector\n   2. **Layers** | manipulate vectors using attention mechanism\n3. **Hidden states (features)** | \n4. **Head** | take high-dimensional vector of hidden states as input, then convert predictions to task-specific output\n5. Output for post-processing\n\n\n## Sentiment Analysis\n[Finbert Github](https://github.com/ProsusAI/finBERT)  |  [Blog](https://huggingface.co/blog/sentiment-analysis-python)  |  [Grammar Correction](https://huggingface.co/vennify/t5-base-grammar-correction)\n\nBERT\n- Bidirectional Encoder Representations from Transformers\n- ML model for NLP\n- Developed in 2018 by Google AI. Serves as a swiss army knife solution to 11+ of the most common language tasks, such as sentiment analysis and named entity recognition.\n\nA massive dataset of 3.3 Billion words has contributed to BERT’s continued success. BERT was specifically trained on Wikipedia (~2.5B words) and Google’s BooksCorpus (~800M words). \n\nMLM enables/enforces bidirectional learning from text by masking (hiding) a word in a sentence and forcing BERT to bidirectionally use the words on either side of the covered word to predict the masked word.\n\nA random 15% of tokenized words are hidden during training and BERT’s job is to correctly predict the hidden words. Thus, directly teaching the model about the English language (and the words we use).\n\n"},{"title":"ML Ops","tags":["ai_"],"path":"/AI/ML Ops","body":"\n- Model Deployment Strategies\n- API Development for Models\n- Containerization (Docker)\n- Monitoring and Maintaining Models in Production\n\n\n\n\n# ML Flow\n\n[Databricks - my account](https://community.cloud.databricks.com/?o=4863812759132216)\n[Databricks - Import notebooks here](https://community.cloud.databricks.com/browse/folders/546568900529560?o=4863812759132216)\n\n## Core Components\n\n[MLflow | Intro](https://www.mlflow.org/docs/latest/introduction/index.html)\n- [Image | Workflow and Personas](https://www.mlflow.org/docs/latest/_images/mlflow-overview.png)\n\nMLflow provides a **unified platform** to navigate the intricate maze of **model development**, **deployment**, and **management**.\n\n- [[MLflow - Tracking]]: Tracks parameters, code versions, metrics, and artifacts.\n- [[MLflow - Registry]]: Handles model versions, discerns their current state, ensures smooth productionization.\n- [[MLflow - Deployment for LLMs]]: Server/interface to access SaaS & OSS LLM models. Offers a common set of APIs for prominent LLMs.\n- [[MLflow - Evaluate]]: Set of tools for model comparison, be it traditional ML algorithms or LLMs.\n- [[MLflow - Prompt Engineering UI]]: Provides a space for prompt experimentation, refinement, evaluation, testing, and deployment.\n- [[MLflow - Recipes]]: Guide for structuring ML projects. Offers recs and helps ensure model is optimized for deployment.\n- [[MLflow - Projects]]: Standardize the packaging of code, workflows, and artifacts, akin to an executable. Each project, be it a directory with code or a Git repository, employs a descriptor or convention to define its dependencies and execution method.\n\n---\n\n## Getting Started\n\n[Intro](https://www.mlflow.org/docs/latest/introduction/index.html) --> [How to run Tutorials](https://www.mlflow.org/docs/latest/getting-started/running-notebooks/index.html)\n\n\n\n\n"},{"title":"NLP","tags":["ai_"],"path":"/AI/NLP","body":"\nBack/Outgoing Links\n```dataview\nlist from [[]] and !outgoing([[]])\n```\n\n\nDeeper\n- [[HuggingFace NLP]]\n\n### Methods\n`What are the most common model types (and corresponding examples) within NLP?`\n\n**NLP methods**\n1. **Symbolic (Rule-Based):**\n   Not really used anymore because of the advance of LLMs. Used to be used for:\n   - Small data\n   - Tokenization (pre-processing in NLP pipelines)\n   - Knowledge extraction (pre-processing output of NLP pipelines)\n\n2. **ML (Statistical & Neural)**\n   \n\n**Breaking out the \"ML\" methods**\n\n1. **ML / DL:**\n   - **RNNs**: Sequential data in sentiment analysis\n   - **LSTMs**: Same as above, better for long-range dependencies.\n2. **Transformer Models:**\n   - **Description:** Transformer architectures have gained widespread adoption in NLP due to their attention mechanisms.\n   - **Example:** BERT (Bidirectional Encoder Representations from Transformers) for pre-training language representations.\n3. **Sequence-to-Sequence Models:**\n   - **Description:** Sequence-to-sequence models process variable-length input sequences and generate variable-length output sequences.\n   - **Example:** Used for machine translation, summarization, and question answering. Notable model: Google's GNMT (Google Neural Machine Translation).\n4. **Transfer Learning Models:**\n   - **Description:** Transfer learning models pre-train on large datasets and fine-tune for specific tasks.\n   - **Example:** ULMFiT (Universal Language Model Fine-tuning) for transfer learning in NLP.\n5. **Attention Mechanism Models:**\n   - **Description:** Models incorporating attention mechanisms to focus on different parts of input sequences.\n   - **Example:** Transformer-based models like BERT, GPT, and T5.\n6. **Graph Neural Networks (GNNs):**\n   - **Description:** GNNs handle data with complex relationships, suitable for tasks involving graphs.\n   - **Example:** GNNs applied to tasks like semantic parsing and knowledge graph completion.\n"},{"title":"_AI MOC","tags":[],"path":"/AI/_AI MOC","body":"\n\n### TOC\n\n```ad-sam\n\n[ChatGPT](https://chatgpt.com/share/6817848d-fc2c-8000-acc3-e7610850caeb)\n\n**Overview of TOC Parts**\n\n(1) **Core Concepts**\nRefresh NN intuition. Need for transformers, self‑supervision, and modern frameworks like PyTorch.\n\n(2) **Generative AI Essentials**\nUnderstand and **use** LLMs, prompt engineering, and RAG.  \n\n(3) **Practical MLOps**\nDeploy, scale, and version models with minimal DevOps pain.  \n\n(4) **Responsible & Edge AI**\nPrivacy/security for devices and constrained environments.\n\n(5) **Applications & Career**\nTie to real business use‑cases / continuous learning habits.\n\n```\n\n\n| Part                          | Chapter                          | Section                                                  |\n| ----------------------------- | -------------------------------- | -------------------------------------------------------- |\n| I – Core Concepts             | 1 Deep‑Learning Basics           | [[1.1 Why NNs Work (Intuition)]]                         |\n|                               |                                  | [[1.2 Transformers in Plain English]]                    |\n|                               |                                  | 1.3 Self‑Supervision: “Learning Without Labels”          |\n|                               |                                  | 1.4 Modern Frameworks (PyTorch 2.x, JAX) at a Glance     |\n| II – Generative AI Essentials | 2 Large Language Models          | [[2.1 What Makes GPT‑4o & Llama 3 Tick (High Level)]]    |\n|                               |                                  | 2.2 ChatGPT vs Open‑Source LLMs: When to Use Which       |\n|                               |                                  | 2.3 Easy Fine‑Tuning with LoRA (Step‑by‑Step Guide)      |\n|                               | 3 Prompt Engineering             | 3.1 Crafting Prompts & System Messages                   |\n|                               |                                  | 3.2 Chain‑of‑Thought & “Show Your Work” Tricks           |\n|                               |                                  | 3.3 Function Calling & JSON Output (No Coding Headaches) |\n|                               | 4 Retrieval‑Augmented Generation | 4.1 RAG in One Picture                                   |\n|                               |                                  | 4.2 Vector Stores 101 (Pinecone, Qdrant)                 |\n|                               |                                  | 4.3 Building Your First RAG Chatbot                      |\n| III – Practical MLOps         | 5 Deploying LLMs                 | 5.1 Local vs Cloud Inference (Pros & Cons)               |\n|                               |                                  | 5.2 Quick Quantization to Fit on a Laptop GPU            |\n|                               | 6 Data Pipelines for Gen‑AI      | 6.1 Collecting & Cleaning Text Data Fast                 |\n|                               |                                  | 6.2 Simple CI/CD for Models (GitHub Actions Template)    |\n| IV – Responsible & Edge AI    | 7 On‑Device AI                   | 7.1 Running LLMs on Apple Silicon or a Phone             |\n|                               |                                  | 7.2 Privacy‑First Design Tips                            |\n|                               | 8 Ethics & Governance            | 8.1 Bias & Fairness Checklists (Non‑Math)                |\n|                               |                                  | 8.2 Key Regulations in Plain Language (EU AI Act, US EO) |\n| V – Applications & Career     | 9 AI Agents & Tools              | 9.1 ReAct, CrewAI & Other Agent Patterns                 |\n|                               |                                  | 9.2 Safeguarding Agents (Rate Limits, Guardrails)        |\n|                               | 10 Domain Playbooks              | 10.1 E‑Commerce: Smart Recommendations                   |\n|                               |                                  | 10.2 Finance: Fast Fraud Detection with Gen‑AI           |\n|                               |                                  | 10.3 Healthcare: HIPAA‑Friendly Chat Assistants          |\n|                               | 11 Portfolio Projects            | 11.1 Build a Personal RAG Bot over Your Notes            |\n|                               |                                  | 11.2 Publish a Blog Post from Your Evergreen Notes       |\n|                               | 12 Continuous Learning           | 12.1 Must‑Follow Newsletters & Paper Digests             |\n|                               |                                  | 12.2 Quarterly Skill‑Gap Self‑Check                      |\n\n\n\n# May4: Can get rid of everything below once fleshed out ^\n\n### Temp - move into TOC\n\n\n[[NLP]]\n[[Generative Models]]\n[Stanford Cheatsheets](https://stanford.edu/~shervine/teaching/cs-221/)\n[[3Blue1Brown - GPT]]\n\n\n\n## Classes of NNs\n\n[ChatGPT](https://chatgpt.com/share/677453cb-d690-8000-8926-be642b5d1e01): The “best” class depends heavily on your data and task:\n- **Images** → CNNs or Vision Transformers\n- **Language** → RNN-based or Transformer-based models\n- **Graphs** → GNNs\n- **Generating new data** → GANs, VAEs\n- **Dimensionality reduction** → Autoencoders, RBMs\nIn practice, researchers and engineers often combine ideas from multiple classes to tailor solutions to specific problems.\n\n| Class                                   | Use Cases                                                                         | Key Idea                                                                                    | Examples                                                     |\n| --------------------------------------- | --------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | ------------------------------------------------------------ |\n| **1. Feedforward NNs**                  | Basic classification and regression                                               | Information flows in a single direction (input → output); no feedback loops                 | Multi-Layer Perceptron (MLP)                                 |\n| **2. Convolutional NNs**                | Image recognition, computer vision, text classification                           | Uses convolution and pooling layers to capture spatial/temporal features                    | LeNet, AlexNet, ResNet                                       |\n| **3. Recurrent NNs**                    | Language modeling, speech recognition, time-series forecasting                    | Maintains a hidden state that evolves over time, processing data sequences                  | LSTM (Long Short-Term Memory), GRU (Gated Recurrent Unit)    |\n| **4. Transformers**                     | Language modeling, machine translation, text summarization, multimodal tasks      | Relies on self-attention to process sequential data in parallel                             | The original “Attention Is All You Need,” BERT, GPT series   |\n| **5. Autoencoders**                     | Dimensionality reduction, anomaly detection, generative modeling                  | Learns compressed representations (encodings) and reconstructs data from them               | Denoising Autoencoders, Sparse Autoencoders, Variational AEs |\n| **6. Generative Adversarial Networks**  | Image generation, data augmentation, style transfer                               | Employs two competing networks: a Generator and a Discriminator, trained in a zero-sum game | DCGAN, CycleGAN, StyleGAN                                    |\n| **7. Graph NNs**                        | Social networks, molecular graph analysis, recommendation systems                 | Operates on graph-structured data, capturing node and edge relationships                    | Graph Convolutional Network (GCN), GraphSAGE, GAT            |\n| **8. Boltzmann Machines**               | Feature learning, collaborative filtering (e.g., Netflix Prize solutions)         | Stochastic, energy-based models learning internal data representations                      | Restricted Boltzmann Machines (RBMs)                         |\n| **9. Spiking NNs**                      | Low-power computation, robotics, real-time processing in IoT                      | Uses spikes/timing-based signals, mimicking biological neural behavior                      | Neuromorphic hardware implementations                        |\n| **10. Other Specialized Architectures** | Hierarchical image representation, continuous time modeling, structured NLP tasks | Various advanced or niche models targeting specific improvements or use cases               | Capsule Networks, Neural ODEs, Recursive NNs                 |\n\n\n\n## Other Resources\n\n[what-is-chatgpt-doing-and-why-does-it-work/](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)\n\n**LangChain** | a framework designed to facilitate the development of applications that use large language models (LLMs) for tasks such as answering questions, document retrieval, and automation of workflows. It helps developers easily integrate LLMs with other data sources and tools. [Chat](https://chatgpt.com/share/66f820e4-b0d0-8000-9f59-5bc5ea0765e3)\n\n```ad-sam\n\nI am a data scientist with a background in Machine Learning. I would like to use an existing GPT, but train on my own data. What are some ways I could do this?\n\n[ChatGPT](https://chatgpt.com/share/66ed9177-e9ac-8000-afcf-2827782d1b07)\n\n```\n\n\n\n#### AI is for Everyone - Might delete\n[External - AI for Everyone](https://www.deeplearning.ai/courses/ai-for-everyone/)\n**Artificial Intelligence**: Development of systems that perform tasks that mimic/simulate human intelligence. \n\nAI \"types\" or \"ideas\":\n1. **ANI: Artificial *Narrow* Intelligence**: Smart speaker, self driving car.\n2. **Generative AI**: ChatGPT\n3. **AGI: Artificial *General* Intelligence**: Anything a human can do (or more)\n\nLLMs are built by using **supervised** learning to predict the next word.\n\nAI Branches:\n- **ML**\n\t- Deep Learning\n- **Others**: Generative AI, unsupervised learning, reinforcement learning, graphical models, planning\n\nMajor AI techniques:\n- Video: [Survey of major AI techniques](https://www.coursera.org/learn/ai-for-everyone/lecture/qxMIm/survey-of-major-ai-techniques-optional)\n- Slides: [AI-For-Everyone-W3](AI-For-Everyone-W3.pdf)\n\n**Reinforcement learning**: trial & error\n**GANs**: can create realistic-looking data, such as images, videos, and text\n"},{"title":"1.1 Why NNs Work (Intuition)","tags":[],"path":"/AI-Book/1.1 Why NNs Work (Intuition)","body":"\nResources\n- [[Deep Learning]]: Class notes, more detailed than below.\n- [ChatGPT](https://chatgpt.com/share/681789dd-021c-8000-a07b-964d90d8e09d): for this markdown\n\n---\n\n```ad-sam\n**Summary**\nNNs work because they are **flexible function approximators** that learn useful **internal representations** of data by stacking layers of transformations. \nInstead of manually designing features or rules, neural nets **learn patterns directly from data** through a process of trial-and-error optimization.\n\n| Strength                        | What It Means                                     |\n| ------------------------------- | ------------------------------------------------- |\n| Hierarchical representation     | Learns from simple to complex features            |\n| Flexible function approximation | Can learn a wide variety of patterns and tasks    |\n\n```\n\n### Why NNs Work\n```ad-sam\n- Neural nets can **approximate almost any function**, given enough layers and data (Universal Approximation Theorem).\n- They are **data-driven**: no need to hand-engineer features or rules.\n- They are **modular** (think sub-task) and **scalable**: you can adjust size, depth, and architecture based on the problem.\n```\n\n### What Are NNs?\n```ad-sam\nAt their core, NNs are inspired by the brain. They consist of layers of artificial “neurons” that **process input data** and pass signals forward. Each neuron learns to activate in response to specific patterns.\n\n- **Input layer**: Receives raw data (e.g., pixels, words, numbers).\n- **Hidden layers**: Transform and abstract the input features into higher-level representations.\n- **Output layer**: Produces a prediction or decision.\n\nEach connection has a **weight** that determines how much influence one neuron has on the next.\n```\n\n### Layered Representations\n```ad-sam\nThe true magic of NNs lies in **stacking multiple layers**:\n\n- **First layers** learn low-level features (e.g., edges in images).\n- **Deeper layers** build on those to detect more abstract patterns (e.g., faces, objects).\n- **Final layers** make task-specific predictions (e.g., cat vs. dog).\n\nThis **hierarchical learning** allows neural nets to go from raw data to meaning, automatically.\n```\n\n### Learning Through Feedback (Training)\n```ad-sam\n\nNNs improve by **learning from mistakes**. Here's how:\n\n1. Make a guess (prediction).\n2. Compare it to the correct answer (loss).\n3. Adjust internal weights to reduce future error.\n\nThis is called **gradient-based optimization**, but all you need to know is:\nThe model gets better over time by seeing more examples and adjusting itself.\n\n```\n"},{"title":"1.2 Transformers in Plain English","tags":[],"path":"/AI-Book/1.2 Transformers in Plain English","body":"\nResources\n- [[NLP]] and [[HuggingFace NLP]]: Talks about transformers\n- [ChatGPT](https://chatgpt.com/share/681792c6-48c0-8000-b324-765516a6ce87): This markdown\n\n### Everyday Analogy\n```ad-sam\nImagine reading a paragraph and instantly knowing which earlier sentences are important. \nThat’s what transformers do — they \n1. read left-to-right AND\n2. weigh relevance across the whole passage in real time\n```\n\n```ad-sam\n**Transformers are the architecture behind nearly every language model today.**\n\nTransformers marked a shift \n**FROM** sequence-based models \n**TO** attention-based models. \n\nThey are both fast & context-aware.\n```\n\n### What is a Transformer?\n```ad-sam\nTransformers are a type of DL model introduced in 2017. They're best known for powering LLMs like GPT & BERT. \nUnlike older models that processed language one word at a time, transformers look at entire sentences (or documents) all at once.\n\n**Transformers replaced recurrence with attention**, allowing models to see everything at once — a breakthrough for understanding context.\n```\n\n### Why They Matter\n```ad-sam\nTraditional models like RNNs had trouble (1) remembering long-term dependencies or (2) were slow to train. \nTransformers solved both problems:\n- **Parallel Processing**: They process words simultaneously, not sequentially.\n- **Long-Range Context**: They can \"attend\" to any word, no matter how far apart.\n```\n\n### Key Ingredients (Without Equations)\n```ad-sam\n**Self-attention is like scanning a room and deciding who’s worth listening to** — for every word in the sentence.\n\n\n- **Tokens**: Break input into chunks (usually words or subwords).\n- **Embeddings**: Convert those chunks into numbers.\n- **Self-Attention**: Each token \"looks\" at others to decide what matters.\n- **Layers**: These operations repeat multiple times to refine understanding.\n\n```\n"},{"title":"ML Ops","tags":[],"path":"/BigData/ML Ops","body":"\n[YouTube Playlist | Andrew Ng](https://www.youtube.com/playlist?list=PLkDaE6sCZn6GMoA0wbpJLi3t34Gd8l0aK)\n\n**V1**: Intro\n**V2**: Project lifecycle | [image](Pasted%20image%2020241105105907.png)\n**V3**: Project lifecycle example\n**V4**: *Course outline*\n**V5**: Possible issues could be ML or software\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"MLflow - Tracking","tags":[],"path":"/BigData/MLflow - Tracking","body":"\nMain page: https://www.mlflow.org/docs/latest/tracking.html#tracking\nQuickstart: https://www.mlflow.org/docs/latest/getting-started/intro-quickstart/index.html\n- Loaded into databricks: [Databricks notebook](https://community.cloud.databricks.com/#notebook/306626164773736/command/306626164773737)\n\n> Tracks parameters, code versions, metrics, and artifacts.\n\n\nConcepts:\n- **Runs**: Runs are executions of some piece of code (eg, a single `python train.py` execution). Records metadata and artifacts.\n- **Experiments**: An experiment groups together runs for a specific task.\n- **Tracing**: Each \"trace\" is data that's recorded for future review, debugging, or analysis.\n\n"},{"title":"_BigData MOC","tags":[],"path":"/BigData/_BigData MOC","body":"```dataview\nTABLE without id\n\nfile.link,\ncovers,\n\nQuality,\n\n\"<progress max=\" + \n(sum(HoursDone) + sum(HoursRemain)) + \" value=\" + number(\nsum(HoursDone)) + \"> </progress> \"  + number(\nsum(HoursDone)) + \" of \" + number(\nsum(HoursDone) + sum(HoursRemain)) + \" \" + \"hours\" + \" (\" +round(number(\nsum(HoursDone))/number(\nsum(HoursDone) + sum(HoursRemain))*100) + \"%\" + \")\" as Progress,\n\nsum(HoursRemain) as Remain\nfrom outgoing([[]])\n```\n\n\n\n\n[ML Ops](DataScienceFolder/AI/ML%20Ops.md)\n[MLflow](MLflow.md)\n\n\n\n[Platforms and Other Essentials](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/69346214-320e-487f-b4cf-bd5c469dc75e.xhtml)\n1. [Technical requirements](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/2040ff62-0a01-4742-84f5-617648afb54f.xhtml)\n2. TensorFlow, PyTorch, and Keras\n3. Cloud computing essentials\n   1. AWS basics (EC2, S3, Sagemaker)\n   2. Google Cloud Platform basics\n4. CPUs, GPUs, and other compute frameworks\n   1. Installing GPU libraries and drivers\n   2. [Basic GPU operations](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/df97f2fe-058e-4be6-b7d6-b2c4e7f08489.xhtml)\n   3. [The future – TPUs and more](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/9fb972bb-6148-43e3-86ee-af8a3128e681.xhtml)\n"},{"title":"Ch 17 Autoencoders, GANs, and Diffusion Models","tags":[],"path":"/Ch 17 Autoencoders, GANs, and Diffusion Models","body":"```ad-sam\nNote to self - created March 22, 2025. \n```\n\n\nAlso see [[Generative Models]] - different textbook\n\n## Autoencoders\n\n[ChatGPT](https://chatgpt.com/share/67dee1a1-8600-8000-88c7-ffce728e06cf) - `Quick summary. Meant to be intuitive, not exhaustive.`\n\nAutoencoders learn succinct representations. They serve as a foundation for many generative and dimensionality-reduction techniques.\nStructurally, autoencoders consist of an **input layer**, a **hidden layer**, and an **output** **layer**: [[Pasted image 20241231143947.png]]\n\n```ad-sam\n\n**Intuition**\n\n**Autoencoders**: example of encoder --> decoder.\n\n1. I have an **idea** that I want to share. I'll explain using an example. Three examples come to mind, and I choose the simplest one.\n2. The listener hears my example, and then re-generates my original **idea**.\n\nWe want the **idea** I shared to be as close as possible to the **idea** the listener understands. (\"Reconstruction loss\")\n\n```\n\n**Autoencoders** are a self-supervised approach to representation learning. They operate with two main components:\n1. An **encoder** that compresses (or *encodes*) the input into a smaller, more compact representation (an “information bottleneck”).\n2. A **decoder** that *reconstructs* the original input from this compact representation.\nThe encoder is a *recognition* network, the decoder is a *generative* network.\n\n**Key Ideas**\n- **Information Bottleneck**: The encoder forces the network to keep only *the most relevant aspects* of the data; this helps avoid simply memorizing inputs.\n- **Reconstruction Loss**: Typically mean squared error or cross entropy, which measures how close the decoder’s output is to the original input.\n- **Goal**: Find a balance where the model accurately reconstructs input data but doesn’t overfit or memorize it.\n\n**Connection to PCA**\n- Like **PCA**, autoencoders perform **dimensionality reduction**, taking high-dimensional data and learning a lower-dimensional representation.\n- **Difference**: Autoencoders can capture **nonlinear** relationships, whereas PCA is restricted to **linear** correlations.\n\nManifolds\n- A **manifold** is a continuous, non-intersecting surface (think of a sphere).\n- In neural networks, loss functions and data structures often lie on (possibly complex) manifolds. Autoencoders learn to navigate these manifolds by mapping input data into a meaningful, compressed space and then reconstructing it back.\n\n---\n\n## Ch 17\n\n**Autoencoders** are ANNs capable of learning latent representations without supervision. \n- **Latent representations** (aka **codings**): dense representations of the input data.\n\n**Autoencoders** uses\n- **Dimensionality reduction**: Since codings typically have a lower dimensionality than the input data\n- **Feature detectors**: Can be used for unsupervised pretraining of DNNs\n- **Generation**: Some are _generative models_: they are capable of randomly generating new data that looks very similar to the training data\n\n### GANs\n\n**GANs** (Generative Adversarial Networks) are composed of 2 NNs that compete\n1. *generator* to generate data similar to training data \n2. *discriminator* that tries to tell real data from fake data\n**Intuition**: criminal generates fake money, cop tries to id fake money\n**Adversarial training**: training *competing* NNs\n\n### Autoencoders vs GANs\nBoth\n- Unsupervised\n- Learn dense representations\n- Can be used for generation\n- Similar applications\n\nWork differently:\n- **Autoencoders**: simply learn to copy their inputs --> outputs (non-trivial)\n- **GANs**: create 2 NNs that compete with each other\n\n \n### Variational Autoencoders\n\nThese are different than the other autoencoders in the chapter:\n- They are **probabilistic** - ie, their outputs are partly determined by chance.\n- They are **generative** - ie, they can produce new data\n\n\n\n\n"},{"title":"DataScience","tags":[],"path":"/DataScience","body":"\n[Github Cheatsheets](https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf)\n\n```dataview\nTABLE without id\n\nchoice(contains(CoverImage, \"http\"), (\"![coverimg|100](\" + CoverImage + \")\"), embed(link(CoverImage, \"150\")) ) as \"Cover\",\nfile.link\n\nfrom outgoing([[]])\n\n\n```\n\n\n## Cheatsheet\n\n![[DS Cheatsheet.pdf]]\n\n\n\n## Algorithm Types\n\n![[Algos.jpeg]]\n\n## MOCs\n\n[[_AI MOC]]\n[[_BigData MOC]]\n[[_ML MOC]]\n\n\n**Specialty**\n[[_Optimization MOC]]\n[[_Strategy MOC]]\n[[_TS MOC]]\n\n\n\n\n\n"},{"title":"Deep Learning","tags":["ml_"],"path":"/ML/Deep Learning","body":"\n## Oreilly Outline\n\n[Your First ANN](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/8c724645-08d4-4a08-af9e-45bf607f8a88.xhtml)\n1. [Technical requirements](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/aa5174d0-e5cf-4dbd-9b64-92b8754c34cb.xhtml)\n2. Network building blocks\n   1. [Network layers](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/562cb6bc-c88f-4613-8ff2-fa1e64cc915c.xhtml)\n   2. Naming and sizing neural networks\n   3. Activation functions\n   4. Weights and bias factors\n   5. Loss functions\n   6. Stochastic gradient descent\n   7. [Regularization](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/a1be58ad-36e0-42d0-a74f-f6444275fce3.xhtml)\n3. The training process\n   1. [Putting it all together](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/36c76076-c14e-45b2-ae65-850332e645c4.xhtml)\n   2. [Forward propagation](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/920d17e8-8c14-4524-9dfc-875fe5048ec1.xhtml)\n   3. [Backpropagation](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/9d59ff80-df00-4855-a2fe-7b8e9e4a6564.xhtml)\n   4. [Forwardprop and backprop with MNIST](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/2ba064ba-37d2-414e-b8f5-4acf065e7543.xhtml)\n   5. Managing a TensorFlow model\n\n\n[RNNs](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/15e91aca-5877-405a-99eb-1d105727be82.xhtml)\n1. [Technical requirements](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/bfa7eb5e-e1e0-4484-ad1d-cead24304749.xhtml)\n2. The building blocks of RNNs\n   1. [Basic structure](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/77fc0c65-fd61-4b85-93d3-19b0e0ad03bf.xhtml)\n   2. Vanilla recurrent neural networks\n   3. [Backpropagation through time](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/a7f10981-82e6-4194-bc45-35eb23b311a0.xhtml)\n3. Memory units; LSTMs and GRUs\n   1. [LSTM](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/30e008a1-d5ce-462c-ae50-265e8c85fa5a.xhtml)\n   2. [GRUs](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/4bf7738c-53a0-4493-a1dc-504b8691d27a.xhtml)\n4. Sequence processing with RNNs\n   1. Neural machine translation\n      1. [Attention mechanisms](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/8f836ba7-438b-4218-813d-437095b00374.xhtml)\n   2. [Generating image captions](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/beb80ae8-dd40-4d77-badb-046b71a748da.xhtml)\n5. Extensions of RNNs\n   1. [Bidirectional RNNs](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/ba9a32b4-a351-4308-baa4-33ab5c870b29.xhtml)\n   2. [Neural turing machines](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/0517c6a9-4b76-4083-b4f1-d2c198dbb5d7.xhtml)\n\n\n\n\n## GENERAL NEURAL NETWORKS\n\nhttps://www.tensorflow.org/tutorials\n\n*From class notes*\n\nLinks\n- [Ch 13 Code](https://github.com/ageron/handson-ml/blob/637bc1c298a593e02b439ce54aa5de9f8e7f71b4/13_convolutional_neural_networks.ipynb): CNNs\n- [Ch 14 Code](https://github.com/ageron/handson-ml/blob/2adec01b34cbfe05866fca6bc724d093c8352e20/14_recurrent_neural_networks.ipynb): RNNs\n- [Andrew Ng Code](https://github.com/dibgerge/ml-coursera-python-assignments/blob/master/Exercise3/exercise3.ipynb): Multi-Class & Neural Nets\n- [Andrew Ng Code](https://github.com/dibgerge/ml-coursera-python-assignments/blob/master/Exercise4/exercise4.ipynb): Neural Nets\n\nThe activation function is a hyperparameter, the weights and biases are parameters.\n\n### Ch 10\n> In the first part of this chapter, we will introduce artificial neural networks, starting with a quick tour of the very first ANN architectures, leading up to Multi-Layer Per‐ ceptrons (MLPs) which are heavily used today (other architectures will be explored in the next chapters). \n> In the second part, we will look at how to implement neural networks using the popular Keras API.\n\n### ANNs\n> Warren McCulloch and Walter Pitts proposed a very simple model of the biological neuron, which later became known as an artificial neuron: it has one or more binary (on/off) inputs and one binary output. The artificial neuron simply activates its out‐ put when more than a certain number of its inputs are active. McCulloch and Pitts showed that even with such a simplified model it is possible to build a network of artificial neurons that computes any logical proposition you want.\n\nPg 283: Artificial neuron contains:\n- 1+ binary input neurons (IN)\n- Input **connections** between IN & ON\n- 1 binary output neuron (ON)\n- If a threshold number of **connections** are reached, the ON is activated\n\n---\n\n### Perceptron\n> The Perceptron is one of the simplest ANN architectures, invented in 1957 by Frank Rosenblatt.\n\nTable from Pg 293: Typical Regression MLP Architecture\n\n| hyperparameter               | Typical value                                           |\n| ---------------------------- | ------------------------------------------------------- |\n| \\## input neurons            | One per input feature                                   |\n| \\## hidden layers            | Typically 1-5                                           |\n| \\## neurons per hidden layer | Typically 10-100                                        |\n| \\## output neurons           | 1 per prediction dim (1 for regress, 2 for binary, etc) |\n| Hidden activation            | ReLu or SELU                                            |\n| Output activation            | None for regression. ReLu/softplus                      |\n| Loss function                | MSE or MAE/Huber (if outliers)                          |\n> An MLP is composed of one passthrough input layer, one or more layers of TLUs (threshold logic units), called hidden layers, and one final layer of TLUs called the output layer. The layers close to the input layer are usually called the lower layers, and the ones close to the outputs are usually called the upper layers. Every layer except the output layer includes a bias neuron and is fully connected to the next layer. The architecture that the signal flows only in one direction from the inputs to the outputs is called feedforward neural network (FNN). When an ANN (artificial neural network) contains a deep stack of hidden layers, it is called a deep neural network (DNN). - pg 287\n---\n\nPg 284: **Perceptron** (figure on pg 286)\n\n**Perceptrons** are based on a slightly different type of artificial neuron called a *threshold logical unit* (TLU). Instead of using binary \"off/on\", the inputs & outputs are **numbers**.\n\nSteps:\n1. TLU computes **weighted sum** of inputs (IN & input weight).\n   $z = w_1 x_1 + w_n x_n = X^T w$\n2. TLU applies a **step function** (sigmoid, tangent, or ReLu) to this sum.\n   $h_w(x) = step(z)$,     where     $z=X^T w$\n\n1 single TLU **layer** is called a **Perceptron**.\n\n---\n\n#### Equation\n\n**Outputs of fully connected layer** =\n$h_{W,b} (X) = \\Theta(XW + b)$\n\n**X** = our dataset (matrix of input features)\n- 1 row per instance\n- 1 column per feature\n\n**W** = weight matrix\n- 1 row per input neuron (IN)\n- 1 column per artifical neuron (AN) in the layer\n\n**b** = bias vector, contains all connection weights between bias neuron & AN\n- 1 bias term per AN\n\n$\\Theta$ = activation function\n\n\n#### MLP Backpropagation\n\n> An MLP is composed of one (passthrough) input layer, one or more layers of TLUs, called hidden layers, and one final layer of TLUs called the output layer.\n\n*Note*: The Perceptron learning algorithm is the same thing as Stochastic Gradient Descent assuming the following parameters:\n- `loss` = 'perceptron'\n- `learning_rate` = 'constant'\n- `eta0` = 1 (the learning rate)\n- `penalty` = None (no regularization)\n\nPg 290: Backpropagation is **Gradient Descent** but using an efficient technique for computing the **gradients** automatically.\n- **Forward** | Make prediction, measure total error\n- **Backward** | (in reverse) Go through each layer to measure **each connection's** error contribution\n- **Gradient descent** | Tweak connection weights\n\nBackpropagation computes the gradients of cost function for every model parameter using reverse-mode autodiff\n1. (Forward) Feed into network  \n2. For each layer, the output is found based on **connection** (weight & bias)\n   Note that the connection is not linear so that we can take derivative using the chain rule.\n3. Finds total network error\n4. (Backwards) Uses chain rule to find how much each **connection** contributed to total error working from final layer to initial layer\n5. (Gradient descent) Adjust the connection weights  \n\n\n### Code explanation\nPg 299-316\n\n### Hyperparameters\nPg 323 | [Paper by Leslie Smith](https://arxiv.org/abs/1803.09820)\n\n- **\\# hidden layers**: Start with 1 or 2 hidden layers. Early layers find simple patterns, later layers find complex. Add until we start overfitting.\n- **\\# neurons per hidden layer**: Typically use the same for each (100), but could try adding more neurons to early layers if needed.\n- **Learning rate**: Start by training the model with 300 iterations and a low learning rate ($10^{-5}$) and gradually increase it to 10.\n- **Optimizer**: Ch 11\n- **Batch size**: 32\n- **Activation function**: ReLU for hidden layers, output layer depends on task\n- **\\# of iterations**: Don't worry about it, use Early Stopping instead\n\n### Tips for training NN\n\n**Scaling input data**\n- Standardscaler for numeric\n- [Categorial/Ordinal Guide](https://towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee)\n\n**If bad on training**:\n- Use different activation function (try maxout)\n- Use different learning rate optimizer\n\n**If good on train but bad on test (overfitting)**:\n- Regularization - apply penalty in the loss function if weight and bias is too high from layer to layer\n  - L1 subtracts which is why we are able to get rid of irrelevant features\n  - L2 discounts, which is why the features don't reach 0\n- Early stop - makes regularization not that important - limits epoch - need to be run on validation set\n  - When we increase epoch, we will repeat GD many times. This will decrease error for training data, but we are looking for the min testing error.\n- Drop out\n  - Use separate mini batches - remove a certain percent from each training batch for each layer (Need to multiply all weights by `1 - drop %`)\n  - Training we drop out some neurons, in testing we bring them back and discount their weights\n\n### Why not just add more layers?\n- Vanishing gradient - First layers not nearly as impacted as later stages because much large variance in later stages\n - ReLU - A change in the slope from one neuron to the next will have the same impact on each resulting layer\n   - Problem of Relu - Change of zero will lead to the resulting neuron dying out though\n   - Alternative - Leaky ReLU - very small instead of 0\n   - Alternative - Parametric ReLU - can adjust slope for the \"below 0\" section\n - Batch normalization - Makes sure that the changing distribution of prev layer's inputs aren't impacting us\n - Gradient clipping (for grad explosion) - set a threshold that gradients can't go above/below\n"},{"title":"ML","tags":["ml_"],"path":"/ML/ML","body":"\n> [!summary] Summary\n> Consolidates ML foundations.\n> \n> [Textbook online PDF](https://powerunit-ju.com/wp-content/uploads/2021/04/Aurelien-Geron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-OReilly-Media-2019.pdf)\n\n\n## Overview #cards\n\n>[!quote]\n>**AI** is rooted in mathematics and statistics. When creating an ANN, we're conducting mathematical operations on *data* represented in linear space; it is, by nature, applied mathematics and statistics. ML  *algorithms* are nothing but function approximations; they try and find a mapping between an input and a correct corresponding output. We use algebraic *methods* to create algorithms that learn these mappings.\n>\n>Almost all ML can be expressed in a fairly straight-forward formula; bringing together a dataset and model, along with a loss function and optimization technique that are applicable to the dataset and model. [Source](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/c72aa49d-41f1-4a15-bee5-9efc9190f282.xhtml)\n\n| Term                       | Cake Analogy Explanation                                                  | ML Examples                                                                                                 | ML Definition                                                                                       |\n| -------------------------- | ------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n| **Data**                   | Ingredients.                                                              | Raw dataset                                                                                                 |                                                                                                     |\n| **Method**                 | Deciding to bake a specific type of cake (e.g., birthday cake).           | Supervised learning, classification                                                                         | The broader framework. Combines algorithms, techniques, and strategies to solve a problem.          |\n| **Algorithm**              | The recipe you follow to bake the cake. Defines the step-by-step process. | **For XGBoost**: Gradient Boosting<br><br>**For NNs**: Backpropagation                                      | The *procedure* or set of rules used to train the model. It defines how the model learns from data. |\n| **Model**                  | The finished cake, ready to serve. Represents what has been learned.      | **For XGBoost**: Collection of DTs<br><br>**For NNs**: Network of neurons with learnable weights and biases | The *output* or *representation* of what has been learned.                                          |\n| **Loss Function**          | The taste test. Measures how close the cake is to the desired flavor.     | MSE, cross-entropy                                                                                          |                                                                                                     |\n| **Optimization Technique** | Adjusting the recipe to improve the cake’s flavor (minimize error).       | **For XGBoost**: second-order gradient boosting<br><br>**For NNs**: Adam, etc                               | How you iteratively modify parameters (weights, biases) to minimize error                           |\n\n---\n\n## Introduction\n### Data Mining Tasks \n1) **Classification**: which set of class does this person belong to?\n2) **Regression**: How many hours will this person use our service?\n3) **Similarity matching**: These firms bought from us. Who else is likely to? \n4) **Clustering**: Which segments do our customers fall into? \n5) **Co-occurence** (market basket analysis): For each segment, what are commonly purchased together? \n6) **Profiling**: What is the typical behavior of this segment? \n7) **Link prediction**: You and x share 10 friends. She likes this person, so you prob will too.\n8) **Data reduction**: Dropping unnecessary info thats clouding our insights \n9) **Causal modeling**: What influences our DV? \n\n### Data Mining Process \nThe ML lifecycle includes several steps for transforming data into actionable insights. \n1. **Business Understanding**: Define the problem & success criteria.\n2. **Data Understanding**: How was it collected? Any implicit biases?\n3. **Data Preparation**\n4. **Model**\n    1. **Data Preparation** (possibly)\n    2. **Modeling** (possibly)\n5. **Evaluate**\n6. **Deploy**\n\n---\n## Types of Systems\n```ad-sam\n\nThere are so many different types of ML systems that it is useful to classify them in broad categories based on:\n\n- Are they trained with human supervision? \n  - **Supervised**: Where data includes labels for learning.\n  - **Unsupervised**: Where data lacks explicit labels.\n  - **Semisupervised**: \n  - **Reinforcement**: Where an agent learns by interacting with an environment.\n\n- Can they learn incrementally on the fly?\n  - **Online**: Yes\n  - **Batch**: No\n\n- How do they generalize?\n  - **Instance-based**: Can simply comparing new data points to known data points\n  - **Model-based learning**: Require training data to detect patterns\n\n```\n\n### Human Supervision\n#### Supervised Learning \nDataset contains both inputs & corresponding labels. Tasks include:\n- **Classification**: Discrete categories.\n- **Regression**: Continuous values.\n#### Unsupervised Learning \nIdentifies patterns without labeled data. Key methods are:\n- [[Clustering]]: Group similar data points (k-means, Hierarchical Cluster Analysis (HCA), Expectation Maximization).\n- [[Dimensionality Reduction]]: Simplify datasets without losing too much info.\n    - PCA | Principal Component Analysis\n    - Kernel PCA\n    - LLE | Locally-Linear Embedding\n    - t-SNE | t-distributed Stochastic Neighbor Embedding\n- [[Anomaly detection]]: Identify deviations from normal behavior.\n- [[Association Rules]] (Apriori, Eclat)\n#### Semi-Supervised \nSome data is labeled, some isn't. (Typically lots of unlabeled data + some labeled data) \n- Most of these algorithms are combinations of unsupervised & supervised algorithms.\n- Deep belief networks (DBNs), restricted Boltzmann machines (RBMs)\n#### Reinforcement Learning \n**Process**: The learning system (aka agent) \n1. Observes environment\n2. Performs actions\n3. Gets rewarded \nWith trial-and-error, it teaches itself the best strategy (ie policy) to max reward.\n\n### Learning Type | Batch & Online\n> Another criterion used to classify Machine Learning systems is whether or not the system can learn incrementally from a stream of incoming data. Pg 41\n\n| Learning Type | When      | **Training Process**                                                                                         | **Adaptability** |\n| ------------- | --------- | ------------------------------------------------------------------------------------------------------------ | ---------------- |\n| `BATCH`       | Static    | Train on the entire dataset at once                                                                          | Slow             |\n| `ONLINE`      | Streaming | Model updates iteratively as new data points or mini-batches of data are received. (`Learning rate` is key.) | Fast             |\n### Generalization Type | Model & Instance\n> One more way to categorize Machine Learning systems is by how they generalize. Pg 44\n\n- **Model-Based Learning**: Use training data to build a model, then extrapolate.\n- **Instance-Based Learning**: Use known problems as initial points. Predict new problems based on similarity to old ones.\n    - **Examples**: Case-Based Reasoning, Radial Basis Function Networks, Locally Weighted Regression, Memory-Based Collaborative Filtering, Prototype-Based Learning \n        All these methods depend heavily on **stored data** or a **local region** of the feature space. Predictions or decisions are derived **directly or indirectly from comparisons** to similar instances.\n\n| FEATURE    | Explanation                             | **Prediction**                                                              | Adaptability                       | When                                                                               |\n| ---------- | --------------------------------------- | --------------------------------------------------------------------------- | ---------------------------------- | ---------------------------------------------------------------------------------- |\n| `Instance` | Learn \"by heart\", think look-alikes     | Using a similarity metric. Predictions are `locally-informed`. See example. | High - changes predictions quickly | Intuitive for business users<br><br>Local relationships more important than global |\n| `Model`    | Learns over time with new training data | Using learned parameters                                                    | Low - adding drops to an ocean     | Generalization to unseen data is key                                               |\n\n#### Instanced-Based | Details\n**Analogy**: Think spam detection. Ideally, every spam email would be the same. Model learns this \"by heart\", then flags all identical emails. (In reality, use a *measure of similarity* between 2 emails.)\n\nSteps for **instance-based** regression using k-NN:\n1. **Find the k-NN**:\n    - For a given query instance, calculate distance from all the training instances.\n    - Select $k$. (The number of instances to use.) These are the \"neighbors\" of the query point.\n2. **Predict**: Using these neighbors, compute the average of their target value. Use this as your prediction. (Could use more advanced technique than just average.)\n\n---\n## Challenges of ML \n> In short, since your main task is to select a learning algorithm and train it on some data, the two things that can go wrong are “bad algorithm” and “bad data.”  Pg 50\n\n### Data Issues\n1. **Quantity**: Typically need thousands of examples \n2. **Quality**: Might have too much info missing, could be poorly collected\n3. **Non-representative**: When old cases no longer reflect new cases. Sources:\n    Sampling *noise*: Data is too small\n    Sampling *bias*: Sampling method is flawed.\n4. **Irrelevant features**. Solutions:\n    *Feature selection*: Select only most useful features.\n    *Feature extraction*: Combine existing features to produce meaningful ones.\n    *New features*: Use external sources to create new features.\n\n### Algorithm Issues\n1. **Overfitting** solutions:\n    - Select a model with fewer parameters\n    - Feature reduction\n    - Constrain the model (*regularization*)\n    - Gather more data\n    - Reduce noise in training data\n2. **Underfitting**: Model is too simplistic to capture underlying patterns.\n    - Select a more powerful model, with more parameters \n    - Feeding better features to the learning algorithm (feature engineering)\n    - Reducing the constraints on the model (e.g., reducing the regularization hyper‐parameter)\n---\n## Tuning & Evaluation\n\n### Process | Testing & Validating\n1) **Split**: Split data into train & test. (Usually 80% for training.) \n2) **Validation set**: Use nested k-fold CV to split up training set.\n3) **Train set**: Run multiple models x hyperparameters\n4) **Train set**: Select models x hyperparameter combo with best performance on validation set. \n5) **Test set**: Find **generalization error** for an estimate of performance on unseen data.\n    1) Training good + validation bad = overfitting ([Image](https://i.imgur.com/EkW054R.png))\n    2) Validation good + test bad = overfitting\n    3) Validation bad + test bad = learning rate too high. \n  \n### Hyperparameter Optimization\n> [!quote] Hyperparameters are configuration variables that tell the model what methods to use, as opposed to **model parameters** which are learned during training.\n\nFine-tuning hyperparameters is critical for optimal model performance:\n- **Grid Search**: Exhaustive search over parameter combinations.\n- **Random Search**: Randomly sample parameters to find optimal settings.\n- **Bayesian Optimization**: Use probabilistic models to select parameters.\n\n**Model-type details:**\n\n| Type          | \\# of parameters                | Complexity                       | Scalability with Data Size | Hyperparameters                                                                  |\n| ------------- | ------------------------------- | -------------------------------- | -------------------------- | -------------------------------------------------------------------------------- |\n| PARAMETRIC    | Fixed                           | Lower, less risk of overfitting. | Limited                    | 1. Regularization terms (L1/L2)<br>2. Learning rate<br>3. Small \\# of key params |\n| NONPARAMETRIC | Unconstrained, grows with size. | High, prone to overfitting.      | High                       | Focus on selecting right complexity (e.g., depth of trees).                      |\n\n#### Code\n```python\n# Grid search\nsearch = GridSearchCV(estimator = rf_classifier, param_grid = parameters, cv = 3)\n\n# Apply to training\nsearch.fit(x_train, y_train)  \nsearch.best_params_\n\n# Best combo\nbest = search.best_estimator_  \naccuracy = evaluate(best, x_test, y_test)\n```\n\n\n---\n### Cross-Validation\nCross-validation splits data to validate models. Methods include:\n- **k-Fold**: Divides data into $k$ subsets for training and testing.\n- **Nested**: Addresses hyperparameter overfitting by adding an outer validation loop.\n#### Nested K-Fold\nRemoves overfit \"leak\" from evaluating on train set.\n- Use when hyperparameters also need to be optimized\n- Estimates generalization error of the underlying model & hyperparameters\nProcess\n- **Inner loop**: Fits model to each training set, then select hypers over validation set\n- **Outer loop**: Estimates generalization error by averaging test set scores over several dataset splits\n\n"},{"title":"_ML MOC","tags":[],"path":"/ML/_ML MOC","body":"```dataview\nTABLE without id\n\nfile.link,\ncovers,\n\nQuality,\n\n\"<progress max=\" + \n(sum(HoursDone) + sum(HoursRemain)) + \" value=\" + number(\nsum(HoursDone)) + \"> </progress> \"  + number(\nsum(HoursDone)) + \" of \" + number(\nsum(HoursDone) + sum(HoursRemain)) + \" \" + \"hours\" + \" (\" +round(number(\nsum(HoursDone))/number(\nsum(HoursDone) + sum(HoursRemain))*100) + \"%\" + \")\" as Progress,\n\nsum(HoursRemain) as Remain\nfrom outgoing([[]])\n```\n\n[[TOC]]\n[[ML]]\n[[Advanced]]\n[[DataScienceFolder/AI/ML Ops]]\n[[Deep Learning]]\n"},{"title":"MLflow","tags":[],"path":"/MLflow","body":"```ad-sam\nMLflow is an open-source platform for managing the machine learning (ML) lifecycle, including experimentation, reproducibility, deployment, and model tracking. It was developed by **Databricks** and is now widely used in the industry for MLOps (Machine Learning Operations).\n```\n\n[Tutorials](https://www.mlflow.org/docs/latest/tutorials-and-examples/index.html)\n\n"},{"title":"Duality example","tags":[],"path":"/Optimization/Duality example","body":"\n[Youtube]([https://www.youtube.com/watch?v=642lZIwdSxs&list=PL8uIP3DsMWIxgSIfkKXv0GxJFAazocko3&index=6](https://youtu.be/642lZIwdSxs?si=PzNKPdiHOubCkJCG&t=1657))\n\n![](https://i.imgur.com/DyLqQeW.png)\n\n$x_1$ = units of product 1 we should produce\n$x_2$ = units of product 2 we should produce\n\n---\n##### Part 1: Primal\n$Max: \\:\\: 300x_1 + 200x_2$  |  *Profit*\nst.\n- $2x_1 + 1x_2 \\leq 8$    |  *Machine 1*\n- $1x_1 + 2x_2 \\leq 8$    |  *Machine 2*\n\nWhen we plot the constraints, we find an intersection point of (2.66, 2.66). After plugging in and trying our corner points, this point ends up also being the optimal point. The resulting profit is $1333.\n\n$z = \\$1333$  |  *Profit*\n- $x_1 = 2.66$   |  *Machine 1 units*\n- $x_2 = 2.66$\n\nInstead, increase the available hours for *Machine 1* from 8 hours to 9 hours, we end up with:\n$z = \\$1466$  |  *Profit*\n- $x_1 = 3.33$\n- $x_2 = 2.33$\n---\n##### Part 2: Shadow\n\nThis **Shadow Price** is showing us how our profit changes as we adjust *Machine 1* available hours.\n\n$\\frac{Z_b - Z_a}{M1 \\: capacity \\: to \\: change} = \\frac{1466 - 1333}{1 \\: hour \\: adj} = \\$133.33 / hour$\n\nWhen the objective function is a..\n- **Max**: Shadow price is marginal utility of *relaxing* constraint\n- **Min**: Shadow price is marginal cost of *strengthening* constraint\n---\n##### Tying in together\nThe values we got from relaxing our constraints (shown in Part 2) are conceptually the same as the values we would be willing to sell the raw materials for; in this case, machine hours.\n\n**Primal**: (units to produce)\n$z = \\$1333$  |  *Profit*\n- $x_1 = 2.66$   |  *Machine 1 units*\n- $x_2 = 2.66$\n\n**Dual**: (price where we are willing to sell raw materials instead of producing)\n$z = \\$1333$  |  *Profit*\n- $y_1 = \\$133.33$   |  *Machine 1 price to charge*\n- $y_2 = \\$33.33$\n\n\n---\n\n##### LPsolve\n\n```\n /* Objective function */  \n max: 300 X1 + 200 X2;  \n ​  \n /* Variable bounds */  \n 2 X1 + X2 <= 8;  \n X1 + 2 X2 <= 8;\n```\n"},{"title":"LP Math formula","tags":[],"path":"/Optimization/LP Math formula","body":"\n## Math formula\n\n[Book, page 7](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA11&hl=en) |  [ChatGPT](https://chatgpt.com/share/b16e4fc1-7cd7-494e-8d39-111bb12165ef)\n\n**Formula (canonical form):**\n\n$Maximize \\:\\: z=c^Tx$\n$\\small\\text{where..}$\n$\\small\\text{c = coefs of decision variables (vector)}$\n$\\small\\text{x = decisions variables (vector)}$\n$c^Tx \\small\\text{ = dot product}$\n\n\n$s.t. \\:\\: Ax \\leq b$\n$\\small\\text{where..}$\n$\\small\\text{A = matrix of coefficients for the constraints}$\n$\\small\\text{x = vector of decision variables}$\n$\\small\\text{b = vector representing the RHS of the constraints}$\n\n---\n\n**Example:**\n\n$\\text{Maximize} \\:\\: z= 3x_1 + 5x_2$\n\n$\\text{Subject to:}$\n$2x_1 + 3x_2 \\leq 12$\n$x_1 + 2x_2 \\leq 8$\n$x_1 \\leq 4$\n\n$\\text{Non-negativity:}$\n$x_1 \\geq 0$\n$x_2 \\geq 0$\n\nHere:\n$$C^T = [3 \\:\\: 5]$$\n$$\nx = \\begin{bmatrix}\n    x_{1} \\\\\n    x_{2} \\\\\n\\end{bmatrix} \n\\\\\n$$\n$$A = \\begin{bmatrix}\n    2       & 3 \\\\\n    1       & 2 \\\\\n    1       & 0\n\\end{bmatrix}$$\n$$b = \\begin{bmatrix}\n    12        \\\\\n    8        \\\\\n    4      \n\\end{bmatrix}$$\n\n---\n"},{"title":"LP Notes","tags":[],"path":"/Optimization/LP Notes","body":"[Key Topics (Image)](https://i.imgur.com/fRgtITF.png)\n\nTextbooks\n\n- [Modeling and Solving Linear Programming with R](https://www.omniascience.com/books/index.php/scholar/catalog/book/34)\n- [Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan](https://nyu-cdsc.github.io/learningr/assets/kruschke_bayesian_in_R.pdf)\n- [Introducing Monte Carlo Methods with R](https://moodle2.units.it/pluginfile.php/290154/mod_resource/content/1/Casella%20Robert%20R.pdf)\n\n[[LP Math formula]]\n\n\n| 1H \\| Optimization |                  |                                                              |\n| ------------------ | ---------------- | ------------------------------------------------------------ |\n| March 18           | **Intro**        | Linear programs, integer programs, initial feasible solution |\n| March 23           | **Intro**        | Setting up optimization problems, using R for solving LPs.   |\n| March 25           | **Applications** | Dual problem, branch and bound search, sensitivity analysis, shadow prices. |\n| April 15           | **Non-Linear**   | Langrangian method                                           |\n\n| 2H \\| Bayesian |                                                   |                                                              |\n| -------------- | ------------------------------------------------- | ------------------------------------------------------------ |\n| April 20       | **Introduction to Distributions for Simulations** | Overview of Monte Carlo Simulations, Probability distributions, Random Numbers, PMF/PDF and CDF of Discrete and Continuous Distributions: Bernoulli, Binomial, Geometric, Poisson, Uniform, Exponential, Weibull, Normal, Gamma, Beta |\n| April 22       | **Random Number Generation**                      | RNG implementations in R, RNG from non-standard distributions, Inverse Transforms, General Transformation Methods, Accept Reject Method. |\n| April 27       | **Bayesian Analysis & Applications**              | Bayes Theorem, Informative vs Non-informative Priors, Conjugate priors, Likelihood Function. Approximate Bayesian Computation in R with examples. Application: A/B Testing with Bayesian Computation in R. |\n| April 29       | **Discrete Event Simulation in R**                | Queuing simulations, Tandem queues                           |\n\n---\n\n\n# Lectures\n\n## Wk1 | Linear Optimization\n\n> Linear programs, integer programs, initial feasible solution.\n\n[YT Playlist](https://www.youtube.com/watch?v=9p9MvPS1X7Q&list=PL8uIP3DsMWIzkdOb4710ANbAEg_LNX6H-&index=1)\n\n- 1-4 | Ignore\n- [5](https://www.youtube.com/watch?v=nMC8Lm4q6PM&list=PL8uIP3DsMWIzkdOb4710ANbAEg_LNX6H-&index=5) | Notes below, ignore\n\n[Problem Formulation](https://youtu.be/nMC8Lm4q6PM?si=8CriYQNfz1H6wT8T&t=499)\n\n1. **Define decision variables** | Determine quantity to be optimized.\n2. **Define constraints**\n3. **Define conditions** | Think non-negativity.\n\n---\n\n\n\n## Wk2a | Linear Optimization\n\n> Setting up optimization problems, using R for solving LPs.\n\n[Week 2 | Monday YT Playlist](https://www.youtube.com/watch?v=dZdQOfsZJdA&list=PL8uIP3DsMWIyAXuHDB2Y2ZpV-xcAFw4au)\n\n1. Beer vs ale example graphically. Ignore, in separate note section. \n2. Continued. Ignore.\n3. Practice problem 1. Butcher Shop.\n4. Practice problem 3. Furniture Maker.\n5. Practice problem 2. Universal Mines.\n6. Exercise Problem. Blue Ridge Hot Tubs.\n7. Continued.\n8. Special Case: [**Unbounded Solutions**](https://www.youtube.com/watch?v=xEoFAcFOgWk&list=PL8uIP3DsMWIyAXuHDB2Y2ZpV-xcAFw4au&index=8) & [**Infeasibility**](https://youtu.be/xEoFAcFOgWk?si=YIAtKWAwIklKJBfz&t=275). Why?\n   1. My mistake --> Forgot a constraint\n   2. My mistake --> Wrote as max problem instead of min problem\n   3. My mistake --> Defined constraints incorrectly.\n   4. My mistake --> Error in the inequality sign of the constraint.\n9. Beer vs ale example in R.\n\n---\n\n\n\n## Wk2b | Applications\n\n> Dual problem, branch and bound search, sensitivity analysis, shadow prices.\n\n[Week 2 | Wednesday YT Playlist](https://www.youtube.com/watch?v=jytGeGs4kl0&list=PL8uIP3DsMWIxgSIfkKXv0GxJFAazocko3)\n\n1. Review, intro Simplex ([MIT Chapter](https://web.mit.edu/15.053/www/AMP-Chapter-02.pdf))\n2. **Duality**\n3. **Duality continued, economic interpretation**\n4. **Duality continued, solving with R**\n5. 1 pager: connecting primary & dual. [Strong Duality Theorom](https://www.youtube.com/watch?v=NWxYQQYaWO8&t=445s)\n   1. 1 pager: [see page 4](https://canvas.umn.edu/courses/161932/files/11795212?module_item_id=3709569)\n6. Example: Manufacturing.\n7. Example: Manufacturing (continued). Dual problem.\n8. **Sensitivity Analysis**\n\n\n\n### Dual Problem\n\n[[LP duality example beer ale]]\n\n[ChatGPT](https://chatgpt.com/share/150c6a88-3448-429d-a749-490ca2ba5686): In linear programming (LP), **duality** is a fundamental concept that establishes a relationship between two related optimization problems: the **primal** problem and its **dual** problem. Understanding the dual problem provides valuable insights into the original (primal) problem, offering alternative perspectives, aiding in sensitivity analysis, and sometimes simplifying computations. [These dual variables are also known as \"shadow prices\".](https://youtu.be/hDw970ogeOY?si=jYmwrF198v7IjzqH&t=893)\n\n\n\n### [Strong Duality Theorem](https://youtu.be/NWxYQQYaWO8?si=J8iv7jLpBNnA2yNY&t=445)\n\n[ChatGPT](https://chatgpt.com/share/2ea28ff3-b5f0-4764-a7a2-f81b531144dc): If a linear programming problem (the **primal** problem) has an optimal solution, then its **dual** problem also has an optimal solution, and the optimal values of the objective functions for both the primal and dual problems are equal.\n\n\n\n### [Shadow Price](https://youtu.be/642lZIwdSxs?si=2q0COwQSNqedjlXx&t=1156)\n\n[ChatGPT](https://chatgpt.com/share/432129a8-bc37-44e0-b89f-85a3702fa912): The **shadow price** (also known as the **dual value** or **dual price**) is the value that represents how much the objective function (such as profit or cost) would improve or deteriorate if there were a one-unit increase in the right-hand side (RHS) of a constraint, while keeping all other parameters constant.\n\n> **Shadow price**: The change in the optimal value of the object function when we relax a constraint.\n>\n> --> If the objective function is **utility**, then the shadow price is the marginal utility of relaxing the contraint.\n>\n> --> If the objective function is **cost**, then the shadow price is the marginal cost of strengthening the contraint.\n\n[YouTube](https://youtu.be/a5ceSLFeutk?si=j-SwiXGPn5DC5h8n&t=538): Showing Strong Duality Theorem.\n\n[YouTube](https://youtu.be/8BnphwZJtBY?si=ueLU6dVyrr7KSkGq&t=525): 8:45. Since solving the primal problem is equivalent to solving the dual problem, don't try to \"guess and check\" a bunch of constraint changes in the primal problem. Just solve the dual problem.\n\n---\n\n\n## Wk3a | Applications\n\n[Week 3 | Monday YT Playlist](https://www.youtube.com/watch?v=8BnphwZJtBY&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj)\n\n1. **Review of primal & dual.** \n2. Ex: Furniture Maker.\n3. Ex: Universal Mines.\n4. Ex: Universal Mines (continued). Introducing \"Cplex\" tool as alternative to R.\n5. Ex: Production plan with fixed costs (reading problem)\n6. Ex: Production plan with fixed costs (solve part 1).\n7. Ex: Production plan with fixed costs (solve part 2).\n8. Ex: Purchase plan with decreasing unit costs\n\n\n\n## Wk3b | Applications\n\n[Week 3 | Wednesday YT Playlist](https://www.youtube.com/watch?v=i0Dv5S63YMU&list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&index=1)\n\n1. Ex: A Production Plan with Extra Capacity (reading problem)\n2. Ex: A Production Plan with Extra Capacity (solve part 1 & 2)\n3. Ex: A Production Plan with Extra Capacity (read part 3)\n4. Ex: A Production Plan with Extra Capacity (solve part 3)\n5. Ex: Transportation by Trucks (reading problem)\n6. Ex: Transportation by Trucks (solving problem)\n7. Ex: Production of two models of chairs (reading problem)\n8. Ex: Production of two models of chairs (solve part 1)\n9. Ex: Production of two models of chairs (solve part 2)\n10. Ex: Production of two models of chairs (solve part 3)\n\n\n\n## Wk4a | Applications\n\n[Week 4 | Monday YT Playlist](https://www.youtube.com/watch?v=4RwptG8BKkI&list=PL8uIP3DsMWIx33yWHEYjXW2CCJoRkDGOF)\n\n1. Ex: Hiring and Firing (reading)\n2. Ex: Hiring and Firing (solve part 1)\n3. Ex: Hiring and Firing (solve part 2)\n4. Ex: Planning of Personnel Shifts (reading)\n5. Ex: Planning of Personnel Shifts (solving)\n6. Ex: Staff Scheduling Problem (reading)\n7. Ex: Staff Scheduling Problem (solving)\n8. Ex: Assignment Maximizing Quality (reading)\n9. Ex: Assignment Maximizing Quality (solving)\n\n\n\n\n\n# Textbook\n\n[Modeling and Solving Linear Programming with R](https://www.omniascience.com/books/index.php/scholar/catalog/book/34) (only like 100 pages)\n\n- [Github](https://github.com/jmsallan/linearprogramming)\n\n\n\n## 1 | Intro\n\n> Introduction \n>\n> This book is about using linear programming to help making better decisions in the organizational context. Linear programming is one of the most useful and extensively used techniques of operational research. It is one special case of mathematical optimization , where the function to optimize and the constraints are linear functions of the decision variables. \n\n---\n\n\n\n## 2 | Solving LP\n\n### 2.1 Intro\n\n>  Linear programming is one of the most extensively used techniques in the toolbox of quantitative methods of optimization. Its origins date as early as 1937, when Leonid Kantorovich published his paper \"A new method of solving some classes of extremal problems. Kantorovich developed linear programming as a technique for planning expenditures and returns in order to optimize costs to the army and increase losses to the enemy. The method was kept secret until 1947, when George B. Dantzig published the simplex method for solving linear programming. In this same year, John von Neumann developed the theory of duality in the context of mathematical analysis of game theory.\n\n\n\n> The power of linear programming was greatly enhanced when came the opportunity of solving integer and mixed integer linear programming. In these models all or some of the decision variables are integer, respectively. This field was opened by the introduction of the branch and bound method by Land and Doig. Later other algorithms have appear, like the cutting plane method. These techniques, and the extension of computing availability, have increased largely the possibilities of linear programming. \n\n---\n\n\n\n### 2.2 Problem Formulation\n\n**2.2.1 Linear programming formulation**\n\n> Roughly speaking, the LP problem consists in **optimizing** the value of a linear **objective function** of a vector of **decision variables**, considering that the variables can only take the values defined by a set of linear **constraints**. \n\n- **Objective function**: value we want to optimize\n- **Decision Variables**: values we want to determine (vector)\n- **Linear Constraints**: constrains values of the Decision Variables\n\n*Written out in mathematical form in doc called \"Optimization Notes\"*.\n\n\n\n**2.2.2 A simple example of a PL model**: Example showing how to set up the problem. (See 2.6.1 for R code.)\n\n**2.2.3 A transportation problem**: Same ^\n\n**2.2.4 Transformations of elements of a LP**: How to transform a \"MAX\" problem into a \"MIN\" problem.\n\n\n\n**2.2.5 Turning a PL into standard form**\n\n> A usual transformation of a PL model is turning all constraints into equalities adding slack and excess variables. This is required to solve the PL using any version of the simplex algorithm. \n\n\n\n### 2.3 Solving\n\n> The most extended procedure to solve the LP is the **simplex algorithm**, developed by George Bernard Dantzig in 1947. \n\n> The software that solves LPs uses usually the **simplex** algorithm, or the **revised simplex** algorithm, a variant of the original simplex algorithm that is implemented more efficiently on computers. Other algorithms exist for **particular LP problems**, such as the transportation or trans-shipment problem, or the maximum flow problem. \n>\n> Another approach to solve LPs is the interior point algorithm, developed by Narenda Karmarkar [4]. This algorithm has been proven as partic- ularly useful in large problems with sparse matrices. Contrarily to the simplex approach, this algorithm starts from a point inside the feasible region, and approaches the optimum iteratively. \n\n\n\n### 2.4 Duality in LP\n\n>  Let’s consider a MAX linear program in its canonical form. The following linear program, expressed in MIN canonical form, is the **dual** of the program above, called the **primal**.\n\n\n\n**2.4.2 Properties of the primal-dual relationship** \n\n- **The dual of dual is the primal** \n- **Optimum of primal and dual**: If a linear program has a bounded optimum, its primal has also a bounded optimum and both have the same value.\n- **Dual variables as shadow prices**: The values of the dual variables in the optimum represent the shadow price of the constraints of the primal. \n\n[[Duality example]]\n\n\n\n### 2.5 Integer and mixed-integer linear programming \n\n**Integer** linear programming (ILP): When *all* decisions variables need to be integers.\n\n**Mixed integer** linear programming (MILP): When *a subset* of decisions variables need to be integers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"LP duality example beer ale","tags":[],"path":"/Optimization/LP duality example beer ale","body":"\n\n## Beer vs Ale\n\n1. [From Week 1 Playlist | Problem Formulation](https://youtu.be/nMC8Lm4q6PM?si=tWgUZeQQjgBCSlGJ&t=959) \n2. [From Week 2 Monday Playlist | Solving Graphically](https://youtu.be/dZdQOfsZJdA?si=ayUbx0hQ1qLi8B7M)\n3. [From Week 2 Monday Playlist | Solving with R](https://www.youtube.com/watch?v=xfkdt0geeHY&list=PL8uIP3DsMWIyAXuHDB2Y2ZpV-xcAFw4au&index=9)\n4. [From Week 2 Wednesday Playlist | Dual Problem](https://www.youtube.com/watch?v=HMrq1HPAkzc&list=PL8uIP3DsMWIxgSIfkKXv0GxJFAazocko3&index=2) --> [Economic Interpretation](https://www.youtube.com/watch?v=hDw970ogeOY&list=PL8uIP3DsMWIxgSIfkKXv0GxJFAazocko3&index=3) --> [R Code](https://www.youtube.com/watch?v=F3PsccapBrA&list=PL8uIP3DsMWIxgSIfkKXv0GxJFAazocko3&index=4)\n\n\n\n**Optimization**: Modeling where we need to max/min value that is subject to some parameters with constraints \n\n**Objective function**: what needs to be maximized, subject to constraints\n\n<img src=\"https://i.imgur.com/7zICd6P.png\" style=\"zoom:50%;\" />\n\n*Note that X = ale, Y = beer*\n\n*Later on in the dual problem, the Available Quantities will be a, b, and c*\n$$\n\\text{\"Primal\"} \\\\\nZ = max(13x + 23y) \\\\\nSubject \\: to: \\\\\nCorn: \\quad 5x + 15y \\leq 480 \\\\\nHops: \\quad 4x + 4y \\leq 160 \\\\\nMalt: \\quad 35x + 20y \\leq 1190 \\\\\nx, y \\geq 0\n\n\\\\\\\\\\\\\n\n\\text{\"Dual\"} \\\\\nZ \\star = min(480a + 160b + 1190c) \\\\\nSubject \\: to: \\\\\nAle: \\quad 5a + 4b + 35c \\geq 13 \\\\\nBeer: \\quad 15a + 4b + 20c \\geq 23 \n\n\\\\\\\\\\\\\n\n\\text{Solution} \\\\\nZ = Z \\star = \\$800 \\\\\nX = Ale = \\text{12 to produce} \\\\\nY = Beer = \\text{28 to produce}\n$$\n\n*Feasible* *region* is a region of possible solutions where all (linear) constraints are satisfied. Optimal point will be one of the corner points. It will be the outermost point that touches the slope from our objective function.\n\n- **Y**: Beer that can be produced (\\$23 profit per barrel)\n- **X**: Ale that can be produced (\\$13 profit per barrel)\n- **Result**: $800 in profit, this occurs at (12, 28)\n\n<img src=\"https://i.imgur.com/fSt6ESQ.png\" style=\"zoom:40%;\" />\n\nSpecial Cases of Feasible Region\n\n1. **Unbounded regions**: when we have constraints moving in opposite directions\n\n2. **Infeasibility**: no overlap between our constraints\n\n   Why can these occur?\n\n   1. Maybe we forgot a constraint\n   2. Maybe we defined constraints incorrectly\n   3. Maybe we are trying to min - the \"inner\" line is all that matters\n   4. Maybe we have a sign incorrect \n\n<img src=\"https://i.imgur.com/7zICd6P.png\" style=\"zoom:50%;\" />\n\n```python\n# Max function\nc_ex1 = np.array([13, 23])     # Profit\n\n# Inequality constraints\nA_ex1 = np.array([\n    [5, 15],                   # Corn\n    [4, 4],\t\t\t\t\t\t\t\t\t\t # Hops\n    [35, 20]\t\t\t\t\t\t\t\t\t # Malt\n    ])\n\n# Available quantities\nb_ex1 = np.array([480,160,1190])\n\n# we put a negative sign on the objective as linprog does minimization\nres_ex1 = linprog(-c_ex1, A_ub=A_ex1, b_ub=b_ex1, method='revised simplex')\n\nres_ex1\n\n# Results:\n  # fun: -800\n  # x: array([12, 28])\n\n# The optimal plan says to produce 12 ale and 28 beer; that generates a maximizing value of revenue of $800.\n```\n\n\n\n### General Solution\n\n**C**:   Profit from ale and beer\n**X**:   Decision variables (how much beer / ale should we produce?)\n**A**:   6 coefficient values from constraints\n**b**:   Available quantities we have of each raw material\n**u**:   Decision variables (how much would we sell each raw material for instead)?\n\n[Image 1](https://i.imgur.com/xBoaNH2.png), [Image 2](https://i.imgur.com/5SmtZcs.png), [Image 3](https://i.imgur.com/eA8xexD.png)\n\n**Theorem (Strong Duality):** Objective Function Equal at Optimal Values\n\n$c^T * x' = b^T * u'$ \n\n- $c^T$ = Primal objective function  \n- $x'$ = Primal optimal solution  \n- $b^T$ = Dual objective function\n- $u'$ = Dual optimal solution  \n\n\n\n### Part 1: Primal \n\nSolving for profit max\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function\n\n- $Obj: Max(Profit) = Max(13x + 23y)$\n\nStep 2: Define constraints mathematically\n\n- (Corn)   |  $5x + 15y \\leq 480$\n- (Hops)  |   $4x + 4y \\leq 160$     \n- (Malt)   |    $35x + 20y \\leq 1190$\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- $x >= 0, y >= 0$\n\n\n\n### Part 2: Dual\n\nSolving for shadow price\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function\n\n- $Obj: Min(Cost) = 480a + 160b + 1190c$\n\nStep 2: Define constraints mathematically\n\n- $st: 5a + 4b + 35c \\geq 13$ \n- $st: 15a + 4b + 20c \\geq 23$ \n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- $a, b, c >= 0$\n\nResult:\n\n- $Total \\: Profit \\: = 800$\n- $a = \\$1, \\: b = \\$2, \\: c = \\$0$\n\n---\n\n### Sensitivity Analysis\n\nWhat happens if our per-unit profits change?\n\n$$\nZ = \\text{Slope of Obj Function} \\\\\n\nC_1 = \\text{Product 1 Unit Profit} \\\\\n\nX_1 = \\text{Product 1 Required Hours} \\\\\n\nX_2 = -1 * \\frac{c_1}{c_2} * x_1 + \\frac{v}{c_2}\n$$\nAs long as the slope of the obj function is between the slopes of our 2 constraints, the optimal point will be where the 2 constraints intersect.\n"},{"title":"More optim examples","tags":[],"path":"/Optimization/More optim examples","body":"## Examples\n\n### Min cost\n\n#### Primal Example: Min cost (Problem 1)\n\nMeat loaf = beef (x) + pork (y). Minimize cost, keep the fat content <= 25%\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function\n\n- Beef costs 80 cents per pound, pork costs 60 cents\n- $Obj: Min(Cost) = .8x + .6y$\n\nStep 2: Define constraints mathematically\n\n- $Fat: .2x + .32y \\leq .25$ \n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- $x >= 0, y >= 0$\n- $x + y = 1$\n\n\n\n<img src=\"https://i.imgur.com/HnyXvoV.jpg\" style=\"zoom:50%;\" />\n\n\n\n```cplex\n/* Objective function */\nmax: 300 X1 + 200 X2;\n\n/* Variable bounds */\n2 X1 + X2 <= 8;\nX1 + 2 X2 <= 8;\n```\n\n---\n\n### 1: Production\n\n[Youtube](https://www.youtube.com/watch?v=q1gG1-RnZug&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj&index=6)\n\n*End result is that we should produce 400, 400, 50, 0.*\n\n*q1* = quantity to produce in 1st month\n\n*s1* = quantity to stock at end of 1st month\n\n| Month              | 1       | 2       | 3       | 4       |\n| ------------------ | ------- | ------- | ------- | ------- |\n| **Total Cost**     | **$12** | **$14** | **$16** | **$18** |\n| Labor Cost         | $6      | $6      | $6      | $6      |\n| Unit Cost          | $6      | $8      | $10     | $12     |\n|                    |         |         |         |         |\n| **Demand**         | **100** | **200** | **150** | **400** |\n|                    |         |         |         |         |\n| **Total Capacity** | **400** | **400** | **300** | **300** |\n| Available Hours    | 200     | 200     | 150     | 150     |\n\n- $2 for each unit not sold by end of month\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function. We are looking to min cost of production and min cost of storage.\n\n- $Obj: Z = Min(12q_1 + 14q_2 + 16q_3 + 18q_4 + 2s_1 + 2s_2 + 2s_3 + 2s_4)$\n\nStep 2: Define constraints mathematically. In this case, the constraints are our demand.\n\n- (Month 1)   |  $q_1 - s_1 = 100$\n- (Month 2)   |  $s_1 + q_2 - s_2 = 200$\n- (Month 3)   |  $s_2 + q_3 - s_3 = 150$\n- (Month 4)   |  $s_3 + q_4 - s_4 = 400$\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Total capacity constraints)  |  $q_1 \\leq 400, q_2 \\leq 400, q_3 \\leq 300, q_4 \\leq 300$\n- (Non-negative)  |  Each $s$ can't be negative, each $q$ can't be negative\n\n```\n/* Objective function */\nmin: 12q1 + 14q2 + 16q3 + 18q4 + 2s1 + 2s2 + 2s3 + 2s4;\n\n/* Variable bounds */\nc1: q1-s1 =100;\nc2: s1+q2-s2=200;\nc3: s2+q3-s3=150;\nc4: s3+q4-s4=400;\nc5: q1-400<=0;\nc6: q2-400<=0;\nc7: q3-300<=0;\nc8: q4-300<=0;\n```\n\n---\n\n[Youtube](https://www.youtube.com/watch?v=_VpKE4Lou_w&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj&index=7)\n\nNow we are making a slight adjustment: there is a fixed cost every month for $1,000 if we produce anything.\n\n*End result is that we should produce 150, 400, 300, 0.*\n\nAdjustments:\n\n- (Obj function) Add $1000b_i$\n- (Total capacity constraints, c5:c8)  |  Multiply $b_i$ with capacity values\n\n```\n/* Objective function */\nmin: 12q1 + 14q2 + 16q3 + 18q4 + 2s1 + 2s2 + 2s3 + 2s4  + 1000b1 + 1000b2 + 1000b3 + 1000b4;\n\n/* Variable bounds */\nc1: q1 - s1 = 100;\nc2: s1 + q2 - s2 = 200;\nc3: s2 + q3 - s3 = 150;\nc4: s3 + q4 - s4 = 400;\nc5: q1 - 400b1 <= 0;\nc6: q2 - 400b2 <= 0;\nc7: q3 - 300b3 <= 0;\nc8: q4 - 300b4 <= 0;\n\nbin b1;\nbin b2;\nbin b3;\nbin b4;\n```\n\n---\n\n### 2: Purchasing, Decreasing Costs\n\n[Youtube](https://www.youtube.com/watch?v=D8migSjrxQw&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj&index=8)\n\n*$q_1$* = quantity to purchase in 1st month $\\leq 200$\n\n*$r_1$* = quantity to purchase in 1st month $> 200$\n\n*$s_1$* = quantity to stock at end of 1st month\n\n*$b_1$* = 1 if we should go above 200 in the month\n\n| Month                            | 1       | 2       | 3       | 4       |\n| -------------------------------- | ------- | ------- | ------- | ------- |\n| **Unit Cost (before 200 units)** | **$12** | **$14** | **$16** | **$18** |\n| **Unit Cost (after 200 units)**  | **$10** | **$12** | **$14** | **$16** |\n| **Total Capacity**               | **200** | **200** | **200** | **200** |\n| **Demand**                       | **150** | **200** | **250** | **150** |\n\n- All units purchased above 200 in any given month will have a discounts of $2\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function. \n\n$Obj: Z \\\\ = Min(12q_1 + 14q_2 + 16q_3 + 18q_4 \\\\ + 2s_1 + 2s_2 + 2s_3 + 2s_4 \\\\ + 10r_1 + 12r_2 + 14r_3 + 16r_4)$\n\nStep 2: Define constraints mathematically. \n\n- (Month 1)   |  $q_1 + r_1 - s_1 = 150$\n- (Month 2)   |  $s_1 + q_2 + r_2 - s_2 = 200$\n- (Month 3)   |  $s_2 + q_3 + r_3 - s_3 = 250$\n- (Month 4)   |  $s_3 + q_4 + r_4 - s_4 = 150$\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Total capacity constraints)  |  $q_1 \\leq 200, q_2 \\leq 200, q_3 \\leq 200, q_4 \\leq 200$\n- (Non-negative)  |  Each $s$ can't be negative, each $q$ can't be negative\n- We are going to say that $r_i$ has to be less than some huge number to make sure we don't hit infinity\n\n```\n/* Objective function */\nmin: 12 q1 + 14 q2 + 16 q3 + 18 q4 + 10 r1 + 12 r2 + 14 r3 + 16r4 + 2s1 + 2s2 + 2s3 + 2s4;\n\n/* Variable bounds */\nd1: q1 +r1 - s1 = 150;\nd2: s1 + q2 + r2 - s2 = 200;\nd3: s2 + q3 + r3 - s3 = 250;\nd4: s3 + q4 + r4 - s4 = 150;\nl1: q1 - 200 b1 >= 0;\nl2: q2 - 200 b2 >= 0;\nl3: q3 - 200 b3 >= 0;\nl4: q4 - 200 b4 >= 0;\nm1: r1 - 10000 b1 <= 0;\nm2: r2 - 10000 b2 <= 0;\nm3: r3 - 10000 b3 <= 0;\nm4: r4 - 10000 b4 <= 0;\n\n0 <= q1 <= 200;\n0 <= q2 <= 200;\n0 <= q3 <= 200;\n0 <= q4 <= 200;\n\nbin b1;\nbin b2;\nbin b3;\nbin b4;\n```\n\n---\n\n### 3: Production, Increasing Costs\n\n[Youtube](https://www.youtube.com/watch?list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&v=i0Dv5S63YMU&feature=emb_title)\n\n- Monthly capacity = 1,300 tonnes\n- Storage cost = $2k per tonne\n- Initial stock = 200 tonnes\n- Ending stock = need to have 200 tonnes\n\n![](https://i.imgur.com/ubrVM8u.png)\n\n- $q$ = tonnes to produce\n- $s$ = tonnes to stock at end of each month\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n- $Obj: Z \\\\ = Min(3q_1 + 8q_2 + 6q_3 + 7q_4 \\\\ + 2s_1 + 2s_2 + 2s_3 + 2s_4)$\n\n\n\nStep 2: Define constraints mathematically. In this case, the constraints are our demand.\n\n- For the following 4 months: $Starting \\: stock + q_i = demand + s_i$\n- (Month 1)   |  $200 + q_1 = 800 + s_1$\n- (Month 2)   |  $s_1 + q_2 = 900 + s_2$\n- (Month 3)   |  $s_2 + q_3 = 1200 + s_3$\n- (Month 4)   |  $s_3 + q_4 = 1800 + s_4$\n- (Starting)   |   $s_0 = 200$\n- (Ending)     |   $s_4 = 200$\n\n\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Total capacity constraints)  |  $q_1, q_2, q_3, q_4 \\leq 1300$\n- (Min production))  |  $q_1, q_2, q_3, q_4 \\geq 0$\n- (Storage non-negative)  |  $s_i \\geq 0$\n\n```\n/* Objective function */\nmin: 3q1+8q2+6q3+7q4+2s1+2s2+2s3+2s4;\n\n/* Variable bounds */\nd0: s0=200;\nd1: q1+s0-s1=800;\nd2: s1+q2-s2=900;\nd3: s2+q3-s3=1200;\nd4: s3+q4-s4=1800;\nd5: s4=200;\n\n0<=q1<=1300;\n0<=q2<=1300;\n0<=q3<=1300;\n0<=q4<=1300;\n```\n\n*What is the meaning of the dual variables of the constraints defined in the model?*\n\nThe dual variables here are what we looked at in Step 2 and Step 3. Generally, they each show how a marginal change in the constraint (the RHS) will impact our objective function.\n\n(For demand, Step 2) Here, they show how cost (our objective function) increases as we increase demand (our constraint).\n\n(For capacity, Step 3) Here they show how our total cost (the objective function) decreases as we relax the available amount we can produce each month.\n\n---\n\n#### b. Add new shift\n\n- Should we add a new shift? \n  - Would increase plant capacity in 400 tonnes per month\n  - Would include an extra fixed cost of $500k \n  - For legal reasons, it is not possible to add extra capacity in a month if it has been added in the previous month.\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z \\\\ = Min(3q_1 + 8q_2 + 6q_3 + 7q_4 \\\\ + 2s_1 + 2s_2 + 2s_3 + 2s_4\\\\ + 500(b_1 + b_2 + b_3 + b_4)$\n\n\n\nStep 2: Define constraints mathematically. In this case, the constraints are our demand.\n\n- For the following 4 months: $Starting \\: stock + q_i = demand + s_i$\n- (Month 1)   |  $200 + q_1 = 800 + s_1$\n- (Month 2)   |  $s_1 + q_2 = 900 + s_2$\n- (Month 3)   |  $s_2 + q_3 = 1200 + s_3$\n- (Month 4)   |  $s_3 + q_4 = 1800 + s_4$\n- (Starting)   |   $s_0 = 200$\n- (Ending)     |   $s_4 = 200$\n\n\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Total capacity constraints) \n  - $q_1 \\leq 1300 + 400b_1$\n  - $q_2 \\leq 1300 + 400b_2$\n  - $q_3 \\leq 1300 + 400b_3$\n  - $q_4 \\leq 1300 + 400b_4$\n- (Min production))  |  $q_1, q_2, q_3, q_4 \\geq 0$\n- (Storage non-negative)  |  $s_i \\geq 0$\n- $b_1$ = binary\n- (Binary alternating constraint)\n  - $b_1 + b_2 \\leq 1$\n  - $b_2 + b_3 \\leq 1$\n  - $b_3 + b_4 \\leq 1$\n\n```\n/* Objective function */\nmin: 3q1+8q2+6q3+7q4+2s1+2s2+2s3+2s4+500b1+500b2+500b3+500b4;\n\n/* Variable bounds */\nd0: s0=200;\nd1: q1+s0-s1=800;\nd2: s1+q2-s2=900;\nd3: s2+q3-s3=1200;\nd4: s3+q4-s4=1800;\nd5: s4=200;\n\nq1-400b1<=1300;\nq2-400b2<=1300;\nq3-400b3<=1300;\nq4-400b4<=1300;\nb1+b2<=1;\nb2+b3<=1;\nb3+b4<=1;\nbin b1;\nbin b2;\nbin b3;\nbin b4;\n```\n\n---\n\n### 4: Transportation\n\n[Youtube](https://www.youtube.com/watch?v=Ci4wmBHDgxU&list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&index=5)\n\n- Storage cost = $8k per tonne\n- Initial stock = 100 tonnes\n- Ending stock = needs to be 100 tonnes\n- Small trucks\n  - Cost = $700k\n  - Capacity = 500 tonnes\n- Large trucks\n  - Cost = $1,400k\n  - Capacity = 1,200 tonnes\n\n\n\n![](https://i.imgur.com/QN2EBSO.png)\n\n- $q$ = tonnes to produce\n- $s$ = tonnes to stock at end of each month\n- $t$ = number of small trucks\n- $u$ = number of large trucks\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Min \\: Z = \\sum c_i * q_i + 8s_i + 700k_i + 1400u_i$\n\n\n\nStep 2: Define constraints mathematically. In this case, the constraints are our demand.\n\n- For the following 4 quarters: Last quarter stock + quantity we produce = demand + ending stock\n\n- (Demand)  |  $s_{i-1} + q_i = d_i+ s_i$\n\n- (Demand re-written)  |  $s_{i-1} + q_i  - s_1 = d_i$\n\n- (Starting)   |   $s_0 = 100$\n\n- (Ending)     |   $s_4 = 100$\n\n  \n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Trucks)      |   $q_i \\leq 500t_i + 1200u_i$\n\n- (Min production))  |  $q_1, q_2, q_3, q_4 \\geq 0$\n\n- (Storage non-negative)  |  $s_i \\geq 0$\n\n  \n\n```\n/* Objective function */\nmin:20 q1 + 25 q2 + 30 q3 + 40 q4 + 8 s1 + 8 s2 + 8 s3 + 8 s4 + 700 t1 + 700 t2 + 700 t3 + 700 t4 + 1400 u1 + 1400 u2 + 1400 u3 + 1400 u4 ;\n\n\n/* Variable bounds */\ns0 = 100;\ns0 + q1 - s1 = 1000;\ns1 + q2 - s2 = 1200;\ns2 + q3 - s3 = 1500;\ns3 + q4 - s4 = 1800;\nq1 - 500 t1 - 1200 u1 <= 0;\nq2 - 500 t2 - 1200 u2 <= 0;\nq3 - 500 t3 - 1200 u3 <= 0;\nq4 - 500 t4 - 1200 u4 <= 0;\ns4 = 100;\nint t1;\nint t2;\nint t3;\nint t4;\nint u1;\nint u2;\nint u3;\nint u4;\n\n```\n\n\n\n---\n\n### 5: Building Products\n\n- Can buy wood for $80 / block\n  - 1 block = 10 seats, 20 legs, 2 backs\n- Need to produce at least 1k chairs\n\n![](https://i.imgur.com/8uxJwWs.png)\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z = Min(30q_1 + 40q_2 + 80q_3)$\n\n\n\nStep 2: Define constraints mathematically.\n\n- (Legs)   |  $4q_1 + 3q_2 \\leq 200 + 10q_3$\n\n- (Seats)   |  $q_1 + q_2 \\leq 500 + 20q_3$\n\n- (Backs)   |  $q_1 \\leq 100 + 2q_3$\n\n- (Demand)   |  $q_1 + q_2 \\geq 1000$\n\n  \n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Integer and non-neg)      |   $q_1, q_2, q_3 \\geq 0$\n- (Min production)  |  $q_1 + q_2 \\geq 1000$\n\n```\n/* Objective function */\nmin: 80q3 + 30q1 + 40q2;\n\n/* Variable bounds */\n\nq1 + q2 - 10q3 <= 500;\n4q1 + 3q2 - 20q3 <= 200;\nq1 - 2q3 <= 100;\nq1 + q2 >= 1000;\n\nint q2;\nint q1;\nint q3;\n```\n\n\n\n\n\n---\n\n#### b. Only Make 1 Product\n\nIn order to get the program to choose between $q_1$ and $q_2$, we are going to use \"M\" as a large number to make the cost of producing both look huge. This is translated in \"Additional constaints\" below.\n\n- $q_1 \\leq = M * b$      and also that     $q_2 \\leq M(1 - b)$\n\n  \n\nAdditional constraints\n\n- $b$ is binary\n- $q_2 - 10,000*b \\leq 0$\n- $q_1 + 10,000 * b \\leq 10,000$\n\n```\n/* Objective function */\nmin: 80q3 + 30q1 + 40q2;\n\n/* Variable bounds */\n\nq1 + q2 - 10q3 <= 500;\n4q1 + 3q2 - 20q3 <= 200;\nq1 - 2q3 <= 100;\nq1 + q2 >= 1000;\n\nq1 - 10000b<=0;\nq2 + 10000b<=10000;\n\nint q2;\nint q1;\nint q3;\n\nbin b;\n```\n\n---\n\n#### c. 4x more\n\nThe CEO wants to produce 4 times more Model A than Model B.\n\nAdditional constraints (relative to Part 2)\n\n- $4 * q_2 \\leq q_1$\n\n```\n/* Objective function */\nmin: 80q3 + 30q1 + 40q2;\n\n/* Variable bounds */\nq1 + q2 - 10q3 <= 500;\n4q1 + 3q2 - 20q3 <= 200;\nq1 - 2q3 <= 100;\nq1 + q2 >= 1000;\n\nq1 - 4q2 >= 0;\n\nint q2;\nint q1;\nint q3;\n\n```\n\n\n\n---\n\n### 6: Hiring and Firing\n\n- Salary = 8k per month\n- Initial staff = 20 people\n- Cost of firing = $10k\n- Cost of hiring = $5k\n- We need to at least meet demand\n\n![](https://i.imgur.com/KK8zpB7.png)\n\n- $h$ = number of pilots we hired last month\n- $f$ = number of pilots we fired last month\n- $s$ = number of pilots during the month\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z = Min \\:\\: \\sum5h_i + \\sum10f_i + \\sum8s_i$\n\n\n\nStep 2: Define constraints mathematically.\n\n- (Per month)   |  $s_i = h_i - f_i + s_{i-1}$\n\n\n\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Starting)   |  $s_0 = 20$\n- (Demand)   |   $s_i \\geq d_i$\n- (Non-neg)   |   $h, f, s \\geq 0$\n\n```\nmin: 5 h1 + 5 h2 + 5 h3 + 5 h4 + 5 h5 + 5 h6 + 10 f1 + 10 f2 + 10 f3 + 10 f4 + 10 f5 + 10 f6 + 8 s1 + 8 s2 + 8 s3 + 8 s4 + 8 s5 + 8 s6;\n\n/* Variable bounds */\nsini: s0 = 20;\nsm1: s0 + h1 - f1 - s1 = 0;\nsm2: s1 + h2 - f2 - s2 = 0;\nsm3: s2 + h3 - f3 - s3 = 0;\nsm4: s3 + h4 - f4 - s4 = 0;\nsm5: s4 + h5 - f5 - s5 = 0;\nsm6: s5 + h6 - f6 - s6 = 0;\n\n s1 - 30 >= 0;\n s2 - 60 >= 0;\n s3 - 55 >= 0;\n s4 - 40 >= 0;\n s5 - 45 >= 0;\n s6 - 50 >= 0;\n```\n\n\n\n#### b. New constraint\n\nCan't fire if we hired last month\n\nGenerally, we are setting a binary variable that has $b_i = 1$ if we hired in the month and a corresponding $f_{i+1} = 0$ if we did.\n\nWe do this by adding in a large number as \"M\" which will make it look extremely expensive to hire and then fire. We are setting \"M\" as 1000 in the code below.\n\n- (Hire this month)   |   $h_i \\leq Mb_i$\n- (Fire next month)   |   $f_{i+1} \\leq M(1- b_i)$\n\n```\n/* Objective function */\nmin: 5 h1 + 5 h2 + 5 h3 + 5 h4 + 5 h5 + 5 h6 + 10 f1 + 10 f2 + 10 f3 + 10 f4 + 10 f5 + 10 f6 + 8 s1 + 8 s2 + 8 s3 + 8 s4 + 8 s5 + 8 s6;\n\n/* Variable bounds */\nsini: s0 = 20;\nsm1: s0 + h1 - f1 - s1 = 0;\nsm2: s1 + h2 - f2 - s2 = 0;\nsm3: s2 + h3 - f3 - s3 = 0;\nsm4: s3 + h4 - f4 - s4 = 0;\nsm5: s4 + h5 - f5 - s5 = 0;\nsm6: s5 + h6 - f6 - s6 = 0;\nhf01: h1 - 1000 b1 <= 0; /*if you hire in month 1 ie b1 = 1 */\nhf02: h2 - 1000 b2 <= 0;\nhf03: h3 - 1000 b3 <= 0;\nhf04: h4 - 1000 b4 <= 0;\nhf05: h5 - 1000 b5 <= 0;\nhf06: f2 + 1000 b1 <= 1000;  /* you cannot fire in month 2 since f2 = 0 */\nhf07: f3 + 1000 b2 <= 1000;\nhf08: f4 + 1000 b3 <= 1000;\nhf09: f5 + 1000 b4 <= 1000;\nhf10: f6 + 1000 b5 <= 1000;\n\n s1 - 30 >= 0;\n s2 - 60 >= 0;\n s3 - 55 >= 0;\n s4 - 40 >= 0;\n s5 - 45 >= 0;\n s6 - 50 >= 0;\n\nint h1,h2,h3,h4,h5,h6,f1,f2,f3,f4,f5,f6;\nbin b1,b2,b3,b4,b5,b6;\n```\n\n\n\n---\n\n### 7: Shift Planning\n\n- 6 shifts, 4 hours each\n- Each person works 2 consecutive shifts\n\n<img src=\"https://i.imgur.com/F4eutX5.png\" style=\"zoom:50%;\" />\n\n$s_i$ = employees per shift\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z = Min \\:\\: \\sum s_i $\n\n\n\nStep 2: Define constraints mathematically.\n\n- (Per shift) \n  - $s_6 + s_1 \\geq 5$ \n  - $s_1 + s_2 \\geq 7$\n  - $ s_2 + s_3 \\geq 18$\n  - $s_3 + s_4 \\geq 12$ \n  - $s_4 + s_5 \\geq 15$ \n  - $s_5 + s_6 \\geq 10$\n\n\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Int and non-neg)   |  $s_i \\geq 0$\n\n```\n/* Objective function */\nmin:s1 + s2 + s3 + s4 + s5 + s6 ;\n\n/* Variable bounds */\ns6 + s1 >= 5;\ns1 + s2 >= 7;\ns2 + s3 >= 18;\ns3 + s4 >= 12;\ns4 + s5 >= 15;\ns5 + s6 >= 10;\nint s1;\nint s2;\nint s3;\nint s4;\nint s5;\nint s6;\n```\n\n---\n\n### 8: Employee day planning\n\n[Youtube](https://www.youtube.com/watch?v=tGfDYeXQT74&list=PL8uIP3DsMWIx33yWHEYjXW2CCJoRkDGOF&index=6)\n\n- Each person must work 5 consecutive days and then take 2 consecutive days off\n\n![](https://i.imgur.com/3E3u5Ar.png)\n\n$s_i$ = number of employees that start working per day, Monday is $s_1$\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z = Min \\:\\: \\sum s_i $\n\n\n\nStep 2: Define constraints mathematically.\n\n- (Monday)   |    $s_1 + s_4 + s_5 + s_6 + s_7 \\geq 17$ \n  - This is everyone except for people who started working on Tuesday and Wednesday\n\n\n\nStep 3: Express hidden conditions (eg can't be negative, has to be integer, etc)\n\n- (Int and non-neg)   |  $s_i \\geq 0$\n\n```\n/* Objective function */\nmin: x1+x2+x3+x4+x5+x6+x7;\n\n/* Variable bounds */\nx1+x4+x5+x6+x7 >= 17;\nx1+x2+x5+x6+x7 >=13;\nx1+x2+x3+x6+x7 >=15;\nx1+x2+x3+x4+x7 >=19;\nx1+x2+x3+x4+x5 >=14;\nx2+x3+x4+x5+x6 >=16;\nx3+x4+x5+x6+x7 >=11;\n\nint x1,x2,x3,x4,x5,x6;\n```\n\n\n\n---\n\n### 9: Assignment Maximizing Quality\n\n<img src=\"https://i.imgur.com/XcN6S0m.png\" style=\"zoom:50%;\" />\n\n- 1 course per teacher\n\n```\n/* Objective function */\nmax: 34 b11 + 87 b12 + 26 b13 + 47 b14 + 76 b15\n+ 43 b21 + 90 b22 + 24 b23 + 63 b24 + 97 b25\n+ 60 b31 + 65 b32 + 64 b33 + 83 b34 + 54 b35\n+ 89 b41 + 62 b42 + 39 b43 + 37 b44 + 18 b45\n+ 27 b51 + 15 b52 + 69 b53 + 93 b54 + 96 b55;\n\n/* Variable bounds */\n b11 + b12 + b13 + b14 + b15 = 1;\n b21 + b22 + b23 + b24 + b25 = 1;\n b31 + b32 + b33 + b34 + b35 = 1;\n b41 + b42 + b43 + b44 + b45 = 1;\n b51 + b52 + b53 + b54 + b55 = 1;\n b11 + b21 + b31 + b41 + b51 = 1;\n b12 + b22 + b32 + b42 + b52 = 1;\n b13 + b23 + b33 + b43 + b53 = 1;\n b14 + b24 + b34 + b44 + b54 = 1;\n b15 + b25 + b35 + b45 + b55 = 1;\n```\n\n\n\n---\n\n### 10: Investment\n\n- Investing for 3 years\n- Balance at year 0 = $100k\n- \"-1\" means an investment became available\n- $75k max per investment\n- Could earn 8% annually if using money market acct instead\n- A, C, D are available at t=0\n\n<img src=\"https://i.imgur.com/6nDgDHj.png\" style=\"zoom:50%;\" />\n\n\n\nStep 1: Define decision variables and quantity to be optimized as a mathematical function.\n\n$Obj: Z = Max \\:\\: 1B + 1.9D + 1.5E + 1.08S_2$ \n\n- We are looking to maximize the values of cash inflow at time period 3 - Note that we are moving from time period 2 to time period 3 in this setup\n\n```\n/* Objective function */\nmax: B + 1.9 D + 1.5 E + 1.08 S2;\n\n/* Variable bounds */\nA + C + D + S0 - 100000 = 0;       /* t=0 */\n\n0.5A + 1.2C + 1.08S0 - B - S1 = 0; /* t=1 */\n\nA + 0.5B + 1.08S1 - E - S2 = 0;   /* t=2 */\n\nA<=75000;\nB<=75000;\nC<=75000;\nD<=75000;\nE<=75000;\n```\n\n---\n\n### 11: Short term production\n\nWe are trying to determine how much to produce in December. \n\n- Dec 1, 2002 - Raw materials able to produce\n  - 100 tape recorders\n  - 100 radios\n- Current ratio = 20k / 10k = 2\n- December - We must pay 1k loan and 1k rent\n- December - We will be paid 2k from previous A/R\n- January 1 - Cash balance must be at least 4k\n\n- January 1 - Current ratio must be at least 2\n- January - Will receive raw materials worth 2k\n- February - Payments from December will be received\n\n<img src=\"https://i.imgur.com/swDl9im.png\" style=\"zoom:50%;\" />\n\n\n\n$x_1$ = tape recorders to produce\n\n$x_2$ = radios to produce\n\nProfit from tape recorder = $100 - 50 - 30 = 20$\n\nProfit from radio = $90 - 35 - 40 = 15$\n\nJan 1 cash = 10k \n\n- $Dec \\: 1 \\: cash + Dec \\: AR \\: collect  - loan \\: pay - Dec \\: rent \\: - Dec \\: labor$\n\nJan 1 AR = $1000 + 100x_1 + 90x_2$\n\n- $Dec \\: 1 \\: AR + Dec \\: sales \\: AR - Dec \\: collected \\: AR$\n\nJan 1 inventory = $9000 - 30x_1 - 40x_2$\n\n- $Dec \\: 1 \\: inventory - Dec \\: inventory \\: used + Jan \\: 1 \\: inventory \\: received$\n\nJan 1 assets = $20000 + 20x_1 + 15x_2$\n\n- Jan 1 cash + Jan 1 AR + Jan 1 inventory\n\nJan 1 liable = $11000$\n\n- Dec 1 liable - Dec loan pmt + amt due for inventory shipment\n\nBank: $20x_1 + 15x_2 \\geq 2000$\n\n- Assets / liable $\\geq$ 2\n\n```\n/* Objective function */\nmax: 20x1 + 15x2;\n\n\n/* Variable bounds */\nx1 <= 100;             /* Capacity */\nx2 <= 100;             /* Capacity */\n\n50x1 + 35x2 <= 6000;   /* Labor and Jan 1 cash */\n20x1 + 15x2 >= 2000;   /* Liquid */\n\nint x1, x2;\n```\n\n\n\n---\n\n### 12: Loans\n\n<img src=\"https://i.imgur.com/cVlOHvC.png\" style=\"zoom:50%;\" />\n\n\n\n```\n/* Objective function */\nmax: 0.026x1 + 0.0509x2 + 0.0864x3 + 0.06875x4 + 0.078x5;\n\n/* Variable bounds */\nx1 + x2 + x3 + x4 + x5 <= 10;\n0.3x1 + 0.3x2 + 0.3x3 - 0.7x4 - 0.7x5 <= 0;\n0.4x1 + 0.4x2 - 0.6x3 <= 0;\n0.06x1 + 0.03x2 - 0.01x3 + 0.01x4 - 0.02x5 <= 0;\n```\n\n\n\n---\n\n### 13: Distances\n\n<img src=\"https://i.imgur.com/V1dTxDw.png\" style=\"zoom:50%;\" />\n\n```\n/* Objective function */\nmin: 21 x14 +50 x15 +40 x16 +35 x24 +30 x25 + 22 x26 +55 x34 +20 x35 +25x36;\n\n/* Variable bounds */\nx14 +x24 +x34 <=200000;\nx15 +x25 +x35 <=600000;\nx16 +x26 +x36 <=225000;\n\nx14 +x15 +x16 = 275000;\nx24 +x25 +x26 = 400000;\nx34 +x35 +x36 = 300000;\n```\n\n\n\n# R\n\n**Primal**\n\n```R\nlibrary(lpSolve) # https://cran.r-project.org/web/packages/lpSolve/lpSolve.pdf\n\n# Profit of beer and ale\nobj_fun <- c(13, 23)\n\nconstr_eq <- matrix(c(5,15,    # corn\n                      4,4,     # hops\n                      35,20),  # malt\n                      ncol=2, byrow=T)\n\nconstr_dir <- c(\"<=\", \"<=\", \"<=\")\n\n# Available quantities\nconstr_rhs <- c(480, 160, 1190)\n\nsolution <- lp(\"max\", \n               obj_fun, \n               constr_eq, \n               constr_dir, \n               constr_rhs)\n\nsolution$objval    # profit\nsolution$solution  # quant of each\n```\n\n\n\n**Dual**\n\n```R\nlibrary(lpSolve) # https://cran.r-project.org/web/packages/lpSolve/lpSolve.pdf\n\n# Available quantities\nobj_fun <- c(480, 160, 1190)\n\nconstr_eq <- matrix(c(5,15,    # corn\n                      4,4,     # hops\n                      35,20),  # malt\n                      nrow=2, byrow=F)\n\nconstr_dir <- c(\">=\", \">=\")\n\n# Available quantities\nconstr_rhs <- c(13, 23)\n\nsolution <- lp(\"min\", \n               obj_fun, \n               constr_eq, \n               constr_dir, \n               constr_rhs)\n\nsolution$objval    # profit\nsolution$solution  # quant of each\n```\n\n\n\n### R Example: Furniture (Problem 3)\n\n<img src=\"https://i.imgur.com/KHTXnW9.jpg\" style=\"zoom:25%;\" />\n\n<img src=\"https://i.imgur.com/5lirwXD.png\" style=\"zoom:25%;\" />\n\n\n\n### R Example: Production (Problem 2)\n\n\n\n<img src=\"https://i.imgur.com/pn38dnZ.jpg\" style=\"zoom:15%;\" />\n\n<img src=\"https://i.imgur.com/XIgWrjK.png\" style=\"zoom:25%;\" />\n\n<img src=\"https://i.imgur.com/4NPfm1c.png\" style=\"zoom:25%;\" />\n\n\n\n"},{"title":"Nonlinear","tags":[],"path":"/Optimization/Nonlinear","body":"[Week 5 Playlist - Non-Linear](https://www.youtube.com/watch?list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&v=_VzJ7QxZK3g&feature=emb_title)\n\n*Convex* = when line segments are above the graph\n\n*Contour lines* = the slope of the function at different boundaries\n\nAble to find solutions when (or vice versa)\n\n- Concave objective function (maximization)\n- Convex constraints (or linear)\n\n---\n\n[Video 2](https://www.youtube.com/watch?v=friizMs4SM4&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=2)\n\nIf constraints are non-linear: \n\n- The maximum/minimum of an obj function s.t. constraints occurs when the **slope of the constraints** = **slope of the contour lines** (the tangent point)\n\nIf constraints & obj function are non-linear: \n\n- The maximum/minimum of an obj function s.t. constraints occurs when the **slope of the constraints (convex hull)** = **slope of the obj function** (contour lines). This is the tangent point.\n\n---\n\nThe gradient of the obj function gives a vector perpendicular to the contour line.\n\n<img src=\"https://i.imgur.com/lQ9QsqK.png\" style=\"zoom:25%;\" />\n\n\n\n**Gradient of a circle**\n\n$g(x, y) = x^2 + y^2 = k$    |     This is the contour line for a circle\n\n$\\frac{\\partial g}{\\partial x} = 2x$      |       Partial derivative with respect to x\n\n$\\frac{\\partial g}{\\partial y} = 2y$       |       Partial derivative with respect to y\n\nThe image shows the gradient when we are looking at point (1, 0). The slope of the contour lines goes up&down, so the gradient is side-to-side.\n\n<img src=\"https://i.imgur.com/ZEXwLub.png\" style=\"zoom:25%;\" />\n\n\n\n---\n\n[Video 3](https://www.youtube.com/watch?v=NxMs9vtfFZk&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=3)\n\nWhen the contour lines are tangent, the gradient vectors are parallel. \n\n<img src=\"https://i.imgur.com/yEY0MYo.png\" style=\"zoom:25%;\" />\n\nEven though the gradients could be parallel, it doesn't necessarily mean the vectors have the same magnitude. We can always multiply one of the vectors by a constant though to get them as the same magnitude & in the same direction.\n\nTangency condition: \n\nGradient vector of $f$ as some (x,y) \n\n= Gradient vector of $g$ at the (x,y) * some scalar\n\n---\n\n## First Example\n\n$f(x, y) = 2x + y$    |     This is the obj function\n\n$g(x, y) = x^2 + y^2 - 1$    |     This is the constraint\n\n$\\frac{\\partial g}{\\partial x} = 2$      |       (Obj) Partial derivative with respect to x\n\n$\\frac{\\partial g}{\\partial y} = 1$       |       (Obj) Partial derivative with respect to y\n\n$\\frac{\\partial g}{\\partial x} = 2x$      |       (Constraint) Partial derivative with respect to x\n\n$\\frac{\\partial g}{\\partial y} = 2y$       |       (Constraint) Partial derivative with respect to y\n\n\n\nThis is the tangency condition.\n\n$\\begin{bmatrix}\n2\\\\\n1\n\\end{bmatrix}$ = $\\lambda_0  \\begin{bmatrix}\n2x_0\\\\\n1y_0\n\\end{bmatrix}$\n\n\n\nThese leaves us with our 3 variables and 3 equations we need to solve. (The bottom one is our constraint equation)\n\n$2 = 2 * \\lambda_0 * x_0$\n\n$1 = 2 * \\lambda_0 * y_0$\n\n$x^2 + y^2 = 1$\n\n---\n\n[Video 4](https://www.youtube.com/watch?v=C7ziarEslqM&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=4)\n\n## Lagrangian\n\nConditions: $x_0, y_0, \\lambda_0$ must satisfy\n\n1. (Constraint)      $g(x_0, y_0) = c$     \n\n2. (Tangency condition)\n\n   Gradient vector of $f$ as some (x,y) = Gradient vector of $g$ at the (x,y) * some scalar\n\n   $\\nabla f(x_0, y_0) = \\lambda_0 * \\nabla f(x_0, y_0)$\n\n\n\n$L(x, y, \\lambda)$ = $f(x,y) - \\lambda(g(x,y) - c)$\n\nNeed to take the partial derivative with respect to x, y, and then $\\lambda$\n\n<img src=\"https://i.imgur.com/iaz06k6.png\" style=\"zoom:25%;\" />\n\n---\n\n### Example\n\n[Video 5: Example](https://www.youtube.com/watch?v=gF5s7-s6AtY&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=5)\n\nRevenue Max\n\n- Budget = 20k\n- Labor - 20/hour\n- Steel - 170/ton\n- Rev(hour, steel) = $200 * hours^.66 * steel^.33$\n- R(h, s) = $200 * h^.66 * s^.33$\n\n\n\n(Total cost)     20h + 170s = 20,000\n\n(Revenue)       $\\$200 * h^.66 * s^.33$\n\n\n\n$L(x, y, \\lambda)$ = $f(x,y) - \\lambda(g(x,y) - c)$\n\n$L(x, y, \\lambda)$ = $200 * h^.66 * s^.33 \\: - \\: \\lambda(20h + 170s - 20,000)$\n\n<img src=\"https://i.imgur.com/agWe33r.png\" style=\"zoom:25%;\" />\n\n\n\n1. Derivative with respect to h\n   - $0 = 200 * \\frac{2}{3}h^\\frac{-1}{3} * s^\\frac{1}{3} - 20\\lambda$\n\n2. Derivative with respect to s\n   - $0 = 200 * \\frac{1}{3}h^\\frac{2}{3} * s^\\frac{-2}{3} - 170\\lambda$\n\n3. Derivative with respect to $\\lambda$\n   - $0 = 20h + 170s - 20,000$\n\n\n\n$h^* = 667 \\: hours$\n\n$s^* = 39 \\: tonnes$\n\n$\\lambda^*$ = 2.59\n\n$Revenue = \\$51777 = 200*667^\\frac{2}{3} *29^\\frac{1}{3}$\n\n---\n\n[Video 6](https://www.youtube.com/watch?v=RZvkmAkDMfU&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=6)\n\nAbove, $\\lambda^*$ was 2.59.\n\nIn our Lagrangian equation, we have two parts: objective function and constraint. We are going to use $M$ to represent the objective function part. \n\n$L(x^*, y^*, \\lambda^*)$ = $f(x^*,y^*) - \\lambda(g(x^*,y^*) - c)$\n\nWe know that we are going to set our $x$ and $y$ in the constraint part in a way that the section will become 0, so our Lagrangian at the optimal point is just\n\n$L(x, y, \\lambda)$ = $f(x^*,y^*)$\n\n$L(x, y, \\lambda)$ = $M^*$\n\nWe want to know what the impact of relaxing our budget constraint will be on the optimal value of the objective function. This first part is showing how we represent the original function\n\n$M^*(c)$ \n\n= $f(x^*,y^*) - \\lambda(g(x^*,y^*) - c)$\n\n= $L(\\:\\: x^*(c), \\:\\: y^*(c), \\:\\: \\lambda^*(c), \\:\\: c)$\n\nNow we take the partial derivative with respect to our budget constraint\n\n$\\frac{\\partial M^*}{\\partial c}$ = $\\lambda^*$\n\n$\\lambda^*$ = 2.59 represents the change in the optimal value from our objective function as we relax our budget constraint. This is our Shadow Price.\n\nOriginal budget: \\$20,000          |           New budget: \\$20,001\n\nOriginal revenue: \\$51,777         |          New revenue: \\$51779.59\n\n---\n\n[Video 7](https://www.youtube.com/watch?v=RUKO4dznGY0&list=PL8uIP3DsMWIyps1hmNmfI2Y5c0gdavMmd&index=7)\n\n1. Writing in standard form (ie a maximization obj function)\n\n<img src=\"https://i.imgur.com/HOuyXEo.png\" style=\"zoom:25%;\" />\n\n\n\n2. Re-writing as functions\n\n<img src=\"https://i.imgur.com/T3trjWw.png\" style=\"zoom:25%;\" />\n\n\n\n3. Solving partial derivatives\n\n<img src=\"https://i.imgur.com/Crzqqv7.png\" style=\"zoom:25%;\" />\n\n\n\n4. Plotting\n\n<img src=\"https://i.imgur.com/W3Q4SfJ.png\" style=\"zoom:25%;\" />\n\n\n\n\n\n<img src=\"https://i.imgur.com/sntaWaQ.png\" style=\"zoom:25%;\" />\n"},{"title":"Optimization Overview","tags":[],"path":"/Optimization/Optimization Overview","body":"\n\n# Branches of Optimization\n\nUpdate/consolidate this. See [Brittanica](https://www.britannica.com/science/optimization)\n\n[ChatGPT](https://chatgpt.com/share/98d49c1d-314b-4876-afd1-2bda0aecd27d)\n\n> I took an undergrad course on Constrained Optimization which focused heavily on the Lagrangian multiplier and the Hessian matrix. I took a graduate course on Optimization which focused on linear programming. How do these 2 connect?\n\nBoth are **branches** of optimization, but they emphasize different types of problems and techniques.\n- **LP** focuses on finding the optimal solution at the vertices (corners) of the feasible region.\n- **Nonlinear programming** (where Lagrangians and Hessians are used) finds critical points within a broader, often continuous, space. The constraints or the objective function are not necessarily linear.\n\n\n> Provide an outline of the branch of optimization.\n## Unconstrained Optimization\n\n**Objective**: Minimize or maximize a function without constraints.\n\n**Problem Classes**:\n- **Nonlinear Programming (NLP)**: When there are no constraints (i.e., optimizing a nonlinear function without any restrictions).\n    - Example: Using Gradient Descent for machine learning without constraints.\n- **Quadratic Programming (QP)**: If no constraints are present in a quadratic objective function (though typically it involves linear constraints).\n\n\n\n## Constrained Optimization\n\n**Objective**: Minimize or maximize a function subject to constraints.\n**Subtypes**:\n- **Equality-constrained**: Constraints are equations.\n- **Inequality-constrained**: Constraints are inequalities.\n\n\n**Problem Classes**:\n- **Linear Programming (LP)**: Optimizing a linear objective function subject to linear constraints (both equality and inequality constraints).\n    - Example: Supply chain optimization with resource limitations.\n- **Nonlinear Programming (NLP)**: When optimizing a nonlinear objective function subject to nonlinear constraints.\n    - Example: Engineering design problems.\n- **Integer Programming (IP) / Mixed Integer Programming (MIP)**: Involves both integer variables and constraints (linear or nonlinear).\n    - Example: Scheduling problems, logistics.\n- **Quadratic Programming (QP)**: Optimizing a quadratic objective function subject to linear constraints.\n    - Example: Portfolio optimization in finance.\n- **Convex Optimization**: Constrained or unconstrained optimization where the objective and constraint functions are convex.\n    - Example: Machine learning algorithms like Support Vector Machines (SVM).\n- **Non-Convex Optimization**: Can involve either unconstrained or constrained optimization where the objective or constraints are non-convex.\n    - Example: Deep learning model training.\n\n\n## Both\n\n### **Stochastic Optimization**\n\n- This can apply to both unconstrained and constrained problems but introduces randomness or uncertainty into the problem.\n    - Example: Financial modeling under uncertain market conditions.\n\n### **Multi-Objective Optimization**\n\n- This involves optimizing multiple objectives and can be applied in both unconstrained and constrained optimization.\n    - Example: Engineering design where cost, performance, and safety are optimized simultaneously under specific constraints.\n"},{"title":"Problems","tags":[],"path":"/Optimization/Problems","body":"\n**Resources**\n- [Textbook](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA37&hl=en)\n- [Textbook Code](https://github.com/jmsallan/linearprogramming/tree/master/LP)\n- [[More optim examples]] | Messier, probably won't need.\n- [[QuantEcon Example]] | Python. Probably won't need either. \n\n\n\n# HW1\n\n## Q1 | Manufacturing\n\n### Problem\n\nA manufacturing firm in California produces four different metal products, each of which must be machined, polished, and assembled. (All info is weekly.)\n\n![](https://i.imgur.com/lJVq2bx.png)\n\nContract with 1 firm:\n- 50 units of product I\n- 100 units of any combination of products II and III\n\nCan sell to other firms:\n- Products I, II, and III: No restriction\n- Product IV: 30 unit max\n\nGovt regulation:\n- Product IV: Can only produce 25 units\n\nNeed to meet all obligations.\n\n\n### Solutions\n\nHow many units of each product should the firm manufacture each week? What is the max profit?\n\n```r\nlibrary(lpSolve) # https://cran.r-project.org/web/packages/lpSolve/lpSolve.pdf\nlibrary(knitr)\n\n\n# Profit\nobj_fun <- c(6, 4, 6, 8)\n\nconstr_eq <- matrix(c(3,2,2,4,  # Machine\n                      1,1,2,3,  # Polish\n                      2,1,2,1,  # Assemble\n                      1,0,0,0,  # Product I contract\n                      0,1,1,0,  # Product II & III contract\n                      0,0,0,1   # Product IV govt regs\n                      ), ncol=4, byrow=T) # 4 products\n\nconstr_dir <- c(\"<=\", \"<=\", \"<=\",  # Machine, Polish, Assemble\n                \">=\",\">=\",\"<=\")\n\n# Available quantities\nconstr_rhs <- c(480, 400, 400,  # Machine, Polish, Assemble\n                50, 100, 25)\n\nsolution <- lp(\"max\", \n               obj_fun, \n               constr_eq, \n               constr_dir, \n               constr_rhs)\n\nsolution$objval    # 1250\nsolution$solution  # 50  0  145  10\n```\n---\n\n\n## Q2 | Grocery Store\n\n### Problem\nOn Saturday, the manager of a supermarket is making hamburger meat, picnic patties, and meat loaf. The demand for each always exceeds the supermarket’s supply. \n\n\"Filler\": The remainder of each product is an inexpensive non-meat filler which the store has in unlimited supply. \n\n![](https://i.imgur.com/G6oZiGH.png)\n\n\n### Solution\nHow many pounds of each product should be made? How much meat needs to be stored for Sunday?\n\n```r\n# Profit\nobj_fun <- c(0.7, 0.7, 0.8)   # Found by taking \"1 - Filler\"\n\n\nconstr_eq <- matrix(c(0.2, 0.0, 0.1, # Round Steak\n                      0.5, 0.5, 0.4, # Chuck Steak\n                      0.0, 0.2, 0.3  # Pork\n                      ), ncol=3, byrow= TRUE )\n\nconstr_dir <- c(\"<=\", \"<=\",\"<=\")\n\n# Available quantities\nconstr_rhs <- c(200, 800, 150)\n\nsolution <- lp(\"max\", \n               obj_fun, \n               constr_eq, \n               constr_dir, \n               constr_rhs)\n\nsolution$objval    # 1150\nsolution$solution  # 937.5  562.5  125.0\n```\n\n---\n\n\n## Q3 | Oil\n\n### Problem\nProduces two types of unleaded gasoline:\n\n\n- Regular: \\$12 per barrel revenue\n- Premium: \\$14 per barrel revenue\n\nBoth types are blended from Aztec’s inventory of refined domestic oil and refined foreign oil, and must meet the following specifications:\n\nThe characteristics of the refined oils in inventory are as follows:\n\n![](https://i.imgur.com/T4bojeV.png)\n\n\n\n### Solution\nThe company wants to decide what quantities (i.e., blended barrels) of the oils should it blend into the two gasolines in order to maximize weekly profit? What is the maximum weekly profit? (Note: Solve it as a LP, no need to mandate integer values for barrels)\n\n```r\nobj_fun <- c(4,   # barrels of domestic blended into regular (12 - 8)\n             -3,  # barrels of foreign blended into regular (12 - 15)\n             6,   # barrels of domestic blended into premium (14 - 8)\n             -1)  # barrels of foreign blended into premium (14 - 15)\n\n\nconstr_eq <- matrix(c(1,1,0,0,     # ≤ 100000 | max regular demand  \n                      0,0,1,1,     # ≤ 20000  | max premium demand  \n                      1,1,0,0,     # ≥ 50000  | min regular required\n                      0,0,1,1,     # ≥ 5000   | min premium required\n                      1,0,1,0,     # ≤ 40000  | domestic\n                      0,1,0,1,     # ≤ 60000  | foreign\n                      \n                      1,-10,0,0,   # ≤ 0  | octane rating of regular\n                      0,0,6,-5,    # ≤ 0  | premium octane constraint\n                      2,-8,0,0,    # ≤ 0  | regular vapor-pressure constraint\n                      0,0,2,-8    # ≤ 0  | premium vapor-pressure constraint\n                      ), ncol=4, byrow= TRUE )\n\n\nconstr_dir <- c(\"<=\", \"<=\",\">=\",\">=\",\"<=\",\"<=\",\"<=\",\"<=\",\"<=\",\"<=\")\nconstr_rhs <- c(100000,20000,50000,5000,40000,60000,0,0,0,0)\n\nsolution <- lp(\"max\",obj_fun,constr_eq,constr_dir,constr_rhs)\nsolution$objval      # 125000\nsolution$solution    # 40000   10000   0    5000\n```\n\n\n\n\n# HW2\n\n## Q1 | Investment Bonds\n\n### Problem\nYou have $10M to invest.\n\nPolicy limitations on the portfolio manager’s actions:\n1. Govt + agency bonds $\\geq$ $4M.\n2. Portfolio avg **quality** $\\leq$ 1.4.\n3. Portfolio avg years to **maturity** $\\leq$ 5 years.\n\nTaxes\n- **Muni**: 0%\n- **Others**: 50%\n\n![](https://i.imgur.com/00sLtF7.png)\n\n\n### Solutions\n\n1. Maximize post-tax earnings. Write the dual.\n\n[ChatGPT](https://chatgpt.com/share/f9d95e9f-72dc-4451-af32-e8a6b1a721a3)\n```\n/* Objective function */\nmax: 1.043 q1 + 1.054 q2 + 1.05 q3 + 1.044 q4 + 1.045 q5 ; // each of the 5 yields\n\n/* Variable bounds */\n\n// Govt + agency bonds\nq2 + q3 + q4 >= 4;   \n\n// Quality constraint\n.6q1 + .6q2 - .4q3 - .4q4 + 3.6q5 <= 0;\n\n// Maturity constraint\n4q1 + 10 q2 - 1 q3 + - 2q4 - 3q5 <= 0;\n\n// Available to invest\nq1 + q2 + q3 + q4 + q5 <= 10;\n```\n\n\n### Dual\n\n>The dual problem would involve finding the values of these dual variables that minimize the cost function while satisfying the corresponding dual constraints. Specifically, the dual variables can be interpreted as the marginal value of relaxing each constraint. \n\n\n\n\n\n# Textbook examples\n\n## P1 | Production Plan with Fixed Costs\n\n### Resources\n[Book: 3.1](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 3 | Monday YT Playlist](https://www.youtube.com/watch?v=8BnphwZJtBY&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj)\n5. Ex: Production plan with fixed costs (reading problem)\n6. Ex: Production plan with fixed costs (solve part 1).\n7. Ex: Production plan with fixed costs (solve part 2).\n\n\n### Problem\n\n**Objective**: Min total cost (raw materials, labor and storage costs). \n\n**Constraints**:\n- **Labor**: \\$12 per hour. Only worked hours are paid. \n- **Each unit**: 30 minutes of labor. \n- **Storage**: \\$2 per unit at the end of each month. \n- **Fixed cost**: \\$1,000 for each month with production\n\n**Other**:\n- Units produced this month can carry over next month.\n- No beginning stock\n- No minimum stock requirements\n\n|                          | Month 1 | Month 2 | Month 3 | month 4 |\n| ------------------------ | ------- | ------- | ------- | ------- |\n| Unit Cost (\\$)           | 6       | 8       | 10      | 12      |\n| Demand (units)           | 100     | 200     | 150     | 400     |\n| **Available work hours** | 200     | 200     | 150     | 150     |\n\n\n### Solution\nDefine decision variables, objective function, and constraints.\n\n```r\n# q = quantity produced in month i\n# s = stock at the end of month i\n# b = fixed cost\n\nMinimize\n  cost: 12q1 + 14q2 + 16q3 + 18q4 + 2s1 + 2s2 + 2s3 + 2s4 + 1000b1 + 1000b2 + 1000b3 + 1000b4\nSubject To\n  d1: q1 - s1 = 100\n  d2: s1 + q2 - s2 = 200 # (stock month 1) + (produced month 2) - (stock month 2)\n  d3: s2 + q3 - s3 = 150\n  d4: s3 + q4 - s4 = 400\n  \n  l1: q1 - 400b1 <= 0    # (produced month 1) - (fixed cost)\n  l2: q2 - 400b2 <= 0\n  l3: q3 - 300b3 <= 0    # 300 because only 150 available hours\n  l4: q4 - 300b4 <= 0\n  \nBinary\n  b1\n  b2\n  b3\n  b4\nEnd\n```\n\n---\n\n\n## P2 | A purchase plan with decreasing unit costs\n\n### Resources\n\n[Book: 3.2](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 3 | Monday YT Playlist](https://www.youtube.com/watch?v=8BnphwZJtBY&list=PL8uIP3DsMWIy_b3CxJ4WmfZyGMXULx0dj)\n8. Ex: Purchase plan with decreasing unit costs\n\n### Problem\n\n**Objective**: Min cost (raw materials & storage costs). \n\n**Constraints**:\n- **Storage**: $2 per stored unit at the EoM.\n\n**Other**:\n- Units produced this month can carry over next month.\n- No beginning stock\n- No minimum stock requirements\n\n**New offer**: After purchasing 200 units in a month, each additional unit will have a discounts of \\$2.\n\n|                | Month 1 | Month 2 | Month 3 | month 4 |\n| -------------- | ------- | ------- | ------- | ------- |\n| Unit Cost (\\$) | 12      | 14      | 16      | 18      |\n| Demand (units) | 150     | 200     | 250     | 150     |\n\n\n### Solution\n\na. Define decision variables, objective function, and constraints.\n\n```r\n\n# q = quantity purchased leq 200\n# r = quantity purchased > 200\n# s = beginning stock\n# b = binary, value of 1 when >200 were purchased\n\nMinimize\n  cost: \n  12q1 + 14q2 + 16q3 + 18q4 +  # cost w/o discount\n  10r1 + 12r2 + 14r3 + 16r4 +  # cost w $2 discount\n  2s1 + 2s2 + 2s3 + 2s4        # $2 storage fee\nSubject To\n  d1: q1 + r1 - s1 = 150       # demand month 1\n  d2: s1 + q2 + r2 - s2 = 200\n  d3: s2 + q3 + r3 - s3 = 250\n  d4: s3 + q4 + r4 - s4 = 150\n  l1: q1 - 200b1 >= 0          # have to purchase at least 200 for discount\n  l2: q2 - 200b2 >= 0\n  l3: q3 - 200b3 >= 0\n  l4: q4 - 200b4 >= 0\n  m1: r1 - 10000b1 <= 0     \n  m2: r2 - 10000b2 <= 0\n  m3: r3 - 10000b3 <= 0\n  m4: r4 - 10000b4 <= 0\nBounds\n  0 <= q1 <= 200  # expensive has to be purchased 1st\n  0 <= q2 <= 200\n  0 <= q3 <= 200\n  0 <= q4 <= 200\nBinary\n  b1\n  b2\n  b3\n  b4\nEnd\n```\n\n---\n\n\n## P3 | A Production Plan with Extra Capacity\n\n### Resources\n\n[Book: 3.3](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 3 | Wednesday YT Playlist](https://www.youtube.com/watch?v=i0Dv5S63YMU&list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&index=1)\n1. Ex: A Production Plan with Extra Capacity (reading problem)\n2. Ex: A Production Plan with Extra Capacity (solve part 1 & 2)\n3. Ex: A Production Plan with Extra Capacity (read part 3)\n4. Ex: A Production Plan with Extra Capacity (solve part 3)\n\n\n### Problem\n\n**Objective**: Min costs (production + storage)\n\n**Constraints**:\n- **Plant capacity**: 1,300 tonnes (t.) per month. \n- **Storage costs** = \\$2k per tonne stocked at EoM. \n- **End stock month 4**: 200 tonnes\n\nOthers:\n- Production can carryover months. \n- Initial stock = 200 tonnes of finished, 0 of raw materials\n\n|                | Month 1 | Month 2 | Month 3 | Month 4 |\n| -------------- | ------- | ------- | ------- | ------- |\n| Unit Cost (\\$) | 3       | 8       | 6       | 7       |\n| Demand (units) | 800     | 900     | 1200    | 1800    |\n\n\n### Solution\n1. Formulate and solve.\n\n```r\nMinimize\n  cost: 3q1 + 8q2 + 6q3 + 7q4 + 2s1 + 2s2 + 2s3 + 2s4\nSubject To\n  d0: s0 = 200\n  d1: q1 + s0 - s1 = 800\n  d2: s1 + q2 - s2 = 900\n  d3: s2 + q3 - s3 = 1200\n  d4: s3 + q4 - s4 = 1800\n  d5: s4 = 200\nBounds\n  0 <= q1 <= 1300\n  0 <= q2 <= 1300\n  0 <= q3 <= 1300\n  0 <= q4 <= 1300\nEnd\n```\n\n2. What is the meaning of the dual variables of the constraints defined in the model?\n\n\n\n3. Demand is irregular. Mgmt is considering adding extra capacity to the plant (ie, introducing a new shift). \n\t- **New plant capacity**: Extra 400 T (from 1300 to 1700.)\n\t- **New fixed cost**: \\$500\n\t- It is not possible to add extra capacity in a month if it has been added in the previous month. \n\t- Modify the model obtained previously to include the possibility of including extra shifts, and assess the practicality of adding extra shifts.\n\n```r\nMinimize\n  cost: 3q1 + 8q2 + 6q3 + 7q4 + 2s1 + 2s2 + 2s3 + 2s4 + 500b1 + 500b2 + 500b3 + 500b4\nSubject To\n  d0: s0 = 200\n  d1: q1 + s0 - s1 = 800\n  d2: s1 + q2 - s2 = 900\n  d3: s2 + q3 - s3 = 1200\n  d4: s3 + q4 - s4 = 1800\n  d5: s4 = 200\n  e1: q1 - 400b1 <= 1300\n  e2: q2 - 400b2 <= 1300\n  e3: q3 - 400b3 <= 1300\n  e4: q4 - 400b4 <= 1300\nBinary\n  b1\n  b2\n  b3\n  b4\nEnd\n```\n\n\n\n\n## P4 | Transportation by Trucks \n\n### Resources\n\n[Book: 3.4](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 3 | Wednesday YT Playlist](https://www.youtube.com/watch?v=i0Dv5S63YMU&list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&index=1)\n\n5. Ex: Transportation by Trucks (reading problem)\n6. Ex: Transportation by Trucks (solving problem)\n\n### Problem\n- Obj: Min total costs (acquisition, storage & transport, obtaining raw materials, and trucks to be contracted)\n- Table shows quarterly demand (in tonnes) & acquisition costs of raw materials (\\$k per tonne) \n- Can carryover.\n- Stocking = \\$8k per tonne stored at the end of each quarter. \n- Begin stock = 100 tonnes\n- Needed end stock = 100 tonnes\n\n\nTransportation costs (for the raw materials): \n\n- Small trucks: cost of \\$700k, and capacity of 500 tonnes.\n- Large trucks: cost of \\$1400k, and capacity of 1,200 tonnes.\n  \n\n\n\n### Solution\nDefine the problem.\n\n```r\nMinimize\n  cost: 20q1 + 25q2 + 30q3 + 40q4 + 8s1 + 8s2 + 8s3 + 8s4 + 700t1 + 700t2 + 700t3 + 700t4 + 1400u1 + 1400u2 + 1400u3 + 1400u4\nSubject To\n    sini: s0 = 100\n    dem1: s0 + q1 - s1 = 1000\n    dem2: s1 + q2 - s2 = 1200\n    dem3: s2 + q3 - s3 = 1500\n    dem4: s3 + q4 - s4 = 1800\n    sfin: s4 = 100\n\n    cap1: q1 - 500t1 - 1200u1 <= 0\n    cap2: q2 - 500t2 - 1200u2 <= 0\n    cap3: q3 - 500t3 - 1200u3 <= 0\n    cap4: q4 - 500t4 - 1200u4 <= 0\n\nInteger\n    t1\n    t2\n    t3\n    t4\n    u1\n    u2\n    u3\n    u4\n\nEnd\n```\n\n\n\n\n## P5 | Production of two models of chairs\n\n\n### Resources\n\n[Book: 3.5](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 3 | Wednesday YT Playlist](https://www.youtube.com/watch?v=i0Dv5S63YMU&list=PL8uIP3DsMWIygSH23C6vVIEzuOfqs-kr9&index=1)\n7. Reading problem\n8. Solve part 1\n9. Solve part 2\n10. Solve part 3\n\n\n### Problem\nA company produces two models of chairs: 4P and 3P. The model 4P needs 4 legs, 1 seat and 1 back. On the other hand, the model 3P needs 3 legs and 1 seat. The company has a initial stock of 200 legs, 500 seats and 100 backs. If the company needs more legs, seats and backs, it can buy standard wood blocks, whose cost is \\$80 per block. The company can produce 10 seats, 20 legs and 2 backs from a standard wood block. \n\n\nThe cost of producing the model 4P is \\$30/chair, meanwhile the cost of the model 3P is \\$40/chair. Finally, the company informs that the minimum number of chairs to produce is 1,000 units per month.\n\n\n### Solution\n1. Define a linear programming model, which minimizes the total cost (the production costs of the two chairs, plus the buying of new wood blocks). Answer: z = \\$48,680 \n\n```r\nMinimize\n    cost: 80xwood + 30x4p + 40x3p\nSubject To\n    seats: x4p + x3p - 10xwood <= 500\n    legs: 4x4p + 3x3p - 20xwood <= 200\n    backs: x4p - 2xwood <= 100\n    dem: x4p + x3p >= 1000\nInteger\n    x3p\n    x4p\n    xwood\nEnd\n```\n\n2. Due to the economic crisis, the company has considered the possibility to just produce a single chair model between 3P and 4P. Define the new linear programming model for producing only a single chair model, which minimizes the total cost. Answer: z = \\$51,200\n\n```r\nMinimize\n    cost: 80xwood + 30x4p + 40x3p\nSubject To\n    seats: x4p + x3p - 10xwood <= 500\n    legs: 4x4p + 3x3p - 20xwood <= 200\n    backs: x4p - 2xwood <= 100\n    dem: x4p + x3p >= 1000\n    dec3: x3p - 1000decision <= 0\n    dec4: x4p + 1000decision <= 1000\nInteger\n    x3p\n    x4p\n    xwood\nBinary\n    decision\nEnd\n```\n\n3. Finally, the new CEO decided that the factory needs to produce of the model 4P a minimum of 4 times the quantity of the model 3P. Define the new linear programming model, which minimizes the total cost when producing 4P four times the quantity of 3P. Answer: z = \\$60,000\n\n```r\nMinimize\n    cost: 80xwood + 30x4p + 40x3p\nSubject To\n    seats: x4p + x3p - 10xwood <= 500\n    legs: 4x4p + 3x3p - 20xwood <= 200\n    backs: x4p - 2xwood <= 100\n    dem: x4p + x3p >= 1000\n    times: x4p - 4x3p >= 0\nInteger\n    x3p\n    x4p\n    xwood\nEnd\n```\n\n\n\n\n## P6 | Hiring and Firing\n### Resources\n[Week 4 | Monday YT Playlist](https://www.youtube.com/watch?v=4RwptG8BKkI&list=PL8uIP3DsMWIx33yWHEYjXW2CCJoRkDGOF)\n1. Ex: Hiring and Firing (reading)\n2. Ex: Hiring and Firing (solve part 1)\n3. Ex: Hiring and Firing (solve part 2)\n\n[Book: 3.6](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n\n### Problem\nTable 5 lists the need of the number of pilots able to fly a Boeing 787 for the following six months. The cost of a pilot’s salary is \\$8k per month. At the beginning of Month 1 the airline has a staff of 20 pilots, but this staff can be adjusted each month.\n\n|               | Month 1 | Month 2 | Month 3 | month 4 | month 5 | month 6 |\n| ------------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| Needed pilots | 30      | 60      | 55      | 40      | 45      | 50      |\n\nPilots can be hired and fired at the beginning of each month. Newly hired pilots can start working at the same month, and fired pilots stop working the same day they are fired. The cost of firing a pilot is \\$10k, and the hiring cost is of \\$5k per pilot. If it is convenient, the airline can have a staff of pilots larger than the actual needs.\n\n### Solution\n1. Define a linear programming model to obtain the pilots to hire and fire each month to minimize the total cost of pilot staff (costs of salary plus hiring and firing costs). Answer: Total cost = \\$2655k\n\n```r\nMinimize\n  cost: 5h1 + 5h2 + 5h3 + 5h4 + 5h5 + 5h6 + 10f1 + 10f2 + 10f3 + 10f4 + 10f5 + 10f6 + 8s1 + 8s2 + 8s3 + 8s4 + 8s5 + 8s6\nSubject To\n    sini: s0 = 20\n    sm1: s0 + h1 - f1 - s1 = 0\n    sm2: s1 + h2 - f2 - s2 = 0\n    sm3: s2 + h3 - f3 - s3 = 0\n    sm4: s3 + h4 - f4 - s4 = 0\n    sm5: s4 + h5 - f5 - s5 = 0\n    sm6: s5 + h6 - f6 - s6 = 0\nBounds\n  30 <= s1\n  60 <= s2\n  55 <= s3\n  40 <= s4\n  45 <= s5\n  50 <= s6\nEnd\n```\n\n\n2. Modify the linear model to include the constraint that the airline cannot fire pilots if it has hired pilots the previous month. Answer: Total cost = \\$2695k\n\n```r\nMinimize\n  cost: 5h1 + 5h2 + 5h3 + 5h4 + 5h5 + 5h6 + 10f1 + 10f2 + 10f3 + 10f4 + 10f5 + 10f6 + 8s1 + 8s2 + 8s3 + 8s4 + 8s5 + 8s6\nSubject To\n    sini: s0 = 20\n    sm1: s0 + h1 - f1 - s1 = 0\n    sm2: s1 + h2 - f2 - s2 = 0\n    sm3: s2 + h3 - f3 - s3 = 0\n    sm4: s3 + h4 - f4 - s4 = 0\n    sm5: s4 + h5 - f5 - s5 = 0\n    sm6: s5 + h6 - f6 - s6 = 0\n    hf01: h1 - 1000b1 <= 0\n    hf02: h2 - 1000b2 <= 0\n    hf03: h3 - 1000b3 <= 0\n    hf04: h4 - 1000b4 <= 0\n    hf05: h5 - 1000b5 <= 0\n    hf06: f2 + 1000b1 <= 1000\n    hf07: f3 + 1000b2 <= 1000\n    hf08: f4 + 1000b3 <= 1000\n    hf09: f5 + 1000b4 <= 1000\n    hf10: f6 + 1000b5 <= 1000\nBounds\n  30 <= s1\n  60 <= s2\n  55 <= s3\n  40 <= s4\n  45 <= s5\n  50 <= s6\nBinary\nb1\nb2\nb3\nb4\nb5\nEnd\n```\n\n---\n\n## P7 | Planning of Personnel Shifts\n\n### Resources\n\n[Book: 3.7](https://play.google.com/books/reader?id=nWaFCgAAQBAJ&pg=GBS.PA31&hl=en)\n[Week 4 | Monday YT Playlist](https://www.youtube.com/watch?v=4RwptG8BKkI&list=PL8uIP3DsMWIx33yWHEYjXW2CCJoRkDGOF)\n4. Ex: Planning of Personnel Shifts (reading)\n5. Ex: Planning of Personnel Shifts (solving)\n\n### Problem\n\nA hospital has an emergency center that remains open 24 hours a day. Table 6 details the minimal needs of employees for each of the six shifts of four hours in which the day is divided.\n\nEach of the employees of the emergency center works eight hours a day, covering two consecutive shifts of four hours. For instance, a given employee may start working at 20:00, and end working at 04:00. \n\n![](https://i.imgur.com/BIVaXFh.png)\n\n\n### Solution\n1. You are asked to define a linear programming model that can define a planning of shifts to cover the minimal needs for each shift with a minimum number of employees.\n\n```r\nMinimize\n  workforce: s1 + s2 + s3 + s4 + s5 + s6\nSubject To\n  t1: s6 + s1 >= 5\n  t2: s1 + s2 >= 7\n  t3: s2 + s3 >= 18\n  t4: s3 + s4 >= 12\n  t5: s4 + s5 >= 15\n  t6: s5 + s6 >= 10\nInteger\n  s1\n  s2\n  s3\n  s4\n  s5\n  s6\nEnd\n```\n"},{"title":"QuantEcon Example","tags":[],"path":"/Optimization/QuantEcon Example","body":"## QuantEcon Example\n\n[QuantEcon](https://python.quantecon.org/lp_intro.html), [Google Colab](https://colab.research.google.com/drive/10Hjet_MImjqmyLn3C08aw6mNoG2tsb72#scrollTo=89bd93d8)\n\n![](https://i.imgur.com/Ba5hB8A.png)\n\n\n\n```python\n# Max function\nc = np.array([3, 4])        # Revenue: P1, P2\n\n# Inequality constraints\nA = np.array(\n    [[2, 5],                # Material\n     [4, 2]])\t\t\t\t\t\t\t\t# Labor\n\n# Available quantities\nb = np.array([30,20])\n\n\n# we put a negative sign on the objective as linprog does minimization\nres_ex1 = linprog(-c,         # Objective function\n                  A_ub = A,   # Inequality constraints\n                  b_ub = b,   # Available quantities\n                  method = 'revised simplex')\nres_ex1\n\n# Results:\n  # fun: -27.5\n  # x: array([2.5, 5])\n\n# The optimal plan tells the factory to produce 2.5 units of Product 1 and 5 units of Product 2; that generates a maximizing value of revenue of 27.5.\n```\n\n```python\n# Dual Problem:\nres_ex1_dual = linprog(\n  b, \n  A_ub=-A.T, \n  b_ub=-c, \n  method='revised simplex')\n\nres_ex1_dual\n\n# Results:\n  # fun: 27.5\n  # x: array([.625, .4375])\n\n# Shadow prices for materials and labor are 0.625 and 0.4375, respectively.\n```\n\n![](https://python.quantecon.org/_images/lp_intro_3_0.png)\n\n\n\n"},{"title":"_Optimization MOC","tags":[],"path":"/Optimization/_Optimization MOC","body":"\n\n[Optimization Overview](Optimization%20Overview.md)\n- [[LP Notes]]\n- [[Nonlinear]]\n- [[Problems]]\n"},{"title":"New Perspectives on Industrial Organization","tags":[],"path":"/Readwise/Books/New Perspectives on Industrial Organization","body":"# New Perspectives on Industrial Organization\n\n![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/default-book-icon-2.dae1dc4d332b.png)\n\n## Metadata\n- Author: [[Victor J. Tremblay and Carol Horton Tremblay]]\n- Full Title: New Perspectives on Industrial Organization\n- Category: #books\n\n## Highlights\n- The field of industrial organization encompasses a host of intriguing questions.\n"},{"title":"Case Studies","tags":[],"path":"/Strategy/Case Studies","body":"\n[Hacking the Case Interview](https://s3.amazonaws.com/thinkific/file_uploads/163260/attachments/c28/5c8/468/Case_Interview_Cheat_Sheet_and_Study_Guide.pdf)\n\n## Structure\n\nWhat is the structure of a case interview? \nAll case interviews follow 7 major steps:\n\n1. **Understand the case background**: What is the context, company, and objective?\n2. **Ask clarifying questions**: Clarify the above 3.\n3. **Structure a framework** (MECE): A framework is a tool that organizes ideas into *categories*. \n4. **Start the case**: \n\t1. Which *category* to start in?\n\t2. What questions to answer?\n\t3. What analyses to do?\n\t4. What's the next step of the case?\n5. **Solve quantitative problems**\n\t1. **Market sizing**: Estimate the size of a market or figure. Use data or assumptions.\n\t2. **Profitability**: Calculate expected profitability, calculate conditions necessary for a company to break even.\n6. **Answer qualitative questions:** \n\t1. **Brainstorm**: Brainstorm ideas for a particular problem\n\t2. **Judgement**: Give your opinion on a business issue / strategic decision.\n7. **Deliver a recommendation**: Present rec & major reasons. Propose next steps.\n\n\n\n\n## Common cases\n\n**Profitability**: How to address declining profits?\n- ID reason (revenue or costs)\n- ID next layer of ^\n- Solve ^\n\n**Growth**: How can we grow?\n- Grow organically or inorganically?\n\t- Organic: Existing revenue sources OR new revenue sources\n\t- Inorganic: Potential acquisitions OR partnerships\n\n**Market entry case**: Should we enter a new market?\n- Assess demand\n- Assess supply (competitive landscape)\n- Assess company's resources / capabilities to enter\n- Estimate the expected profitability from entering\n\n**M&A**: Should we acquire or merge with a particular company?\n- Determine whether the market is attractive\n- Determine whether the company is attractive\n- Assess potential synergies and risks\n- Estimate the financial implications\n\n\n\n\n\n\n### Grocery Retailer\n\n[YouTube](https://www.youtube.com/watch?v=fXLZjCLE7d0&t=113s)\n\n**Situation**\n- Grocery retailer\n- 5B in revenue\n- Year 2000\n- Considering launching online delivery\n\nQuestion to answer: What are the areas you would look at to help make this decision?\n\nQuestion back --> What is the objective? (Profit, market share, etc?)\n- Answer: Doesn't know. Just wants to know the economics of going online.\n\nKey details you should have pulled out:\n- Year 2000: There weren't many grocery stores doing online delivery.\n\n---\n\n**Framework**\n\n3 areas to explore\n- **Demand**: Number of customers, willingness to pay, needs & expectations\n- **Supply**: Website dev, warehouse reqs, delivery. (In-house v outsource.)\n- **Economics**: Current financial health, investment needed, expected ROI\n\n\n---\n\n\n## BR Dash TGM\n\n[Chat - GA4 and Hubspot](https://chatgpt.com/share/6726643b-f31c-8000-b4a6-388591425b54)\n\n\n**Situation**: As a marketing agency, we need to attract new clients in order to maximize profit. An important piece of attracting new clients is establishing ourselves as experts in the markets we compete in. One way we do this is by hosting a podcast. Separate strategic decisions have led us into the F&B space. As a result, we're creating episodes in this podcast dedicated to F&B specifically.\n\n**Complication**: Its not possible to directly measure the real-world impact that these episodes have on our target audience. Instead, we need to rely on indirect metrics from our website (GA4) and sources of this traffic (paid Linkedin, organic Linkedin posts, SEM).\n\n**Key Question**: How can we assess the effectiveness of our F&B-focused podcast episodes in establishing our agency as a market expert and attracting new clients, using indirect metrics from GA4, SEM and LinkedIn?\n\n\nQuestions:\n- Compared to other marketing efforts, has the podcast series been any good?\n- Compared to other episodes, has BOH been any good?\n\t- Social paid\n\t- Social organic\n\t- SEM\n\t- GA4\n\n\n### Hypothesis 1: Increased Website Engagement\n\n> **Hypothesis**: If the podcast is effective, there will be a measurable increase in website engagement metrics related to F&B content.\n\n- **Sub-hypothesis 1.1**: Podcast listeners are visiting the website after engaging with F&B episodes.\n    - **Testable Metrics**: Click-through rate (CTR) from LinkedIn to the website, direct traffic spikes after episode release.\n      \n- **Sub-hypothesis 1.2**: Website visitors are engaging with F&B content on the site.\n    - **Testable Metrics**: Time spent on F&B pages, page depth on F&B-related articles.\n      \n- **Sub-hypothesis 1.3**: Return visitors are increasing.\n    - **Testable Metrics**: Number of return visitors, repeat visits to F&B content pages.\n\n\n\n### Hypothesis 2: Positive Brand Perception and Authority in F&B\n\n> **Hypothesis**: The podcast is positioning the agency as an authority in the F&B sector.\n\n- **Sub-hypothesis 2.1**: Audience is engaging with F&B content and sharing it.\n    - **Testable Metrics**: Social shares, LinkedIn post engagement (likes, shares, comments) on F&B episodes.\n      \n- **Sub-hypothesis 2.2**: F&B episodes are receiving positive feedback.\n    - **Testable Metrics**: Comments, direct messages, or survey results indicating perceived expertise.\n      \n- **Sub-hypothesis 2.3**: Organic reach is growing within the F&B audience.\n    - **Testable Metrics**: Increase in followers from F&B industry, growth in LinkedIn engagement from F&B professionals.\n\n\n\n\n### Hypothesis 3: New Client Leads from F&B Sector\n\n> **Hypothesis**: The podcast is directly contributing to attracting new leads from the F&B sector.\n\n- **Sub-hypothesis 3.1**: F&B-related leads are coming in through the website.\n    - **Testable Metrics**: New leads or inquiries via website forms attributed to F&B content.\n      \n- **Sub-hypothesis 3.2**: Leads mention the podcast as an influencing factor.\n    - **Testable Metrics**: Survey or direct inquiry form responses referencing the podcast.\n      \n- **Sub-hypothesis 3.3**: Paid LinkedIn campaigns for F&B episodes lead to inquiries.\n    - **Testable Metrics**: Conversion rate from paid LinkedIn ads, increase in relevant leads from LinkedIn traffic sources.\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"Greenwood","tags":[],"path":"/Strategy/Greenwood","body":"\n\n### Week 2\n\nHow do I make informed decisions?\n\n- What is happening in the organization?\n\nFrederick Taylor: Standardize processes, implement throughout the org\n\n1) Replace conventional wisdom\n2) Train employees properly\n3) Provide detailed info and supervision\n4) Mgmt needs to define what the roles are\n\nConvincing management\n\n1) This change won't be hard\n2) It will be worth it\n\nComparing one group to another group\n\n1) **T-test**: checks whether 2 means are different from each other\n2) **ANOVA**: compare means of more than 2 groups\n   One way\n   Repeated measure\n   Factorial\n   Limits of anova - what if we dont want to compare groups?  eg when we are looking to determine how 2 variables move together\n3) **Regression**\n   Logit / probit\n   Tobit (use with censored data)\n   Poisson / negative binomial - count data\n\n---\n\n### Week 4\n\n\nFundamental problem with quantifying the firm\n\n- Do I know why the change occurred?\n\nCausality matters when we are actually setting new policy\nEndogeneity - from within the system\nOmitted variable bias\n\nSolving problems of causality vs reverse causality vs correlation\nIntro exogenous variables to our model\nRun an experiment\n\nA/B tests: identical in every way but 1\n\nWhat if we cant randomly assign?\nTake a fixed effect (time series data)\nThink a Craigslist example where we need to control for city and control for month\nMatching - instead of completely random assign, just to find \"twins\" and treat only one\nDon't try to interpret fixed effects, we include them in the model to control for them\n\n---\n\n\n### Week 6\n\nProblems with enacting policy\n\n- How do we anticipate problems, not just react (assess the probability of known events)\n\nPredict vs cause\nPredict = observing relationships -- develop formula to predict dependent variables -- is there accuracy in our prediction?\nCause = does a IV really cause a DV?\n\nEndogeneity (omitted variable bias) is more significant in causal analysis --> we need to know that THIS yields THIS\nR-squared is more significant in predictive analysis --> we need to make sure this is not out of sample\n\nMulticollinearity matters more in causal --> we don't want to wrongly attribute significance to the wrong variables\nMeasurement error matters more in causal --> biases our coefficient in causal. In prediction, as long as we are predicting accurately, we are okay\n\n"},{"title":"History of DS","tags":[],"path":"/Strategy/History of DS","body":"\n\n## 50 Years of Data Science\n[Paper](https://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)\n\nInteresting stories\n- > Pg 6 | In the late 1700s, **census** data started being collected to get data about all inhabitants of a country. This is where the term ‘**statistics**’ was coined. A statistician (Hollerith) invented the punched card reader to compile US results. #story\n\n- > Pg 10, John Tukey | I used to think of myself as a statistician, focused on drawing inferences from the specific to the general. However, observing the evolution of mathematical statistics has led me to question this identity. Over time, I’ve realized that my true interest lies in data analysis. This encompasses methods for analyzing data, interpreting results, planning data collection to improve analysis, and the statistical tools and insights that support these activities. #story \n\t- Tukey’s central claim was that this new entity, which he called ‘**Data Analysis**’, was a new science, rather than a branch of mathematics. The subject of interest was **learning from data**. (Currently called '**Data Science**'.)\n\n\n### Ch 2 | DS v Stats\n\n*What distinguishes stats & DS?* In this chapter, author is basically suggesting that stats & DS have the same objective - learning from data. He then talks about the 3 \"memes\" that people use when favoring DS, and argues against each one.\n\n1. **\"Big Data?\"** Author suggests people tend to associate Big Data with DS, so university presidents or others working in \"sales\" roles use the term \"DS\" instead of \"stats\" for commercial benefits.\n2. **\"Skills?\"** Author suggests Computer Scientists tend to regard DS as able to work with Big Data, whereas statisticans cannot. Author says that this moves away from the \"learning from data\" definition - says that this type of thinking moves away from \"what is our analysis strategy\" into \"what is the easiest technique for our computer\".\n3. **\"Jobs\"?** Author notes that job postings seem to require additional skills such as computing/database skills. Author says this is IT type of info, shouldn't be considered in the \"stats vs DS\" debate.\n\n\n\n### Ch 3 | Future of Data Analysis (1962)\n\nIn this paper, John Tukey downplays the role of formal statistical inference. Instead, he says that what matters is *data analysis* (learning from data). This encompasses the whole process, making statistical inference a subset of data analysis.\n\nTukey identified four driving forces in the new science: \n\n>  Four major influences act on data analysis today: \n>\n> 1. The formal theories of statistics\n> 2. Accelerating developments in computers and display devices \n> 3. The challenge, in many fields, of more and ever larger bodies of data\n> 4. The emphasis on quantification in an ever wider variety of disciplines\n\n\n\nSo Tukey’s vision embedded statistics in a larger entity. Tukey’s central claim was that this new entity, which he called ‘Data Analysis’, was a new science, rather than a branch of mathematics\n\nAt the time, statistics was considered a sub-field of mathamatics. This new broader classification of \"data analysis\" can be viewed as a science.\n\n\n\n### Ch 4 | 50 Years Since FoDA\n\nThis section talks about how statisticians were hesitant to join this new \"data analysis\" field, but that it is necessary to avoid becoming obsolete.\n\nWilliam Cleveland (Bell Labs) proposed 6 foci of activity\n1. Multidisciplinary investigations (25%) \n2. Models and Methods for Data (20%) \n3. Computing with Data (15%) \n4. Pedagogy (Teaching) (15%) \n5. Tool Evaluation (5%)\n6. Theory (20%)\n\n\n\n### Ch 8 | Full Scope of DS\n\nThe activities of Greater Data Science are classified into 6 divisions: \n1. EDA & Cleaning\n2. Understanding Databases & Applying Mathematical Transformations\n3. Computing with Data (Knowing languages, cloud/clusters, etc)\n4. Data Modeling (Causal & Predictive)\n5. Data Visualization (Learning about data, dashboards for monitoring, conclusions from modeling)\n6. Science about Data Science (Research, domain knowledge)\n   > The true effectiveness of a tool is related to the probability of deployment times the probability of effective results once deployed. Tukey, pg 24\n\n\n\n\n## Timeline\n\n### Early Figures in Statistics\n\n1. **Blaise Pascal (1623-1662)**\n   - **Contributions:** Developed the foundations of probability theory, worked on Pascal's Triangle and the concept of expected value.\n2. **Pierre-Simon Laplace (1749-1827)**\n   - **Contributions:** Made significant contributions to the field of probability and statistics, including the Bayesian interpretation of probability.\n3. **Carl Friedrich Gauss (1777-1855)**\n   - **Contributions:** Developed the method of least squares and the Gaussian distribution (normal distribution).\n4. **Francis Galton (1822-1911)**\n   - **Contributions:** Introduced concepts of correlation and regression to the mean, and made early contributions to the field of eugenics.\n\n\n### 20th Century Pioneers\n1. **Ronald A. Fisher (1890-1962)**\n   - **Contributions:** Developed the analysis of variance (ANOVA), maximum likelihood estimation, and the design of experiments. Fisher is often referred to as the father of modern statistics.\n2. **Jerzy Neyman (1894-1981)**\n   - **Contributions:** Introduced the Neyman-Pearson lemma, a fundamental result in hypothesis testing. Developed concepts of confidence intervals and the theory of estimation.\n3. **John Tukey (1915-2000)**\n   - **Contributions:** Developed the Fast Fourier Transform (FFT) algorithm, exploratory data analysis (EDA), and box plots.\n4. **Andrey Kolmogorov (1903-1987)**\n   - **Contributions:** Formulated the axioms of probability theory and made significant contributions to the theory of stochastic processes.\n\n\n### Data Science and Computing Pioneers\n1. **John von Neumann (1903-1957)**\n   - **Contributions:** Made foundational contributions to computer science, including the architecture of the modern computer (von Neumann architecture).\n2. **Alan Turing (1912-1954)**\n\n- **Contributions:** Pioneered theoretical computer science and artificial intelligence. Developed the concept of the Turing machine and the Turing test.\n\n1. **Claude Shannon (1916-2001)**\n\n- **Contributions:** Known as the father of information theory, Shannon developed the mathematical foundations of communication and data compression.\n\n\n\n\n\n### Modern Figures in Data Science\n\n1. **Geoffrey Hinton (b. 1947)**\n- **Contributions:** A pioneer in artificial neural networks and deep learning. His work on backpropagation and deep learning algorithms has had a profound impact on AI and machine learning.\n\n1. **Yann LeCun (b. 1960)**\n- **Contributions:** Developed convolutional neural networks (CNNs), which are widely used in image and video recognition.\n\n1. **Judea Pearl (b. 1936)**\n- **Contributions:** Made significant contributions to artificial intelligence and causal inference, developing Bayesian networks and the theory of causal and counterfactual inference.\n\n1. **Cynthia Dwork (b. 1958)**\n- **Contributions:** A key figure in the development of differential privacy, ensuring privacy-preserving data analysis.\n\n1. **Hadley Wickham (b. 1979)**\n- **Contributions:** Developed numerous influential tools for data analysis in R, including ggplot2, dplyr, and tidyr, which are widely used in the data science community.\n\n\n\n\n\n\n## AI Timeline\n\n[Book | Oreilly](https://learning.oreilly.com/library/view/hands-on-artificial-intelligence/9781788991063/95d2ab83-e690-4866-8cde-b503dbcc3ca8.xhtml)\n\n> **AI** | Systems that allow computers to perform tasks without explicitly programming\n\n**1956** *Dartmouth Summer Research Project*: Their topics of discussion were fairly forward-thinking for the time – they could have easily been those of an AI conference today—ANNs, NLP, theories of computation, and general computing frameworks.\n\n**1958**: *Perceptron*: Single-layer networks that work as linear classifiers. Consist of four main architectural aspects: (1) input layer (2) weights & biases (3) summation function (4) activation function.\n\n**1980-1987**: *Rebirth*: Hinton coins term \"deep learning\", works with Rumelhart to create back-propagation. \n\n**1997-2005**: *Modern era*: IBM Deep Blue (chess), Bell Labs develops CNNs, development of LSTMs.\n\n**2012-Now**: Cheaper computing power. Other helpers: GPUs, drop-out, ReLu\n\n\n\n\n### NLP History\n\n1950: Turing Test\n\n1980s-1990s: **Symbolic** NLP\n\n- Rule-based parsing (e.g., the development of HPSG as a computational operationalization of generative grammar)\n- Morphology (e.g., two-level morphology)\n- Semantics (e.g., Lesk algorithm)\n- Reference (e.g., within Centering Theory)\n\n1990s-2010s: **Statistical** NLP\nBefore the 90's, most NLPs were based on hand-written rules. Then, ML enters the picture. Why?\n\n1. **Moore's law**: increase in computational power\n2. **Change in linguistic theory** (Transformational vs corpus): Moving to *corpus*.\n   1. **Transformational grammar (Chomsky)**: Each sentence has (1) what the speaker meant & (2) a surface grammatical structure (observable form). \"Transformational rules\" map (1) to (2) and vice-verse.\n   2. **Corpus linguistics**: An approach to the study of language that relies on the analysis of large & principled collections of naturally occurring language data, known as corpora. This methodology aims to understand language use based on real-world examples rather than relying solely on theoretical constructs.\n\n1990s: \nLaws call for governments to translate meetings into official languages of other governments.\nCanada & EU produce multilingual textual corpora.\nIBM Research uses this to advance field of *machine translation*.\n\n2000s: \nGrowth in world-wide-web.\nResearch increases in unsupervised & semi-supervised learning.\n\nPresent: **Neural Nets**\n2003: Yoshu Bengio's **MLP** (multi-layer perceptron) beats n-gram model\n2010: Tomáš Mikolov applies RNN, then develops **Word2vec**. ML usage becomes wide-spread, especially in health care.\n2015: Neural networks replaces statistical. Instead of requiring elaborate feature engineering, NN uses **word embeddings** to capture semantic properties of words.\n\nOther tasks made obsolete by NNs\n- **Part-of-speech tagging**: Tag for each word (noun, verb, adjective, etc.)\n- **Dependency parsing**: Grammatical structure of a sentence due to relationships between words\n- **Word alignment**: Translate words in different languages\n\n"},{"title":"Undergrad Capstone","tags":[],"path":"/Strategy/Undergrad Capstone","body":"\n\n### 1. Intro\n\n**Strategy**: Gain & sustain competitive advantage\n- Plan to solve / respond to problem\n- Requires trade offs for strategic positioning\n- Only have 2-3 main points of focus\n\n**Kernel of strategy**\n- **Diagnosis**: What are we actually solving? How important is it?\n- **Guiding policy**: Solution to the diagnosis + flow from diagnosis\n- **Coherent Action**: Who does what? Where? When? Low level details\n\n\n**AFI Framework**: 3 key elements of strategy\n\n1. **Diagnosis**: What is the competitive landscape?\n- External analysis (industry structure, competitive forces, strategic groups)\n- Internal analysis (resources, capabilities, core competencies)\n- Competitive advantage, firm performance, business model\n\n2. **Guiding policy**: Guiding idea to address competitive challenge\n- Business strategy (differentiation, cost leadership, integration, innovation and entrepreneurship)\n- Corporate strategy (vertical integration, diversification, mergers, strategic alliances)\n- Global strategy (competing around the world)\n\n3. **Coherent Action**: Strategy implementation (Actions to implement idea)\n- Organizational design (structure, culture, control)\n- Corporate governance & business ethics\n\n---\n\n**Effects on firm performance**\n- 55% our effects\n- 20% industry as a whole effects\n- 25% other effects (business cycle, unexplained variance)\n\n**Stakeholders: Superior performance drives reinvestments**\n- External: customers, media, suppliers\n- Internal: employees, stockholders, board members\n\nHow good stakeholder management helps: Cooperation, trust means lower transaction costs, greater adaptable, strong reputation\n\n**Stakeholders impact analysis:** recognize, assess, and address needs of stakeholders, helps achieve competitive advantage\n1. Who are the stakeholders?\n2. What are their interests?\n3. What opps / threats do they pose?\n4. What responsibilities do we have to them?\n5. How to address their concerns?\n\nNeed positive relationships to survive **Black Swan** (unanticipated) events.\n\n---\n\n\n### 2. External\n#### PESTEL\nPolitical, economic, sociocultural, tech, ecological, legal\n- What's most important for our company?\n- What really moves the needle + how it will make a difference?\n\n1. Political\n   Govt influence (eg Subsidies, investment in R&D)\n   Political pressure (eg Drug prices, loan rates)\n\n2. Legal\n   Antitrust regulations, environment, hiring laws, SOX\n3. Economic variables\n   Int rates, employment levels, inflation, disposable income\n\n4. Sociocultural\n   Lifestyle, society values, family size, ethnicity\n\n5. Technology\n   Capturing application of knowledge\n\n6. Ecological\n   Natural environment, global warming\n\n\n#### Industry Structure\n\nIndustry Analysis identifies the industry's profit potential.\n\nCompetitive Advantage = a large value gap (V - C)\n- V = how much people want it\n- C = cost\n\nAttractive industry: high competitive advantage easy (profit potential & weaker 5 forces)\n\n\n\n#### 5 forces\n\nHow profitable firms COULD be, but actual success depends on minimizing weaknesses & taking advantage of strengths.\n\nStructure of the industry based on:\n- Number & size of competitors\n- Pricing power\n- Products offered\n- Barriers of entry\n\n\n**(1) Threat new entrants**\nBarriers to entry\nCustomer switching costs\nCapital requirements\nIncumbents (established brand, prop tech, distribution channels)\n\n**(2) Bargaining power of buyers**\nPricing power\nStrong supplier power when:\n\tSupplier industry concentrated\n\tDon't depend much on current customers, switching costs high\n\tLimited substitutes\n\n**(3) Bargaining power of suppliers**\nPricing power\nStrong buyer power when:\n\tFew large buyer\n\tStandard products\n\tFew switching costs\n\tNo asymmetric info\n\n**(4) Threat of substitutes**\nAttractive price-performance trade-off\nWhen lower price impact MB greater than lower quality MC\nBuyers switching costs low, limits price we can charge\n\n**(5) Incumbent rivalries**\nThink perfect competition\nHigh exit barriers, direct substitutes\n\n#### Competitor Analysis\n\n**Strategic Groups:** why performance can differ greatly within industry\n- Firms with same strategic group = same strategy (Delta & United)\n- Group differences id different strategies (Delta vs regional)\n- Direct competitors = firms in our group (Delta, United)\n- Rivalry within (Delta vs United) is greater than outside rivalry (huge airline vs regional)\n\n**Mobility barriers:** Restrict movement between groups\n\n\n\n### 3. Internal\n\n**Core competency** --> competitive advantage --> differentiation or cost leader\n- **Resources**: Business's assets\n  - Tangible: Capital and labor\n  - Intangible: Culture, reputation, IP\n- **Capabilities**: Ability to exploit its resources\n- **Competency**: Integration and coordination of capabilities\n\n\n\n#### VIRO\n\nObjective is to sustain competitive advantage.\n\nValuable\nRare\nCostly to imitate\nOrganized to capture value of resources\n\nDone at the **resource** level, not the company level.\n\nAssumptions:\n- Hetero resources across the industry\n- Sticky resources from firm to firm\n\n\n\n\n\n**AirAsia Case Notes**\n\n**(1) Problem formulation:**\n\n- Diagnosis: What are we actually solving and how important is it?\n- Diagnosis: How does AirAsia maintain their competitive advantage through their cost leadership strategy without impacting their image in an industry that is typically viewed as having razor thin margins?\n\n**(2) Analytical frameworks: VRIO**\n\n- Achieving sustainable competitive advantage (Internal analysis)\n- Differentiation or cost leadership comes from competitive advantage, which in turn comes from core competencies.\n- Airasia’s CC = much lower long run average expenses compared to the industry\n- Competitive advantage = able to profitably offer lower prices to customers (cost leadership strategy)\n\n**VRIO Overview (Done at resource level, not company level)**\n\n- **Valuable**: Are the features attractive, do they provide lower costs?\n- **Rare**: Is this capability / resource only possessed by a few firms?\n- **Costly to imitate**: Hard for other firms to develop this resource / capability at a reasonable price?\n- **Organized to capture value of resources**: can it help exploit competitive potential?\n\n**VRIO Example**\n\n- **Resource / Capability**: Utilization of staff\n- **Valuable**: Yes - lower average costs when people can perform multiple tasks\n- **Rare**: Yes - typical for firms to have employees specialize\n- **Costly to imitate**: Yes - requires additional up-front training\n- **Organized to capture value of resources**: Yes - huge part of maintaining competitive advantage through cost leadership\n\n\n\n### 4. Strategy\n\nStrategy (Differentiation, Cost Leader, Integrate)\n\n**Determining Strategy** (**Economic value added = Value — Cost**)\n1. Who buys our stuff?\n2. Why do they want it?\n   Cost leader\n   Product differentiation\n3. How do we get it to them?\n\n\n\n**Value Drivers**\n\n(1) **Differentiation**: Minimized substitution, many are tough to imitate\n- Product: quality, convenient, unique etc\n- Customer service\n- Complements: extra stuff along with product\n\n(2) **Cost leader**: Invest in resources that drive down costs in the long run\n- Input factors\n- Economies of scale\n- Learning curve effect\n- Experience curve effect\n\n(3) **Integration**: best of both worlds, very difficult to achieve\n- Technology and innovation: better quality but lower cost\n- Economies of scope\n- Structure & culture\n\n\n**Cost Drivers**: Economies of scale, all of these \"hurt\" at first, then help down the line\n- Learning curves pushed down, then\n- Process innovation pushes down, then\n- Experience curve pushes down\n"},{"title":"_Strategy MOC","tags":[],"path":"/Strategy/_Strategy MOC","body":"\n```dataview\nTABLE without id\n\nfile.link,\ncovers,\n\nQuality,\n\n\"<progress max=\" + \n(sum(HoursDone) + sum(HoursRemain)) + \" value=\" + number(\nsum(HoursDone)) + \"> </progress> \"  + number(\nsum(HoursDone)) + \" of \" + number(\nsum(HoursDone) + sum(HoursRemain)) + \" \" + \"hours\" + \" (\" +round(number(\nsum(HoursDone))/number(\nsum(HoursDone) + sum(HoursRemain))*100) + \"%\" + \")\" as Progress,\n\nsum(HoursRemain) as Remain\nfrom outgoing([[]])\n```\n\n\n\nDeeper\n- [[Undergrad Capstone]]\n- [[Greenwood]]\n- [[History of Data Science]]\n\n\n[Profit Max](Profit%20Max.canvas) - Logic tree. #monthly\n\n[Case Studies](Case%20Studies.md) - McKinsey structure #monthly \n\n\n    \n"},{"title":"Supervised-2-Classification","tags":[],"path":"/Supervised-2-Classification","body":"**2025-02-02**: DONE, quality could be improved though.\n\nResources\n- [Stanford Cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-machine-learning-tips-and-tricks)\n- [k-nn - 100 days guide](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Code/Day%2011%20K-NN.md)\n\n[Image: Decision Boundaries](https://i.imgur.com/rljQgL9.jpeg)\n\n## Overview\n- **Purity Measures**: Gauge how homogeneous or “pure” each segment is after splitting.\n- **Information Gain**: Measures the effectiveness of a new split (or segment) compared to the original.\n- **Statistical Significance**: Each additional “child” branch in a tree should be validated, often with a chi-squared test, to confirm that the improvement in segmentation is statistically significant.\n\n\n## Table Summary\n\nhttps://chatgpt.com/share/679fc159-020c-8000-b16e-e3fd1b93bfc7\n\n- **k-NN** is intuitive and simple but can be slow for large datasets.\n- **Naive Bayes** is fast and works well with high-dimensional data but assumes independent features.\n- **Logistic Regression** is a well-understood parametric approach, ideal for linearly separable data, and can handle regularization elegantly.\n- **Decision Trees** are highly interpretable but can overfit if not carefully regularized (via max depth, minimum samples per leaf, etc.).\n\n\n```ad-sam\n\n| **CATEGORY**            | **CORE IDEA**                                                                                                                                                          | **MODEL TYPE**     | **KEY HYPERPARAMETERS**                                                                                                                                           | **STRENGTHS**                                                                                                                            | **WEAKNESSES**                                                                                                                                                                                     | **REGULARIZATION**                                                                              |\n| ----------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |\n| **k-NN**                | 1. Find _k_ closest neighbors <br><br>2. Majority vote or average.                                                                                                     | **Non-parametric** | **k**: Number of neighbors.<br><br>**Distance metric**                                                                                                            | Simple to implement. <br><br>Minimal statistical assumptions. <br><br>Models complex decision boundaries.                                | Slow for large data. <br><br>Bad in high-d space. <br><br>Domain knowledge for good distance metric.                                                                                               | Not typically applied, could use dimensionality reduction                                       |\n| **Naive Bayes**         | Applies Bayes’ Theorem with a **naive** assumption of conditional independence among features                                                                          | **Probabilistic**  | **Distribution** choice (e.g. Multinomial)                                                                                                                        | Fast <br><br>Robust with many features. <br><br>Works well with small datasets.                                                          | Bad if features are highly correlated.                                                                                                                                                             | Smoothing techniques to avoid zero probabilities. (e.g., Laplace smoothing)                     |\n| **Logistic Regression** | Estimates the probability of each class via a **linear combination** of features passed through a **sigmoid** (or softmax) function, making it a **parametric** model. | **Parametric**     | **C**: Inverse regularization strength. <br><br>**multi_class**: One-vs-Rest or multinomial. <br><br>**Regularization** type                                      | Interpretable coefficients. <br><br>Can incorporate **regularization** <br><br>Good when data is linearly (or log-linearly) separable.   | May struggle with highly non-linear relationships. <br><br>Sensitive to outliers if **regularization** is not used properly. Assumes linear (or log-linear) deci-bound.                            | **L1 (Lasso)** <br><br>**L2 (Ridge)** <br><br>**Elastic Net**: Combo of L1 and L2.              |\n| **Decision Trees**      | Splits data into **hierarchical** branches based on feature values, aiming to maximize “purity” at each split.                                                         | **Non-parametric** | **max_depth**: Maximum tree depth.<br><br>**min_samples_leaf**: Minimum samples required in a leaf node. <br><br>Splitting **criterion** (e.g., Gini or Entropy). | Highly interpretable <br><br>Handles numeric & categorical <br><br>Don't need scaling or dummies. <br><br>Handles multi-output problems. | **Overfitting** if grown without constraints. <br><br>Greedy splitting may not yield a global optimum. <br><br>Sensitive to data imbalance. <br><br>Can struggle with certain complex interactions | Indirectly via **max_depth**, **min_samples_leaf**, etc. <br><br>Pruning can reduce overfitting |\n\n```\n\n\n## Extra Details\n### Naive Bayes\n\n```ad-sam\nIntuition\n- For each observation, given its characteristics (features), the model computes the probability that it belongs to a particular class. (Often relies on different distributions for numeric columns.)\n\n\n**Prob of being in group**\n= prop of my attribute given that they were in the group \n\\* prop of dataset in the group \n/ prop of dataset with my attribute\n\n<img src=\"https://i.imgur.com/pgtG11S.png\" style=\"zoom:33%;\" />\n\n\n```\n\n\n### Logistic\n\n```ad-sam\nTarget\n- **Binary (Logit)**: Two classes (0 or 1).\n- **Softmax Regression**: Multiple classes (unordered); picks the class with the highest probability.\n- **Ordered Logit**: Multiple _ordered_ classes.\n\n\n$probability(x) \\: = \\: \\frac{1}{e^(-1 \\: * \\: regression \\: model)}$\n\n[Image | Logistic Regression Sigmoid Curve](https://i.imgur.com/nq0l2cu.png)\n\nSteps\n1. For each observation in the raw data, we calculate the sum of the coefficients for all variables. This is f(x).\n2. The x-axis location on the logit plot is the f(x) we calculated above for each observation.\n3. For each observation, we then assign the probability of fitting into the top or bottom group according to the logit curve.\n4. We use the probabilities that we found in the logit model as a way to best fit the line that separates our groups apart to minimize the error in our sample. This is how we determine our original slope and intercept.\n5. We assign L1 as the maximum f(x) that we are willing to allow. (This is lambda)\n   More complex = higher f(x) = larger diamond\n6. We 'underfit' the model until it connects with the blue diamond (ie max complexity we allow). This new model will provide us with a new slope and intercept that will generalize better.\n\n```\n\n\n#### Regularization\n\n```ad-sam\nRegularization helps prevent **overfitting** by penalizing large coefficients.\n\n| **Type**                | **Penalty**                                 | **Key Characteristics**                                                                                          |\n|-------------------------|---------------------------------------------|-------------------------------------------------------------------------------------------------------------------|\n| **L1 (Lasso)**          | Sum of absolute values of weights           | - Encourages sparsity (some coefficients may become zero)<br/>- Can be unstable with highly correlated features<br/>- Avoids using all features if many are redundant |\n| **L2 (Ridge)**          | Sum of squared values of weights            | - Tends to shrink coefficients but rarely sets any to zero<br/>- More stable in the presence of correlated features |\n| **Elastic Net (L1 + L2)** | Combination of L1 and L2 penalties         | - Useful when multiple correlated features are suspected<br/>- Retains feature selection from L1 while benefiting from L2’s stability |\n[Image | Regularization](https://i.imgur.com/kkS2s4S.png)\n[Image | Normalization](https://i.imgur.com/sZeYixm.png)\n\n```\n\n\n### Decision Trees\n\n#### Purity\n\n```ad-sam\nWhen deciding how to split a node, decision tree algorithms use measures like **Gini Impurity** or **Entropy** to assess how \"pure\" the resulting child nodes are. Below is a quick comparison:\n\n| **Measure**      | **Range (Binary Setting)** | **Calculation**                  | **Characteristics**                                                                                  |\n|------------------|----------------------------|----------------------------------|-------------------------------------------------------------------------------------------------------|\n| **Gini Impurity**| 0 (pure) to 0.5 (impure)  | Uses squares of class probabilities | - Slightly faster to compute<br>- Tends to isolate the most frequent class                          |\n| **Entropy**      | 0 (pure) to 0.5 (impure)  | Uses logs of class probabilities    | - Tends to produce more balanced splits                                                              |\n\n```\n"},{"title":"Supervised-3-Classification-Eval","tags":[],"path":"/Supervised-3-Classification-Eval","body":"\n**2025-02-02**: DONE.\n\n## Week 3: Class Eval\n\n- [How to train a model](https://sebastianraschka.com/faq/docs/evaluate-a-model.html)\n- [Classification eval for unbalanced data](https://classeval.wordpress.com/introduction/introduction-to-the-precision-recall-plot/)\n- [Sci-kit plot](https://github.com/reiinakano/scikit-plot)\n\n\n**Accuracy** can be misleading. 2 primary reasons:\n1. **Imbalanced Class Distributions**: When one class dominates, accuracy may inflate how well the model performs.\n2. **Ignoring Economic Costs/Benefits**: Different types of errors can have varying costs. It’s often more insightful to build a cost/benefit matrix and maximize profit, rather than maximizing accuracy.\n\nCost-Benefit Approach\n1. Construct a “cost/benefit” matrix, detailing the financial impact of each type of prediction:\n   - **TP** & **TN**: Represent revenue or benefits.\n   - **FP** & **FN**: Represent costs or losses.\n2. Multiply your confusion matrix by the cost/benefit matrix to calculate expected profit (or cost), and use this to guide decisions.\n\n### Formulas (TP, FP, TN, FN)\n\n```ad-sam\n\n| **Metric**                            | **Formula**          |\n| ------------------------------------- | -------------------- |\n| **True Positive Rate (TPR) / Recall** | $\\frac{TP}{TP + FN}$ |\n| **False Positive Rate (FPR)**         | $\\frac{FP}{FP + TN}$ |\n| **Precision**                         | $\\frac{TP}{TP + FP}$ |\n| **Recall (Same as TPR)**              | $\\frac{TP}{TP + FN}$ |\n\n```\n\n\n### Model Evaluation Techniques\n\n[ChatGPT](https://chatgpt.com/share/435a9d82-0d85-4b76-bbec-5b73391dc0f6): Key \"curves\" and model evaluation techniques commonly used in classification:\n\n`Scope`\n- **Within**: These methods evaluate how well a single model is performing, often helping diagnose issues like overfitting, threshold tuning, and class imbalance.\n- **Across**: These methods compare multiple models or evaluate the model’s added value over a random baseline.\n- **Either**: Some techniques can be used **either within a model** (e.g., tuning a threshold) or **across models** (e.g., selecting the best-performing one).\n\n```ad-sam\n\n| `Scope` | **Evaluation Technique**                                | **What**                                                                                                              | **Why**                                                                                                                    | **Imbalanced Data Suitability**                                                                                       |                                                                                                     |\n| ------- | ------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n| Within  | **Confusion Matrix**                                    | Shows the counts of (TP, TN, FP, FN)                                                                                  | From here, can derive performance metrics.                                                                                 | -                                                                                                                     | [Imgur](https://i.imgur.com/GqFRVwK.png)                                                            |\n| Within  | **ROC Curve**<br> <br>Receiver Operating Characteristic | Plots TPR vs. FPR at different probability thresholds.                                                                | Offers insight into the trade-off between TP & FP.                                                                         | **Bad**. When negative class is large, the FPR remains deceptively low, which makes ROC curve look overly optimistic. | [Img1](https://i.imgur.com/MWVJ5bc.png), [Img2](https://i.imgur.com/icN6gnX.png)                    |\n| Either  | **AUC**<br><br>Area Under the ROC Curve                 | A single-number summary (the area under the ROC curve).                                                               | $\\text{AUC} = 1$ indicates a perfect model. <br><br>$\\text{AUC} = 0.5$ indicates a model with no discriminative power.     | -                                                                                                                     | [Imgur](https://i.imgur.com/HLScrQ3.png)                                                            |\n| Either  | **Precision-Recall Curve**                              | Plots precision vs. recall as the decision threshold varies.                                                          | Especially useful for imbalanced datasets, or when false positives and false negatives incur high costs.                   | **Good**. Focuses on the minority class, where precision and recall are most critical.                                | [Img](https://i.imgur.com/oD7MUiT.png)<br><br>[Best & Worst Cases](https://i.imgur.com/3ukkvJx.png) |\n| Across  | **Lift Chart**                                          | Compares the model’s performance against a random baseline.                                                           | Shows how many more positives are identified by the model compared to random selection.                                    | **Good**. Especially relevant if you’re trying to identify a small minority class more effectively than chance.       | [Imgur](https://i.imgur.com/F6HmCkn.png)                                                            |\n| Across  | **Gain Chart**                                          | Displays cumulative gain (the fraction of positives identified) as you move through the sorted predictions.           | Similar to Lift, it shows the improvement gained by the model over random selection.                                       | **Good**. Like the Lift chart, it highlights model performance on minority classes.                                   | [Imgur - Profit Curve](https://i.imgur.com/SD9BQdL.png)                                             |\n| Across  | **Cumulative Response Curve**                           | Shows the proportion of positive instances captured as you move through the ranked predictions.                       | Commonly used in marketing and lead-generation applications to understand how quickly you capture most of the “yes” cases. | -                                                                                                                     | [Cumulative response curve](https://i.imgur.com/MJdeBr0.png)                                        |\n| Within  | **Validation Curve**                                    | Plots the training and validation scores across different levels of model complexity (e.g., varying hyperparameters). | Helps diagnose overfitting or underfitting by showing whether the model performance is improving or plateauing.            | -                                                                                                                     | [Imgur](https://i.imgur.com/lnaPwKO.png)                                                            |\n\n```\n\n\n### Single-Value Measures\n\n```ad-sam\n\n| **Metric**                                 | **What**                                                                                                                                                                          | **Why**                                                                                                                               | **Imbalanced Data Suitability**                                                                              |                                          |\n| ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | ---------------------------------------- |\n| **F-Measure (F1 Score)**                   | The harmonic mean of precision and recall: <br> $F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$                                    | Combines precision and recall into a single metric, weighting them equally.                                                           | **Good**. Highlights performance on the minority class, where both precision and recall can be low.          | [Imgur](https://i.imgur.com/yV39H3u.png) |\n| **Matthews Correlation Coefficient (MCC)** | A correlation coefficient between observed and predicted classifications: <br> $\\text{MCC} = \\frac{(TP \\times TN) - (FP \\times FN)}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$ | Accounts for all four quadrants (\\(TP, TN, FP, FN\\)) and provides a balanced measure even if the classes are of very different sizes. | **Good**. MCC is often more informative than accuracy and works well with imbalanced classes.                | [Imgur](https://i.imgur.com/ekP8auk.png) |\n| **Cohen’s Kappa**                          | Measures agreement between the model’s predictions and the true labels, adjusted for chance agreement.                                                                            | In imbalanced scenarios, a model might appear good by randomly guessing the majority class. Kappa accounts for this chance agreement. | **Mostly good**. While it adjusts for chance, it can still be influenced by highly imbalanced distributions. | [Imgur](https://i.imgur.com/nKydIUS.png) |\n\n```\n\n[ChatGPT - Types of Means](https://chatgpt.com/share/679fa4e5-5a1c-8000-a4c1-0c6d86650e7e) - Arithmetic, harmonic, geometric\n\n\n\n\n\n"},{"title":"Supervised-4-Regression-Eval","tags":[],"path":"/Supervised-4-Regression-Eval","body":"\n## Week 4: Regression Eval\n\n### Evaluation\n- **MAE** = Mean absolute error\n- **MAPE** = Mean absolute pct error\n- **RMSE** = Root mean squared error\n  when want to penalize large errors\n\n- **SMAPE** = Symmetric mean absolute percentage error\n  Goes from 0 to 200% \n  Apply when we are comparing average error of different models \n  Does not apply when we are looking at each observation\n\n### Lift\n\nRanked by their predicted number, comparing to the average\n\nY-axis = Revenue \n\n[Image](https://i.imgur.com/np7zERs.png)\n"},{"title":"Supervised-6-Ensemble","tags":[],"path":"/Supervised-6-Ensemble","body":"\n\n\n## Week 6: Ensemble\n\n- [Interactive Playground](http://arogozhnikov.github.io/2016/07/05/gradient_boosting_playground.html)\n- [Short Review Video](https://www.youtube.com/watch?v=m-S9Hojj1as)\n\n- [Bias vs Variance Graph](https://i.imgur.com/p6nfbsj.png)\n- [Summary of 6 techniques](https://i.imgur.com/PWVMWRG.png)\n\n\n\nData vs Model\n\n- **Data centric**: boosting and bagging (different training data) \n- **Model centric**: stacking (different training algorithms)\n\n---\n\nWhy ensemble?\n\n1. Inherent randomness in the world\n2. Bias: when no matter how many obs we get, our model will never reach perfection\n3. Variance: we are limited to samples, and these samples are never identical\n\n**Bias/Variance Tradeoff**\n\nEnsemble models: when we have high accuracy & high variance, can average them out to bring the variance down while still retaining the high accuracy\n\n\n\n### Using different algorithms\n\n- Hard vote: majority vote of multiple models\n- Soft vote (preferred): highest avg probability (more weight to more confidence)\n- Works best when each initial algo is a weak learner\n\n### Bagging and Pasting \n\n- Use the same algorithm, but train on different subsets of the training data (at the same time). \n- Usually gives similar bias, but smaller variance\n- Works well when each run is making mistakes on **different observations**\n\nBag vs Paste:\n\n- Bagging: With replacement\n  - Bagging is higher bias, lower variance. Usually performs better, but should use cv to check\n- Pasting: Without replacement\n\n---\n\n**Random patches** sampling rows and columns\n**Random subspaces** sampling columns (`boostrap=False, max_samples=1, bootstrapfeatures=True, max_features<1`)\n\nThis reduces variance because its comparing averages, not just one answer. Helps keep accuracy high for both in-sample and out-of-sample\n\n**Hyperparameters**\n\n- feature: max_features \n- feature: bootstrap_features \n- instance: max_samples (normally set to size of training set) \n- instance: bootstrap\n\n---\n\n**Random Forest**\n\n**Randomness**: We are able to keep the full tree, not pruned\n\n- Data: Different random sample\n- Features: For each tree, selects best feature to split on from a random subset of features. \n\n**Extremely randomized trees** also uses random thresholds for each feature when splitting \n\n---\n\n\n\n### Boosting\n\n[Image: Ada vs Gradient Boosting](https://i.imgur.com/8nV0HS8.jpg)\n\n[XGBoost Pydata Vid](https://www.youtube.com/watch?v=s3VmuVPfu0s)\n\nReview pg 205 for hyperparameters\n\n- Run model\n- Get residuals\n- Train another model on the residuals\n- Repeat\n- Final prediction: Sum up predictions from each model\n\n**Shrinkage**: small `learning_rate` + more trees\n\n#### AdaBoost \n1. Run model\n2. Add weight to observations we got wrong (`learning_rate` to tell how much to learn)\n3. Train another model using the updated weights (original data, **not the residuals**)\n4. Repeat\n5. Final prediction: Each of the models makes a prediction, **weighted vote** based on accuracy on the weighted training set \n\nWe could do `bootstrap=True`, but the final vote is still based on accuracy on training set\n\n---\n\n### Stacking\n\n1. Split the training set into 2 subsets (if we are only doing the blender once)\n   $\\quad$ 1st to train original classifer runs\n   $\\quad$ 2nd is the `holdout`: use the runs from above to make predictions on this set \n2. If we had 3 runs of the classifier, we will now have 3 predicted values for each row in the holdout set.\n3. Create a new training set using the 3 predicted values (as features) for each obs + the 1 true value (target)\n4. Train the `blender` on this new training set and make predictions using this model\n\n\n"},{"title":"Supervised","tags":[],"path":"/Supervised","body":"# Weekly\n\n[Canvas Page](https://canvas.umn.edu/courses/139500) | [Reading List](https://canvas.umn.edu/courses/139500/pages/reading-list) | [Self Assess](https://canvas.umn.edu/courses/139500/pages/weekly-self-assessment-questions)\n\n\n\n# ML Code\n\n## Classification\n\n[Curves (Matrix, Precision/Recall, ROC)](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n\n```python\n# Knn\nparam_grid = dict(n_neighbors = list(range(1,31)), \nweights = [\"uniform\", \"distance\"])\nknn = KNeighborsClassifier()\n\n# Tree\nparam_grid = dict(criterion = [\"gini\", \"entropy\"], \nmax_depth = range(2,10),\nmin_samples_leaf = range(2,8),\nmin_impurity_decrease = [0,1e-8,1e-7,1e-6,1e-5,1e-4])\ngrid_tree_clf = tree.DecisionTreeClassifier(random_state=45)\n\n# Logistic\nparam_grid = dict(penalty = ['l1', 'l2'], \nC = range(1,10))\n\n# SVM\nc = 5# reduce if overfitting\ndegrees = 3\ninfluence = 1 \npoly_kernel_svm_clf = Pipeline([\n (\"scaler\", StandardScaler()),\n (\"svm_clf\", SVC(kernel=\"poly\", degree=degrees, coef0=influence, C=c))\n ])\npoly_kernel_svm_clf.fit(X, y)\n```\n\n\n```python\n# In text\n\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\n\ntarget_names = ['malignant', 'benign']\ny_true = y_test\ny_pred = y_pred\n\nprint(target_names)\nprint(\"Accuracy: {0:.2%}\".format(accuracy_score(y_true, y_pred)))\nprint(\"Precision: {0:.2%}\".format(metrics.precision_score(y_true, y_pred)))\nprint(\"Recall: {0:.2%}\".format(metrics.recall_score(y_true, y_pred)))\nprint(\"F1: {0:.2%}\".format(metrics.f1_score(y_true, y_pred)))\nprint('-------------------------------------')\nprint(classification_report(y_true, y_pred))\n```\n\n```python\n# Visually - https://i.imgur.com/PExd8UC.png\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nprint(classification_report(ytest, yfit, target_names=faces.target_names))\n\nmat = confusion_matrix(ytest, yfit)\nsns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\nxticklabels=faces.target_names,\nyticklabels=faces.target_names)\nplt.xlabel('true label')\nplt.ylabel('predicted label');\n```\n\n\n"},{"title":"Theory - Univariate","tags":[],"path":"/TimeSeries/Theory - Univariate","body":"\n- [Springer Textbook](https://mybiostats.wordpress.com/wp-content/uploads/2015/03/time-series-analysis-with-applications-in-r-cryer-and-chan.pdf)\n- [University of South Carolina Lecture Notes (Heavy)](https://people.stat.sc.edu/Tebbs/stat520/f13notes.pdf)\n- [ChatGPT for cleaning this note doc](https://chatgpt.com/share/67cdcb8b-2818-8000-978e-1ad36398337a)\n\n### 1. Intro\n\n| Ch  | Topic  | Topic                                                                                    |\n| --- | ------ | ---------------------------------------------------------------------------------------- |\n| 2   | Basics | Mean, covariance, correlation, stationarity                                              |\n| 3   | Trend  | How to estimate & check common deterministic trend models                                |\n| 4   | ARMA   | Stationary, aka Box-Jenkins models                                                       |\n| 5   | ARIMA  | Nonstationary                                                                            |\n| 6   | Heart  | Techniques for tentatively specifying models                                             |\n| 7   | Heart  | Efficiently estimating the model parameters using least squares and maximum likelihood   |\n| 8   | Heart  | Determining how well the models fit the data                                             |\n| 9   | MSE    | Theory & methods of MSE for ARIMA                                                        |\n| -   | -      | The remaining chapters cover selected topics and are of a somewhat more advanced nature. |\n\n```ad-sam\n\n**Process**:\n1. **Check stationarity**.\n2. **If nonstationary**, use differencing or other transformations.\n3. Identify the number of days to use for ARMA using ACF, PACF, EACF.\n4. **Estimate model parameters**.\n5. **Validate model** (fit, residual checks, etc.).\n\n```\n\n\n### 2. Cheatsheet\n\n```ad-sam\n\n**Basics**\n- **Mean**: Average value over time.\n- **Covariance & Correlation**: Measure how two time points move together.\n- **Stationarity**: Means, variances, and autocovariances do not change over time.\n\n\n**Forecasting**: when consecutive observations are **not** independent. \n- *autocorrelation*: correlation between time points\n- *white noise*: no correlation\n\n```\n\n```ad-sam\n\n1. **Stationarity**\n   - **Definition**: Constant mean, constant variance, and autocovariance depends only on lag.  \n   - **Check**: Plot data, use ADF test, consider differencing if nonstationary.\n<br>\n1. **Autocorrelation Functions**  \n   - **ACF**: Helps identify MA processes (autocorrelations that cut off abruptly often indicate MA).  \n   - **PACF**: Helps identify AR processes (partial autocorrelations that cut off abruptly often indicate AR).\n<br>\n1. **Model Families**  \n   - **AR(p)**: Depends on its own past **values**.  \n   - **MA(q)**: Depends on past forecast **errors**.  \n   - **ARMA(p, q)**: Combination of AR and MA (stationary).  \n   - **ARIMA(p, d, q)**: Adds differencing for nonstationary data.  \n   - **SARIMA**: Adds seasonal components.\n<br>\n1. **Model Selection**  \n   - **ACF/PACF/EACF** to guess initial p, q.  \n   - **AIC/BIC**: Compare candidate models; lower is better.  \n   - Residual checks to ensure white-noise residuals.\n<br>\n1. **Forecasting**  \n   - **Naive**: Use the last observed value.  \n   - **Averaging**: Use the mean of recent observations.  \n   - **Exponential Smoothing**: Heavier weight on recent observations.  \n   - **ARIMA-based**: Incorporates AR/MA terms and differencing.\n<br>\n1. **Trends & Seasonality**  \n   - **Deterministic Trend**: Model explicitly if present (linear, polynomial, etc.).  \n   - **Seasonality**: SARIMA or explicit seasonal terms.\n\n\n```\n\n\n## 3. **Stationary vs. Nonstationary**\n\n```ad-sam\n**Stochastic Process**: A sequence of RVs indexed by time.\n\n- **Sample Path**: One particular realization of that stochastic process.\n- **Stationarity**:\n  - Constant mean over time.\n  - Constant variance.\n  - Constant autocovariance (depends only on the lag).\n  - No inherent seasonality.\n\n**Why Stationarity?**  \nWith only one observed path, stationarity lets us make reliable inferences about the underlying process from that single path.\n\n```\n\n### Random Walk (Nonstationary)\n```ad-sam\n- Values evolve via accumulating errors over time.\n- Variance grows with time.\n- Apparent “trend” might be random fluctuation.\n```\n\n### Converting to Stationary\n```ad-sam\n1. **1st differencing**:  \n   - A random walk $Y_t$ becomes stationary if you take $Y_t - Y_{t-1}$.  \n   - Use the **ADF test** to decide if differencing is needed.\n1. **2nd differencing** if one differencing step is not enough.  \n2. **Log transform** if variance grows with the level of the series (common for financial data).\n\n```\n\n---\n\n## 4. **Model Classes**\n\n### 4.1 White Noise\n\n```ad-sam\n\n- **Definition**: Sequence of i.i.d. RVs with mean 0 and constant variance.\n- **Autocorrelation**: Zero at all lags.\n\n```\n\n### 4.2 Moving Average (MA)\n\n```ad-sam\n- **MA(q)**: Current value depends on past $q$ errors (white-noise terms).\n- Example: **MA(2)**\n\n  $X_{t} = \\varepsilon_{t} + \\theta_{1}\\varepsilon_{t-1} + \\theta_{2}\\varepsilon_{t-2}$\n\n  - **Expected value** of $X_t$ is 0 (if no constant term).\n  - **Variance** of $X_t$ is $1 + \\theta_{1}^2 + \\theta_{2}^2$ (assuming $\\varepsilon_t \\sim \\text{iid}(0,1)$).\n  - **Covariance** terms depend on $\\theta_{i}$ values and the lag.\n\n```\n\n\n### 4.3 Autoregressive (AR)\n\n```ad-sam\n\n- **AR(p)**: Current value depends on its own past $p$ values.\n- Example: **AR(1)**\n\n  $X_{t} = \\phi X_{t-1} + \\varepsilon_{t}$\n\n  - Stationary if $|\\phi| < 1$.\n  - **Variance** of $X_t$ for AR(1):  \n    $\\text{Var}(X_t) = \\frac{1}{1 - \\phi^2}$\n  - **Covariance** at lag 1:  \n    $\\text{Cov}(X_t, X_{t-1}) = \\frac{\\phi}{1 - \\phi^2}$\n\n\n```\n\n#### Backshift Notation\n\n```ad-sam\n- **Backshift operator** $B$: $B(X_{t}) = X_{t-1}$.\n- **AR(1) in backshift form**:\n\n  $(1 - \\phi B)X_t = \\varepsilon_t$\n\n```\n\n\n### 4.4 ARMA\n\n```ad-sam\n- **ARMA(p, q)** = Autoregressive part (p) + Moving Average part (q).\n- **Stationarity**: Required for ARMA to work properly.\n```\n\n### 4.5 ARIMA\n\n```ad-sam\n- **ARIMA(p, d, q)**: Same as ARMA but the series is differenced $d$ times to achieve stationarity.\n- In backshift form:\n\n  $(1 - B)^d X_t \\quad \\text{follows an ARMA}(p,q)$\n```\n\n\n### 4.6 SARIMA\n\n```ad-sam\n- Adds **seasonal** terms for both autoregressive and moving-average, as well as seasonal differencing.\n- Notation: **SARIMA$(p,d,q)(P,D,Q)_m$** where $m$ is the seasonal period (e.g., 12 for monthly data with yearly seasonality).\n```\n\n---\n\n\n## 6. **Forecasting Methods**\n\n```ad-sam\n\n1. **Naive**  \n   - Forecast is simply the last observed value.\n\n2. **Average**  \n   - Forecast is the mean of recent or all observed values.\n\n3. **Exponential Smoothing**  \n   - Weighted average of past observations where weights decay exponentially.\n\n4. **ARIMA-based Forecasts**  \n   - Use the fitted ARIMA model to predict future values, taking into account AR/MA terms and differencing.\n\n**Example**:  \n- **Simple Exponential Smoothing** $\\approx$ ARIMA$(0,1,1)$ under some parameter relationships.  \n\n\n```\n\n---\n\n## 7. **Trends & Seasonality**\n\n```ad-sam\n- **Deterministic Trend**:  \n  - A function of time (linear, polynomial).  \n  - $Y_t = f(t) + \\text{stationary noise}$.\n  - If trend is linear ($f(t) = \\beta_0 + \\beta_1 t$), differencing can remove the linear component.\n\n- **Seasonality**:  \n  - Patterns repeat at fixed intervals.  \n  - Handle with seasonal differencing or adding seasonal AR/MA terms (SARIMA).\n\n- **Tests for Trend**:  \n  - **ADF**: If p-value is high, the series might need differencing or might have a deterministic trend.  \n  - **Residual Analysis**: Check whether residuals are white noise. If not, the trend model might be inadequate.\n\n```\n\n\n"},{"title":"Video Series","tags":[],"path":"/TimeSeries/Video Series","body":"\n- [Udacity: Time Series Forecasting w TensorFlow (Free)](https://learn.udacity.com/courses/ud187)\n\n\n#### RNN\n\n[TensorFlow Guide](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n\nRNN's are networks of **repeating modules**, each passing a message to a successor and allowing information to persist.\n\n**Cell state**: Horizontal top line. Updated by gates.\n\n4 layers (yellow)\n- Forget gate: Remove from the cell state\n- Input gate: Values to update from previous module\n- Tanh: Apply to step 2, add to the cell state\n- Sigmoid: Output to next module\n\n<img src=\"https://i.imgur.com/dscDU4d.png\" style=\"zoom:80%;\" />\n\n\n\n[14. Video](https://classroom.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/cb52c9ee-1abd-48d0-818a-3f7342a7b079)\n\nProcess of RNN (RNN: Contains recurrent layers) ([Image](https://i.imgur.com/CVLyo94.png))\n\n1. Take in the 3D **input windows**\n   1. Batch size\n   2. \\## of time steps\n   3. \\## of features in the model\n2. Send to a Recurrent Layer, composed of a single memory cell\n   1. Take value from previous time step\n   2. Output value for current time step **AND** the state/context so the model runs sequentially\n   3. Repeat\n3. Repeat \\#2\n4. Output forecast (ie Sequence to Vector)\n\n\n\n#### Lectures\n\n###### 0. Basics Overview\n- [4. Common patterns](https://learn.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/6630bdbc-2063-4010-83a4-6b61d1baebbc): White noise, trend, seasonality\n- [6. Forecasting](https://learn.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/23defc4f-9b23-4335-84e4-6779d3cdd0b0): Naive forecast, fixed vs roll forward partitioning\n- [8. Metrics](https://learn.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/1c065978-54ce-48cc-afb4-99113a9acf16): Differencing, MA, smoothing\n- [10. Time Windows](https://learn.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/d4f22578-ee8f-4c2c-ad4f-c7421f5406e4)\n\nSteps:\n1. **Tuning**: Train on training data, test on validation data\n2. **Estimating production**: Train on training & validation data, test on test data\n3. **Production**: Train on all 3, predict out\n\n###### 01. Pre-Steps\n\nWe want to make the time series as simple as possible before sending it to the model.\n\nNeed to get rid of the following:\n- Trend\n- Seasonality (months, weekdays, etc)\n  - Make sure train-val-test captures this seasonality\n\nUse **roll-forward** partitioning instead of **fixed** partitioning  ([Video](https://learn.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/23defc4f-9b23-4335-84e4-6779d3cdd0b0))\n- Fixed: Normal\n- Roll forward: Start with a short training period and then predict out. (Essentially mimicking real-life).\n  Note: Takes much longer\n\n\n**Metrics video**\n- **Differencing**: This helps get rid of the trend & seasonality\n- **MA**: Eliminates some noise but does not anticipate trend & seasonality (apply differencing first)\n- **Forecast for both** = trailing MA of differencing TS + centered MA of past series (t-365)\n\n```python\nimport pandas as pd\nseries = pd.Series(series)\n\nsplit_time = 1000    ### Train vs test\nts_diff = 365        ### Number of time periods to use for differencing\nts_ma = 50           ### Number of time periods to use for moving average\nts_smooth_past = 11\nts_smooth_begin = ts_diff + np.floor(ts_smooth_past / 2)\nts_smooth_end = ts_diff - np.ceil(ts_smooth_past / 2)\n\n### Differencing\ndiff_series = series.diff(ts_diff).dropna()\n\n### MA\ndiff_moving_avg = diff_series.rolling(ts_ma, closed='left').mean().dropna().iloc[split_time - ts_diff - ts_ma:]\ndiff_moving_avg_plus_past = (diff_moving_avg + series.shift(ts_diff)).dropna()\n\n### Both\nsmoothed = series.rolling(ts_smooth_past, closed='left').mean().dropna().iloc[split_time - int(ts_smooth_begin):-int(ts_smooth_end)]\ndiff_moving_avg_plus_smooth_past = smoothed + diff_moving_avg.values\n```\n\n---\n###### 04. Windowing\n\nThe main features of the input windows are:\n- The width (number of time steps) of the input and label windows.\n- The time offset between them.\n- Which features are used as inputs, labels, or both.\n\nExample: Take 24 hours and give a prediction 24 hours in the future.\n- Input width = 24\n- Offset = 24\n- Total width = 48\n- Label width = 1\n\n[Intro to Tensors](https://www.tensorflow.org/guide/tensor)  \n- Tensor: Think of them as np.array that can be 1D, 2D, 3D, etc.\n  - Can be 1 column or more, need to be the same dtype. Basically an np.array.\n- Element: Each value in a tensor. Could be nested which would then contain multiple components\n\n---\n\n###### 05. ML\n\nVideo: 12. Forecasting with ML\n\n[Sample, Batch, Epoch](https://keras.io/getting_started/faq/#what-do-sample-batch-and-epoch-mean)\n- **Sample**: one element of a dataset. (One row)\n- **Batch**: a set of *N* samples. The larger the batch, the better the approximation; pick as large as you can afford without running out of memory\n- **Epoch**: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n\nSGD with some momentum helps converge quickly. Could try Adam as well.\n\nHuber Loss for training: Good for optimizing MAE\n- quadratic for small errors (MSE)\n- linear for large errors (MAE)\n\nEarly Stopping Callback:\n- Patience = 10  --> Interupts training when validation doesn't improve for 10 consecutive epochs\n- This allows us to set epochs = 500 because early stopping will happen way sooner\n\n---\n\n####### Things to be aware of\n\n[Video 1](https://classroom.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/29b5712f-4228-4503-a0e2-3a00a0cfd530)\n1. Do I have the right number of neurons?\n2. Do I have the right number of layers?\n3. Learning rate too..\n   1. High: Training will be unstable, model won't learn\n   2. Low: Training will be slow\n4. Do I have early stopping set right? Loss can jump up/down unpredictably during training.\n\n\n[Video](https://classroom.udacity.com/courses/ud187/lessons/6d543d5c-6b18-4ecf-9f0f-3fd034acd2cc/concepts/0132f4de-dbaf-4d30-b562-f6469c7da3a8)\n1. Vanishing gradient: This often occurs when back propagating through many layers / time steps, especially when detecting long term patterns.\n2. 1. 1 Approach: Make a prediction at each step time (ie Sequence to Sequence). Function: `seq2seq_window_dataset`\n3. RNNs are useful when we have lots of high-frequency data and the signal:noise ratio is high\n\n\nGradient update: $$\\text{New weight} = Weight - LR \\: * \\: Gradient$$\n\nDuring backpropagation, RNNs suffer from vanishing gradient. When going from start to finish, the updates will be too small and the network won't learn.\n\nLSTM uses **gates** to throw away unnecessary info and only keep meaningful.\n\nWithin one cell:\n1. New vector: Combine hidden state (ie prior info) and current input\n2. New hidden state: Apply tan transformation to step 1\n   1. Note: tan to keep regularized between -1 and 1\n\n"},{"title":"_TS MOC","tags":[],"path":"/TimeSeries/_TS MOC","body":"\nDeeper\n- [[Theory - Univariate]] - Univariate\n- [[Video Series]] - Multivariate\n\nDL Resources\n- [Book: Deep Learning for Time Series Forecasting](file:///Users/Sam/Desktop/2%20DS/01%20Predictive/Book-Deep-TS/deep_learning_time_series_forecasting.pdf) by Jason Brownlee\n- [Ch 6: Deep learning for text and sequences](file:///Users/Sam/Library/Mobile%20Documents/iCloud~com~apple~iBooks/Documents/Deep%20Learning%20TS/Ch%206%20Deep%20Learning%20with%20Python.pdf)\n\n\n### TS | Ebook\n\n#### 02. Taxonomy\n\n```ad-sam\n\n1. **Inputs vs. Outputs** (X vs Y)\n   - **Inputs**: Historical data provided to the model in order to make a single forecast.\n   - **Outputs**: Forecast for a future time step beyond the data provided as input.\n<br>\n1. **Endogenous vs. Exogenous** (Influencing each other?)\n   - **Endogenous**: Input variables that *are* influenced by other variables in the system and on which the output variable depends.  \n   - **Exogenous**: Input variables that *are not* influenced by other variables in the system and on which the output variable depends.\n<br>\n1. **Unstructured vs. Structured** (Time-dep patterns?)\n   - **Unstructured**: No obvious systematic time-dependent pattern in a time series variable.  \n   - **Structured**: Systematic time-dependent patterns in a time series variable (e.g. trend and/or seasonality).\n<br>\n1. **Univariate vs. Multivariate**\n   - Uni and Multi **Inputs**: 1+ input variables measured over time.\n   - Uni and Multi **Outputs**: 1+ output variables to be predicted.\n<br>\n1. **Single-step vs. Multi-step**\n   - **One-step**: Forecast the next time step.\n   - **Multi-step**: Forecast more than one future time steps.\n<br>\n1. **Static vs. Dynamic** (Streaming?)\n   - **Static**: Model is fit once and used to make predictions.\n   - **Dynamic**: Model is fit on newly available data prior to each prediction.\n<br>\n1. **Contiguous vs. Discontiguous** (Time uniform?)\n   - **Contiguous**: Observations are uniform over time.  (eg 1 per hour)\n   - **Discontiguous**: Observations are not uniform over time.\n\n```\n\n\n#### 04. Windows\n\nSliding window: Take all columns in the dataset (including target variable) and take the **lag**.\n\nParameters for the **lag**:\n\n- **Input Width**: Number of time steps\n- **Offset**: \"1\" if just using the values from previous time step\n- Total width: Input Width + Offset\n- **Label width**: How many timesteps in the future\n\n\n\n#### 06. Data Transform\n\nInput shape:\n\n- **Samples:** One sequence is one sample. A batch is comprised of one or more samples.  \n- **Time Steps:** One time step is one point of observation in the sample. One sample is comprised of multiple time steps.  \n- **Features:** One feature is one observation at a time step. One time step is comprised of one or more features.\n\nPut Simply:\n\n- Normal Shape: Rows, Columns\n- TS Shape: Rows, **TimeSteps**, Columns\n\n\n\n## Ch 20:  LSTMs\n\nUnlike other algorithms, LSTM RNNs are \n- capable of automatically learning features from sequence data, \n- support multiple-variate data, and \n- can output a variable length sequences that can be used for multi-step forecasting.\n\nReferences\n- Load dataset - ch 17\n- Framework for evaluating models - ch 17\n    - Details of walk-forward validation - ch 19\n\n\nIn this tutorial, we will explore a suite of LSTM architectures for multi-step time series forecasting. Specifically, we will look at how to develop the following models:\n- Vanilla LSTM model with vector output for multi-step forecasting with univariate input data.\n- Encoder-Decoder LSTM model for multi-step forecasting with univariate input data.\n- **Encoder-Decoder LSTM** model for multi-step forecasting with **multivariate** input data.\n- CNN-LSTM Encoder-Decoder model for multi-step forecasting with univariate input data.\n- ConvLSTM Encoder-Decoder model for multi-step forecasting with univariate input data.\n\n\n### Prep / vanilla\n\n```ad-sam\nLSTM shape: [**samples**, **timesteps**, **features**]. \n\n\nOne sample will be comprised of seven time steps with one feature for the seven days of total daily power consumed.\n[1, 7, 1]\n\n\nThe training dataset has 159 weeks of data, so the shape of the univariate training dataset would be: \n[159, 7, 1].\n```\n\n---\n\n```ad-sam\n**Create more training data** \n\n- Test problem: Predict daily consumption for the **next standard week** given the **prior standard week**\n- For training data only: Change the problem to predict the next 7 days given the prior 7 days, regardless of the standard week. \n\n**Flatten**\n- The training data is provided in standard weeks with 8 variables: [159, 7, 8]. \n- Need to flatten the data so we have 8 sequences.\n\n```\n\n```python\n# flatten data \ndata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n```\n\n---\n\n```ad-sam\n**Windowing**\n- For each feature, divide data into overlapping windows.\n- This means that instead of segmenting data into distinct weeks, each training instance slides by one day. (day 1 predicts day 8, day 2 predicts day 9, etc)\n\n\nNeed to keep track of start & end indexes for the inputs & outputs as we iterate across the length of the flattened data in terms of time steps.\n```\n\n```python\n# convert history into inputs and outputs \n\n# \"When we run this function on the entire training dataset, we transform 159 samples into 1,100\"\n# Since the last 6 days in this dataset don’t have a complete output window, we can only use: \n# 1113−7+1 = 1100\n\ndef to_supervised(train, n_input, n_out=7):\n```\n\n---\n\n```ad-sam\nSmall data, so small model\n\n- single **hidden** LSTM layer with 200 units.\n- fully **connected** layer with 200 nodes that will interpret the features learned by the LSTM layer. \n- **output** layer will directly predict a vector with seven elements, one for each day in the output sequence.\n\nSpecs\n- Loss : MSE\n- Optimizer = Adam\n- Epochs: 70\n- Batch size: 16\n```\n\n```python\n\n# The function below \n  # prepares the training data, \n  # defines the model, and \n  # fits the model on the training data, returning the fit model ready for making predictions.\n\ndef build_model(train, n_input):\n```\n\n```ad-sam\n\n**walk-forward validation**\n\n**What is it?**\n- Ccommon evaluation method\n- Instead of training once and making all predictions at once, the model is **retrained over time**, updating with new observations and making one forecast at a time.\n\n**How does it work here?** \n- The model uses the **past week’s observations** (7 days) to predict the **next week** (7 days).\n- After making a prediction, the model gets the **actual observed values** from that week and adds them to the dataset before predicting the following week.\n\n```\n\n\n\n### Encoder-Decoder LSTM With Univariate Input\n\n```ad-sam\n\n| Feature    | **Vanilla LSTM**                                              | **Encoder-Decoder LSTM**                                             |\n| ---------- | ------------------------------------------------------------- | -------------------------------------------------------------------- |\n| Output     | A full sequence is predicted **in one step**                  | The sequence is predicted **one step at a time**                     |\n| Processing | LSTM reads the entire input and outputs a **vector** directly | LSTM first encodes the input, then **iteratively** generates outputs |\n| State      | No feedback from previous outputs                             | **Decoder uses prior predictions** to influence the next step        |\n\n```\n\n```ad-sam\n\n**Key Idea of Encoder-Decoder**\n- The **encoder** reads the input sequence and compresses it into a **fixed-length vector representation**.\n- The **decoder** takes this representation and generates **one time step at a time**, using its internal state to remember prior predictions.\n\n**Why Does This Matter?**\n\n- **Vanilla LSTM** treats **each time step in the output as independent**, meaning it doesn’t explicitly use previous outputs when generating future ones.\n- **Encoder-Decoder LSTM** allows the model to **remember what was predicted in previous time steps** and adjust the next predictions accordingly. This is useful in **multi-step forecasting**, where the prediction for one day can influence the prediction for the next.\n\n\n\n\n```\n\n\n\n### Encoder-Decoder LSTM With Multivariate Input\n\n"},{"title":"Template","tags":[],"path":"/_Assets/Templates/Template","body":"\n"},{"title":"README","tags":[],"path":"/ds_cheatsheets/README","body":"# ML cheatsheets for Stanford's CS 229\n\nSam\n\n- Stanford https://stanford.edu/~shervine/teaching/cs-229\n- Github https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf\n\n\n\n#### Cheatsheets\n|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-supervised-learning.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-001.png?\" alt=\"Illustration\" width=\"220px\"/></a>|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-unsupervised-learning.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-002.png\" alt=\"Illustration\" width=\"220px\"/></a>|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-deep-learning.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-003.png\" alt=\"Illustration\" width=\"220px\"/></a>|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/cheatsheet-machine-learning-tips-and-tricks.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-004.png\" alt=\"Illustration\" width=\"220px\"/></a>|\n|:--:|:--:|:--:|:--:|\n|Supervised Learning|Unsupervised Learning|Deep Learning|Tips and tricks|\n\n#### Refreshers\n|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-probabilities-statistics.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-005.png\" alt=\"Illustration\" width=\"220px\"/></a>|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/refresher-algebra-calculus.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-006.png#1\" alt=\"Illustration\" width=\"220px\"/></a>|\n|:--:|:--:|\n|Probabilities and Statistics|Algebra and Calculus|\n\n\n#### Super Cheatsheet\n|<a href=\"https://github.com/afshinea/stanford-cs-229-machine-learning/blob/master/en/super-cheatsheet-machine-learning.pdf\"><img src=\"https://stanford.edu/~shervine/teaching/cs-229/illustrations/cover/en-007.png\" alt=\"Illustration\" width=\"400px\"/></a>|\n|:--:|\n|All the above gathered in one place|\n\n\n"},{"title":"Home","tags":["welcome"],"path":"/index","body":"\n# Welcome to my Data Science Garden 🌱\n\nUse the sidebar or the search bar (⌘‑K) to jump to any note.\n\n**Tips**\n\n- Newly added Markdown notes automatically appear here after you run  \n  `npm run build-local`.\n- Type in the search box to filter by title, body, or tags.\n- Click a tag chip in search results to narrow further.\n\nEnjoy exploring!\n"}]
